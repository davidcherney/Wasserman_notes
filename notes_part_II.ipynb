{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15d8f3fa-5c72-4f71-ac7d-9250f5547e77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Part II: Statistical Inference\n",
    "\n",
    "How do we go from data to knowledge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc6235b-1b72-427f-a37f-05e56a96ecee",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Ch6 Models, Statistical Inference and Learning\n",
    "The problem: Given a sample $X_1,...,X_n ∼ F$, how do we infer the distribution $F$ they came from?\n",
    "\n",
    "**Definition:** A **statistical model** is a set $\\mathfrak{F}$ of distributions (or densities or regression\n",
    "functions). \n",
    "\n",
    "**Definition:** A **parametric model** is a statistical model \n",
    "$\\mathfrak{F}=\\left\\{ f(x; \\theta)\\, |\\, \\theta \\in \\Theta\\subset \\mathbb{R}^n\\right\\}$ that can be parameterized by a finite number $n$ of parameters $\\theta$.\n",
    "\n",
    "**Definition:** If $\\theta$ is a vector of parameters of a parametric model but we are only interested in one component of $\\theta$, we call the remaining parameters **nuisance parameters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a587c99-1ab6-42b7-9894-1bba2248fb66",
   "metadata": {},
   "source": [
    "### 6.3.1 Point Estimation\n",
    "**Definition:**  **Point estimation** refers to providing a single “best guess” of some quantity of interest from a random sample $X_1,\\dots,X_n$. \n",
    "\n",
    "Note that quantity can mean number, vector, function, et cetera.\n",
    "\n",
    "**Definition:** A (point) **estimator** of a quantity of interest $\\theta$ is a statistic $\\hat\\theta(X_1,\\dots,X_n)$ such that, for any data $x_1,\\dots,x_n$, the quantity $\\hat \\theta(x_1,\\dots,x_n) \\approx \\theta.$\n",
    "\n",
    "**e.g.s** The quantity of interest could be \n",
    "- a parameter in a parametric model, \n",
    "    - e.g. the mean $\\mu$ of a CDF of a random variable $X$.\n",
    "- a cdf $F$, \n",
    "    - e.g. the CDF of the random variable $X$. \n",
    "- a probability density function $f$, \n",
    "- a regression function $r$, or \n",
    "    - e.g. the ine of best fit to the random variable $(X,Y)$ where $X$ and $Y$ are not independent.\n",
    "- a prediction for a future value $Y$ of some random variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abc5414-4433-45d3-8ca1-2b8132ab6c32",
   "metadata": {},
   "source": [
    "**Notation:** We denote a point estimate of $\\theta$ by $\\hat{\\theta}$ or $\\hat{\\theta}_n$ to emphasise its dependence on a random sample of size $n$. Note that $\\theta$ is a fixed, unknown quantity (in the frequentist interpretation). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a2ba9f-17c2-4f3d-8497-148543e9fc2c",
   "metadata": {},
   "source": [
    "**e.g.** \n",
    "1. If $X\\sim F$ has mean $\\mu$ then the sample mean $\\hat{\\mu}_n = \\bar{X}_n = \\frac1n \\sum\\limits_{i=1}^n X_i$ is a point estimator of the parameter $\\mu$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402d65fd-5fa3-4ee1-a52d-02a0408d0db2",
   "metadata": {},
   "source": [
    "2. If $X\\sim F$ then the emperical cumulative distribution $\\hat{F}(x) = \\frac{1}{n} \\sum\\limits_{i=1}^n I(X_i\\geq x)$ is a (point) estimator of the CDF $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491ded70-08c5-4d45-8c66-337d098f79e8",
   "metadata": {},
   "source": [
    "3. The statistic $\\bar{X}_n$ is an estimator of the predicted future value $\\mathbb{E}(X)$ of $X$. \n",
    "\n",
    "4. If the linear function of best fit to some phenomena is the function $L(x)=mx$, then $\\hat{L}$ such that $\\hat{L}(x) = \\hat{m}x=\\left((X^n)^T (X^n)\\right)^{-1} (X^n)^T Yx$ is a (point) estimator of the linear function $L$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500f31d9-17ef-454d-9eb9-68a4d4c27842",
   "metadata": {},
   "source": [
    "#### Distributions for point estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1925bb8-ae29-4161-83fd-eb475485b116",
   "metadata": {},
   "source": [
    "Point estimators have distributions. \n",
    "\n",
    "**e.g.** The statistic known as the sample mean $\\bar X_n$ of a random variable $X$ is a estimator of the population mean $\\mu=\\mathbb{E}(X)$ of $X$; that is $\\hat{\\mu}_n:=\\bar X_n$ is an estimator of $\\mu$. That estimator has a distribution. In particular, but a bit besides the point, by the central limit theorem, for large values of $n$ that distributionis close to a normal distribution. \n",
    "\n",
    "Sometimes the parameter being estimated $\\theta$ is a characteristic of the distribution. For that reason we now use the notation for CDFs $F(X: \\theta)$ to indicate that the CDF $F(\\cdot;\\theta)$ is an element of a parameterized model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af396e7-4382-4035-940f-84df0d7b6ac0",
   "metadata": {},
   "source": [
    "#### LOTUS for point enstimators\n",
    "Recall from ch2.11 that the distribution  $F_{\\hat{\\theta}}$ of a statistic $\\hat{\\theta}(X^n)$ of a random variable $X$ is  derived from the change of variables \n",
    "$\\hat \\theta_n = \\hat\\theta_n(X_1,\\dots,X_n)$. (A point estimator is a statistic, so the same is true of it's distribution.) In terms of the family of sets $A_t = \\{x^n\\,|\\, \\hat{\\theta}(x^n)< t\\}$ and the CDF $F_X(\\cdot;\\theta)$ the distribution of a statistic is\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "F_{\\hat\\theta_n}(t) \n",
    "&=\\idotsint_{A_t} dF_{X_1,\\dots ,X_n } (x_1,\\dots,x_n;\\theta)\\\\\n",
    "&=\\idotsint_{A_t}  \\phantom{d}f_{X_1,\\dots ,X_n } (x_1,\\dots,x_n;\\theta)\\, dx_1\\dots\\,dx_n\\\\\n",
    "&=\\idotsint_{A_t} \\prod\\limits_{i=1}^n \\left[f_X(x_i;\\theta)\\right] \\,dx_1\\dots\\,dx_n.\n",
    "\\end{array}\n",
    "$$\n",
    "where the joint distribution on IID variables $f_{X^n}(x_1,...,x_n; \\theta) = \\prod\\limits_{i=1}^n f_X(x_i;\\theta)$ has been used. \n",
    "\n",
    "Further recall that to calculate expectation values (and other moments) this is not needed: \n",
    "$$\n",
    "\\mathbb{E}\\left(\\hat{\\theta}_n(X^n)\\right) \n",
    "=\\int_{t\\in\\mathbb{R}}t dF_{\\hat\\theta_n}(t) \n",
    "\\stackrel{LOTUS}{=} \\idotsint\\limits_{\\mathbb{R}^n}\\hat{\\theta}_n(x^n)  \\,dF_X(x_1)\\dots\\,dF_X(x_n)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422b818a-ca04-4bc2-a93d-135c7d9024ac",
   "metadata": {},
   "source": [
    "#### Measures of estimation\n",
    "##### Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ee0d98-8c18-453a-bbc9-99aa11a905a9",
   "metadata": {},
   "source": [
    "**Definition:** The **bias** of a (point) estimator $\\hat \\theta_n$ of a parameter $\\theta$ is defined by\n",
    "$\\text{bias}(\\hat{\\theta}_n) = \\mathbb{E}_{\\hat \\theta_n}(\\hat{\\theta}_n − \\theta)$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3239674f-5670-47e9-a88c-3e1d1db3517a",
   "metadata": {},
   "source": [
    "**e.g.** The \"plug in variance\" \n",
    "$V = \\frac{1}{n} \\sum\\limits_{i=1}^n (X_i − \\bar{X_n} )^2$ of a continuous random variable $X$ is a biased estimator of the variance of $X$ because \n",
    "$$\\mathbb{E}(V - \\sigma^2) = \\frac{n-1}{n}\\sigma^2 - \\sigma^2 = -\\frac1n \\sigma^2.\n",
    "$$\n",
    "\n",
    "**non-e.g.** The the sample variance \n",
    "$S^2_n = \\frac{1}{n-1} \\sum\\limits_{i=1}^n (X_i − \\bar{X_n} )^2$ of a random variable $X$ is a un-biased estimator of the variance of $X$ because \n",
    "$$\\mathbb{E}(S_n^2 - \\sigma^2)  =0.$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bea800-b0e4-4319-8209-2de63016f126",
   "metadata": {},
   "source": [
    "##### Consistnency \n",
    "**Definition** An estimator $\\hat{\\theta}_n$ of a parameter $\\theta$ is **consistent** if $\\hat\\theta_n\\stackrel{P}{\\to}\\theta$ as $n\\to\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344bddc8-f332-4afc-adb6-2f1b035a91ef",
   "metadata": {},
   "source": [
    "I gather that the idea of having a consistant estimator used to consume a lot of reserach, but now it is less cool. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429fbe22-50f3-4c64-a6d0-1914fb69e6a5",
   "metadata": {},
   "source": [
    "**e.g.s** Both the sample variance and the plug in variance are consistent estimators of the variance of a random variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e485c-c2e6-4aab-a1d2-6f01ce952b51",
   "metadata": {},
   "source": [
    "##### MSE\n",
    "If we know the value of the parameter being estimated we can calculate the MSE.\n",
    "\n",
    "**Definition** The **mean squared error**, or $\\text{mse}$, \n",
    "of a point estimate $\\hat{\\theta}_n$ of a parameter $\\theta$ is \n",
    "$\\text{mse}\\left(\\hat \\theta_n\\right) = \\mathbb{E}_{\\hat \\theta_n}(  \\hat{\\theta}_n − \\theta)^2$, which is the square of the standard deviation with known mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c77f1b1-42cf-4e47-9ff5-fa52de38eaae",
   "metadata": {},
   "source": [
    "##### SE \n",
    "If we do not know the value of the parameter being estimated then we can calculate the following. \n",
    "\n",
    "**Definition:** The **standard error** of an estimator $\\hat{\\theta}_n$ is the standard deviation of that estimator (with unknown mean). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597507ee-7d42-4f21-8202-2845221c7481",
   "metadata": {},
   "source": [
    "**Notation:** $\\text{se}_n = \\text{se}(\\hat{\\theta}_n) \n",
    "= \\sqrt{\\mathbb{V}_{\\hat \\theta_n } (\\hat{\\theta}_n)}\n",
    " = \\sqrt{\\int \\left( \\hat\\theta_n  - \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta_n) \\right)^2 dF_{\\hat\\theta_n}(x)}.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86172d5c-b2b8-4b4c-85a4-a4f85f986ff9",
   "metadata": {},
   "source": [
    "Note that I used to be confused about the subscript to be used on $\\mathbb{V}$, should it be $\\hat{\\theta}_n$ or $X^n$? But now I think it does not matter because of the law of the unconcious statistician (LOTUS). \n",
    "\n",
    "However, since $\\hat{\\theta}_n$ does not depend on $X$, but rather $X^n$, the subscript $X$ would be inappropriate.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa374a9-f8de-41ee-918f-0bf287b7f52f",
   "metadata": {},
   "source": [
    "Often, the standard error depends on the unknown parameter $\\theta$ of the CDF $F_X(\\cdot;\\theta)$. In those cases, $\\text{se}$ is an unknown quantity but we usually can estimate it. The estimated standard error is denoted by $\\hat{\\text{se}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c1aa92-16e6-40a2-ae45-da1448199deb",
   "metadata": {},
   "source": [
    "That is tricky, so slow down; \n",
    "- estimators have standard error. \n",
    "    - one can form an estimator of the standard error of an estimator.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02732b6e-fa0e-43b2-9d0c-89197dda9f49",
   "metadata": {},
   "source": [
    "#### MSE as bias plus variance. \n",
    "\n",
    "**Theorem:** $\\text{mse}= \\text{bias}^2 + \\mathbb{V}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca11c163-4041-4bb1-bb71-6bf4cdec5715",
   "metadata": {},
   "source": [
    "**Proof** (from my notes on Unpingco)\n",
    "$$\n",
    "\\text{MSE}(\\hat \\theta) \n",
    "= \\mathbb{E}_{\\hat \\theta_n}( \\theta -  \\hat{\\theta}_n )^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97517f70-0b77-4f8c-8b21-2a3cc2a1a163",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\mathbb{E}_{\\hat \\theta_n} \n",
    "\\left[ \n",
    "\\left( \\theta -\\mathbb{E}_{\\hat{\\theta}_n }(\\hat \\theta) \\right) \n",
    "+ \n",
    "\\left( \\mathbb{E}_{ \\hat\\theta_n} ( \\hat \\theta_n) - \\hat{ \\theta } \\right)\n",
    "     \\right]^2 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6792c7e0-8eae-4e82-b7d0-4c4b861823e5",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\mathbb{E}_{\\hat \\theta_n} \\left[  (\\theta                                     -\\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta) )^2 \n",
    "                                + ( \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta)  - \\hat{ \\theta }                    )^2   \n",
    "+ 2(\\theta -\\mathbb{E}_{\\hat\\theta_n}(\\hat \\theta) ) ( \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta)  - \\hat{ \\theta } )\\right] \\\\\n",
    "= \n",
    "\\mathbb{E}_{\\hat \\theta_n} \\left[  (\\theta                                     -\\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta) )^2 \n",
    "                                + ( \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta)  - \\hat{ \\theta }                    )^2   \\right] \n",
    "+ 2(\\theta -\\mathbb{E}_{\\hat\\theta_n}(\\hat \\theta) ) ( \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta)  - \\mathbb{E}_{\\hat\\theta_n}(\\hat{ \\theta } ))\n",
    "$$\n",
    "\n",
    "$$\n",
    "=\\left(\\theta -\\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta) \\right)^2 \n",
    "+ \\mathbb{E}_{\\hat \\theta_n}\\left( \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta)  - \\hat{ \\theta } \\right)^2 $$\n",
    "\n",
    "$$= \n",
    "\\text{bias}^2(\\hat{\\theta}) \n",
    "+\n",
    "\\text{var}(\\hat{\\theta}). \\square \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b7a97-e449-4bc7-be28-8ecf9904cf65",
   "metadata": {},
   "source": [
    "**Theorem:** If both bias and variance go to zero with increasing $n$ then the estimator is consistent. \n",
    "\n",
    "**Proof:** If bias and variance go to zero then $\\text{MSE}$ does too. Thus \n",
    "$\\hat\\theta \\stackrel{QM}{\\to} \\theta \\Rightarrow\\hat\\theta \\stackrel{P}{\\to} \\theta. \\square$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f5768b-6031-4efb-999f-ac22c7b66a97",
   "metadata": {},
   "source": [
    "**Definition:** An estimator $\\hat \\theta$ of a parameter $\\theta$ is **asymptotically normal** if\n",
    "$\\frac{\\hat{\\theta}_n − \\theta}{\\text{se} } \\stackrel{dist}{\\to} N (0, 1)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "414bb8fe-ea86-4165-a979-2173b48b142e",
   "metadata": {},
   "source": [
    "It is striking how many estimators are asymptotically normal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcaaae5-c613-4f71-8ad9-5972ec5c2562",
   "metadata": {},
   "source": [
    "## 6.3.2 Confidence Intervals/sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7eb14-ec08-47f2-b694-f303452b07f6",
   "metadata": {},
   "source": [
    "By contrast with point estimation... \n",
    "\n",
    "When using a continuous random variable $X$ the probability of being correct with a point estimation is zero; e.g. $\\mathbb{P}(\\mu = \\bar{X}_n)=0$.\n",
    "\n",
    "While there is obvious utility in estimating the value of a parameter using a value (e.g. the number 3.1 is an estimate of the parameter $\\pi$) there is also bennefit in estimating the value of a parameter using an interval. The goal in the latter is to find an interval $(a,b)$ of small width such that there is a high probability that the value of the parameter is in the interval; $\\mathbb{P}(\\mu\\in (a,b))\\approx 1$ . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af3a0d-d0a1-4863-bed6-ea6d99ec914e",
   "metadata": {},
   "source": [
    "**Defintion:** For a parmeter $\\theta$ and an interval $(a,b)$, the probability that the parameter is in the interval $\\mathbb{P}(\\theta\\in (a,b))$ is the <u>coverage probability</u> of the interval $(a,b)$. \n",
    "    \n",
    "But how do we obtain coverage probabilities we want from statistics/data? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adfcbce-a4e4-4973-ba01-1c37d3de465a",
   "metadata": {},
   "source": [
    "($\\alpha$ significance interval? \n",
    "\n",
    "**Definition** A $1 −\\alpha$ **confidence interval estimator** for a parameter $\\theta$ is an interval valued statistic $C_n = (a, b)$ where the random variables $a = a(X_1,...,X_n)$ and $b = b(X_1,...,X_n)$ are functions of the data such that\n",
    "$\\mathbb{P}_{X^n}(   C_n  \\ni \\theta\\,;\\,\\theta) ≥ 1−\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f866f3a-febc-400e-a054-965f371c274d",
   "metadata": {},
   "source": [
    "Note that <a href src=\"https://www.stat.purdue.edu/~fmliang/STAT611/st611lect9.pdf\"> Liang</a> calls the interval with random variable upper and lower bounds the <u>interval estimator</u>. I think this is nice to linguistically differentiate between a confdence interval estimator (an interval valued random variable) and a confidence interval (an interval obtained by evaluating at an outcome of a random sample). \n",
    "\n",
    "Remember that $\\theta$ is a fixed quantity, so the idea is that the data specify an interval, and the probability that the data specify an interval containing the parameter is bounded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bb32c4-f980-4383-9a53-01454442363e",
   "metadata": {},
   "source": [
    "**Definition:** If $(a,b)$ is a confidence interval of a statistic $\\theta$ then $a$ is called the <u>lower confidence limit</u> and b is called the <u>upper confidence limit</a>.\n",
    "\n",
    "**Definition:** $1-\\alpha$ is called the <u>confidence coefficient</u>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55764aea-ff15-480e-9ad8-a951e6e85cd7",
   "metadata": {},
   "source": [
    "Another way to think about it is that a confidence interval is a confidence level with a interval estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4282dcc1-09b2-4700-871e-bc5c9ce3bd61",
   "metadata": {},
   "source": [
    "**Note** on the most common misunderstanding of confidence intervals: In $\\mathbb{P}( \\theta \\in C_n\\,;\\, \\theta )$ the symbol $\\theta$ is fixed while $C_n$ is an interval valued random variable. It is common for people to think that $\\theta$ somehow varies with the data here, but it is $C_n$ that varies with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b97d90-67ce-41fd-a1fb-fe6b7dfedab6",
   "metadata": {},
   "source": [
    "**Definition:** If $\\theta$ is a vector then we use a **confidence set** (such as a sphere or an ellipse) instead of an interval."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f21be4-6684-46a5-92c3-96d6c244ec30",
   "metadata": {},
   "source": [
    "Addressing common confusion about confidence sets\n",
    "- It is not a statement about the probability of $\\theta$ being some number, since $\\theta$ is fixed. \n",
    "- It is pretty un-physical to say that if you repeat data collection 100 times that you will obtain 100 intervals, with 95% of those intervals containng the true value $\\theta$, since we do not repeat experiments in real life. Rather, we typically have just one sample. \n",
    "- There have been many experiments of many kinds performed in the past to obtain data and 95% confidence intervals. The best interpretation is that 5% of those experiments led to confidence intervals that did not contain the true value. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be21af6-f057-43cb-81ac-87587321a7a5",
   "metadata": {},
   "source": [
    "### Pivots facilitate estimation CIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c1a891-17fd-414c-9174-7515e0f5f339",
   "metadata": {},
   "source": [
    "This definition is not in Wasserman, but since the term is used I looked it up and found <a href src=\"https://www.stat.purdue.edu/~fmliang/STAT611/st611lect9.pdf\">this</a> dfn, 9.2.1. Also note that \"In general, differences are pivotal for location problems, while ratios are pivotal for scale problems\". I think this means that  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d644c758-efa6-46e6-9140-f9395fda31b6",
   "metadata": {},
   "source": [
    "**Definition:** Let $\\hat{\\theta}_n(X^n)$ be a point estimator of the parameter $\\theta$. Assume that $X\\sim F_{X}(\\cdot;\\theta)$, meaning the distribution for $X$ has a parameter $\\theta$. A function of the estimator and parameter  $R\\left(\\hat{\\theta}_n|\\theta\\right)$ is a **pivotal quantity** of $\\theta$ if its distribution $F_{R\\left(\\hat{\\theta}_n|\\theta\\right)}$ is independent of the parameter $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2e67da-795f-4a2c-9d4f-1e943c5d307f",
   "metadata": {},
   "source": [
    "This <a href src=\"https://pages.stat.wisc.edu/~shao/stat610/stat610-16.pdf\">slide</a> says a pivot is not a statistic. Why isn't a pivot a statistic despite being a function of statistic? I'll have to sort this out another day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec771a4-91be-4a41-8cd3-8b1b593c1e42",
   "metadata": {},
   "source": [
    "Typically these distributions $F_R$ of pivots R are $N(0,1),~t,~\\chi,$ or $F$ dsitributions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af367228-4f99-4122-8c16-91a2e311bf77",
   "metadata": {},
   "source": [
    "The idea is that after finding a pivot the equation $\\mathbb{P}(a\\leq R(\\cdot|\\theta) \\leq b)=1-\\alpha$ can be rearranged to isolate $\\theta$ in an equaltiy of the form $\\mathbb{P} \\left( L\\leq \\theta \\leq U \\right)=1-\\alpha$ with upper and lower confidence limits $L,U$ independent of $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060b0a5b-12c4-4d25-b181-9234d7729869",
   "metadata": {},
   "source": [
    "#### Z\n",
    "How to obtain a confidence interval of the estimator $\\bar{X}_n$ of population mean $\\mu$ of a normal distribution when variance is known via the pivot $\\frac{\\bar{X}_n-\\mu}{\\sigma/\\sqrt{n}} \\sim {\\cal N}(0,1)$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2d77c6-5a01-4f20-aec6-1ba6e0704b8b",
   "metadata": {},
   "source": [
    "If it is known that $X\\sim N(\\mu,\\sigma)$ with $\\mu$ unknown and $\\sigma$ known then, $\\bar{X}_n$ is an estimator of $\\mu$ and \n",
    "$R(\\bar{X}^n|\\mu) = \\frac{\\bar{X}_n-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0, 1)$ is a pivot of $\\mu$. (Prove it some day!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f56c1c-5faa-45ae-b6c7-d28012f7d314",
   "metadata": {},
   "source": [
    "The goal is to find some interval $(a,b)$ such that $\\mathbb{P}\\left( a \\leq \\frac{\\bar{X}_n-\\mu}{\\sigma/\\sqrt{n}} \\leq b \\right) = 1-\\alpha$. One choice for $(a,b)$ is the symmetric interval $\\left( F_{N(0,1)}^{-1}\\left(\\frac{\\alpha}{2}\\right) , F_{N(0,1)}^{-1}\\left(1- \\frac{\\alpha}{2}\\right)  \\right)=:(-U,U)$, giving $1-\\alpha$ confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf74a7-7b85-46bd-8bde-03bb0b88de32",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Leftrightarrow \n",
    "\\mathbb{P}\\left( \n",
    "\\bar{X}_n- F_{N(0,1)}^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\frac{\\sigma}{\\sqrt n}\n",
    "\\leq \n",
    "\\mu\n",
    "\\leq \n",
    "\\bar{X}_n+F_{N(0,1)}^{-1}\\left(1-\\frac{\\alpha}{2} \\right)\\frac{\\sigma}{\\sqrt n}\n",
    "\\right) = 1-\\alpha \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c6dcad-e10f-49c1-8936-84e658d8d365",
   "metadata": {},
   "source": [
    "#### t \n",
    "\n",
    "How to obtain a confidence interval for the estimator $\\bar{X}_n$ of population mean $\\mu$ of normal a distribution when variance is not known via the pivot $\\frac{\\bar{X}_n-\\mu}{S_{n}/\\sqrt{n}}t_{n-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c4259e-949c-4d07-9b8c-be5e2be5eb2f",
   "metadata": {},
   "source": [
    "If it is known that $X\\sim N(\\mu,\\sigma)$ with $\\mu$ unknown and $\\sigma$ unknown then $\\bar{X}$ is an estimator of $\\mu$ and \n",
    "$R(\\bar{X}_n|(\\mu,\\sigma)) = \\frac{\\bar{X}_n-\\mu}{S_{n}/\\sqrt{n}} \\sim F_{t_{n-1}}$. Thus $R$ is a pivot of $\\mu$. The goal is to find some interval $(a,b)$ such that $\\mathbb{P}\\left( a \\leq \\frac{\\bar{X}_n-\\mu}{S_{n}/\\sqrt{n}} \\leq b \\right) = 1-\\alpha$. One choice for $(a,b)$ is the symmetric interval $\\left( F_{t_{n-1}}^{-1}\\left(\\frac{  \\alpha}{2}\\right) , F_{t_{n-1}}^{-1}\\left(1-\\frac{\\alpha}{2}\\right)  \\right)=:(-U,U)$, giving $1-\\alpha$ confidence interval\n",
    "$$\n",
    "\\mathbb{P}\\left( \n",
    "\\bar{X}_n - F_{t_{n-1}}^{-1}\\left(1-\\frac{\\alpha}{2}\\right) \\frac{S_{n}}{\\sqrt n}\n",
    "\\leq \n",
    "\\mu\n",
    "\\leq \n",
    "\\bar{X}_n + F_{t_{n-1}}^{-1}\\left(1-\\frac{\\alpha}{2} \\right)\\frac{S_{n}}{\\sqrt n}\n",
    "\\right) = 1-\\alpha \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334b9479-4438-46ee-8c2b-1e4849a22c5d",
   "metadata": {},
   "source": [
    "#### Chi\n",
    "\n",
    "How to obtain a confidence interval for the estimator $S_n$ (sample variance) of the population variance $\\sigma$ of a normal distribution ${\\cal N}(0,\\sigma)$ via the pivot $\\frac{(n-1)S^2}{\\sigma} \\sim F_{\\chi_{n-1}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d9b30e-ead5-44d0-9a22-a3ce5dd8f257",
   "metadata": {},
   "source": [
    "Say it is known that $X$ is normally distributed with unknown $\\mu$ and $\\sigma$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a08390b-a336-4b80-9a85-96831c045ebe",
   "metadata": {},
   "source": [
    "**Definition:** The <u>chi squared</u> random variable with $n$ degrees of freedom is $\\chi^2_n = \\sum_{i=1}^n X_i^2$ where $X_i\\sim {\\cal N}(0,1)$. \n",
    "\n",
    "**Theorem (Cochran's Theorem):** Let $Y^d = (Y_1,...,Y_d) \\sim {\\cal N}(\\mu  \\bar{1},\\sigma I)$. The centered and normalized sum of squares \n",
    "$$\n",
    "\\frac{1}{\\sigma} (Y^d)^T(I - \\frac1d \\bar{1}\\bar{1}^T)Y^d \n",
    "=\\frac{1}{\\sigma} (Y^d)^T M Y^d \n",
    "$$ \n",
    "is distributed as the $\\chi^2_{d-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70f01a8-9ec0-4376-8fb9-1190aead494b",
   "metadata": {},
   "source": [
    "**Proof:** Note that the symmetric matrix $M$ has set of eigenvalues $\\{0,1\\}$. The eigenspace $V_0 = \\text{Span}\\left( b_1 \\right)$ where $b_1=\\frac1{\\sqrt{n}}\\bar{1}$ while $V_1$, has orthonomal basis $(b_2,...,b_d)$. Thus $BMB^T$ is diagonal with $\\text{Diag}(BMB^T) = (0,1,...,1)$ and is a projection matrix. It is thus idempotent and symmetric. Let $Z^d= \\frac1{\\sqrt{\\sigma}}B(Y^d - \\bar{Y}_d\\bar{1})$ and note that $$\n",
    "Z^d \\sim {\\cal N}\\left(\n",
    "                        \\frac1{\\sqrt{\\sigma}^2} [\\mu \\bar{1} - \\mathbb{E} (\\bar{Y}_d \\bar{1})],\n",
    "                        \\frac1{\\sqrt{\\sigma}^2}(B \\sigma I B^T)\n",
    "                   \\right)\n",
    "={\\cal N}(\\bar{0}, I).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b391f5-399d-46ac-8815-2c558a3603de",
   "metadata": {},
   "source": [
    "Then the centered and normalized sum of squares\n",
    "$$\\begin{array}{ll}\n",
    "\\frac1\\sigma \n",
    "    \\sum\\limits_{i=1}^d (Y_i - \\bar{Y})^2 \n",
    "            &= \\frac1\\sigma (Y^d-\\bar{Y}_d)^T  (Y^d-\\bar{Y}_d) \\\\\n",
    "            &= \\frac1\\sigma (Y^d)^T       M^T M Y^d \\\\\n",
    "            &= \\frac1\\sigma (Y^d)^T       M     Y^d \\\\\n",
    "            & = \\frac1\\sigma Z^d Q\\sqrt{\\sigma} M \\sqrt{\\sigma} Q^T Z^d \\\\ \n",
    "            &= \\sum\\limits_{i=2}^{d} Z_i^2 \\sim \\chi^2_{d-1}.\n",
    "\\end{array}\\\\\n",
    "$$\n",
    "$\\square$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9e9d5d-b33c-4bc2-82ba-27f8fc564028",
   "metadata": {},
   "source": [
    "The parameter $\\sigma^2$ has estimator $S^2_n = \\frac{1}{n-1}\\sum_{i=1}^n(X_i - \\bar{X}_n)^2$. A pivot of $S^2_n$ is $\\frac{ (n-1)S^2 }{ \\sigma^2}$ which, according to Cochran's theorem, is distributed as $F_{\\chi^2_{n-1}}$, which is independent of the parameter $\\sigma$. \n",
    "\n",
    "The goal is to find some interval $(a,b)$ such that $\\mathbb{P}\\left( a \\leq \\frac{ (n-1)S^2 }{ \\sigma^2} \\leq b \\right) = 1-\\alpha$. One choice for $(a,b)$ is the interval $\\left( 0, F_{\\chi_{n-1}^2}^{-1}\\left(1-\\alpha\\right)  \\right)=:(L,U)$, giving $1-\\alpha$ confidence interval\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left( \n",
    "\\sigma^2 \\geq \\frac{(n-1)S_n^2}{F_{\\chi^2_{n-1}}^{-1}\\left(1-\\alpha\\right)}  \n",
    "\\right) = 1-\\alpha \\\\\n",
    "$$\n",
    "\n",
    "Note that while the algebra used $\\sigma^2$, you can see in the end here that it is an unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45b551f-9895-4aed-9ca6-143522a34037",
   "metadata": {},
   "source": [
    "**Note 1** that this can be done with the estimator $\\hat{\\sigma^2}_n = \\frac1n \\sum (X_i - \\bar{X}_i)^2$ too by noting that $\\frac{n}{\\sigma^2} \\hat{\\sigma^2}_n \\sim F_{\\chi^2_{n-1}}$ and thus \n",
    "$$\n",
    "\\mathbb{P}\\left( \n",
    "\\sigma^2 \\geq \\frac{n\\hat{\\sigma^2}_n}{F_{\\chi^2_{n-1}}^{-1}\\left(1-\\alpha\\right)}  \n",
    "\\right) = 1-\\alpha \\\\\n",
    "$$.\n",
    "\n",
    "**Note 2**\n",
    "\n",
    "One can also construct the two sided $\\left(F^{-1}_{\\chi^2_{n-1}}\\left(\\frac{\\alpha}{2}\\right) , F^{-1}_{\\chi^2_{n-1}}\\left(1-\\frac{\\alpha}{2}\\right)\\right)$. That gives 4 ways to construct confidence intervals for an estimator of population variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8001f-4a88-40f7-9b9f-b9624c34bde4",
   "metadata": {},
   "source": [
    "#### F\n",
    "\n",
    "Well I do not know this one yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae76a3f2-907a-475b-ae77-0669293580ed",
   "metadata": {},
   "source": [
    "#### U\n",
    "\n",
    "An estimator of the parameter $\\theta$ in $\\text{Uniform}(0,\\theta)$ is the statistic $M=\\max \\{X_i\\,|\\, i\\in\\{1,\\dots,n\\}\\}$. Since\n",
    "$F_M(m) = \\frac{m^n}{\\theta^n}$ the statistic $M$ is not a pivot of $\\theta$. However, $U=M/\\theta$ has distribution $F_{U}(x) = x^n$, and so the statistic $U$  is a pivot. \n",
    "\n",
    "The goal is to find some interval $(a,b)$ such that $\\mathbb{P}\\left( a \\leq U \\leq b\\right)=1-\\alpha$. One choice is to leave probability $\\alpha/2$ on each side of the CDF of $U$; choose $(a,b) = \\left( F_{U}^{-1}\\left(\\frac{\\alpha}{2} \\right) , F_{U}^{-1}\\left(1-\\frac{\\alpha}{2} \\right) \\right) = \\left( \\left(\\frac{\\alpha}{2}\\right)^{1/n}  , \\left(1-\\frac{\\alpha}{2}\\right)^{1/n}   \\right)$. giving \n",
    "$$\\mathbb{P}\\left(  \\left(\\frac{\\alpha}{2}\\right)^{1/n}  \\leq U \\leq \\left(1-\\frac{\\alpha}{2}\\right)^{1/n}  \\right) = 1-\\alpha$$\n",
    "$$\\Leftrightarrow \n",
    "\\mathbb{P}\\left(  \n",
    "M \\left(1-\\frac{\\alpha}{2}\\right)^{-1/n}  \n",
    "\\leq \\theta \\leq \n",
    "M \\left( \\frac{\\alpha}{2}\\right)^{-1/n}  \n",
    "\\right) = 1-\\alpha$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7245cc-e3e9-4f12-b0bd-a86622ac085c",
   "metadata": {},
   "source": [
    "#### Best interval\n",
    "\n",
    "**Theorem:** The $1-\\alpha$ interval $(a,b)$of smallest width $b-a$ for a unimodal distribution with PFD $f$ satisfies $f(a) = f(b)$ and $a<x^*< b$ where $x^*$ is the mode. \n",
    "\n",
    "This is called the highest density confidence interval. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e09ffdf-43fa-4c5e-8495-21c725fdbea8",
   "metadata": {},
   "source": [
    "### Misunderstanding \n",
    "\n",
    "Again, once one runs experiments to obtain outcomes $\\omega_1,\\dots,\\omega_n \\in \\Omega$ and thereby obtains data $\\{x_i = X(\\omega_i)\\in \\mathbb{R}| i\\in\\{1,\\dots,n\\} \\}$, and obtains a statement like $\\mathbb{P}(.1 \\leq\\theta \\leq .3)=95\\%$... \n",
    "\n",
    "One **does not** have a statement that the probabiliy of $\\theta$ being in the interval is $95\\%$. Rather, the statement $\\mathbb{P}(.1 \\leq\\theta \\leq .3)=95\\%$ is either true or false. The idea, rather, is either that \n",
    "1. If the $n$ experiments were run a very large number of times the resulting statements would be true $95\\%$ of the time. But this is never done in science.\n",
    "2. Our of all $95%$ CI experiments performed, $5\\%$ identified CIs that did not contain the desired parameter. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efce6eb-b876-4eea-a187-db02327cb1eb",
   "metadata": {},
   "source": [
    "##  ch6 Exercises \n",
    "\n",
    "6.6.1 \n",
    "\n",
    "Problem: Let $X_1,...,X_n \\sim \\text{Poisson}(\\lambda)$ and let $\\hat\\lambda_n = n^{−1} \\sum\\limits_{i=1 }^n X_i$ be an estimator of $\\lambda$. Find the $\\text{bias, se}$ and $\\text{mse}$ of this estimator. \n",
    "\n",
    "Solution: The pdf of the Poisson distribution is $ f(k) = \\frac{\\lambda^k}{k!} e^{-\\lambda}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f1fb89-4655-4b8a-bb35-cbaaef3c44a1",
   "metadata": {},
   "source": [
    "The mean $\\mu$ of the Poisson distribution is \n",
    "$$\n",
    "\\mu = \\mathbb{E}(k) = \\sum\\limits_{k=1}^\\infty k \\frac{\\lambda^k}{k!} e^{-\\lambda} \n",
    "=e^{-\\lambda} \\lambda \\frac{d }{d\\lambda} \\sum\\limits_{k=0}^\\infty   \\frac{\\lambda^{k}}{k!} \n",
    "=e^{-\\lambda} \\lambda \\frac{d }{d\\lambda} e^{\\lambda}  = \\lambda\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019ca1a8-3941-4c54-a9f1-e287a265b370",
   "metadata": {},
   "source": [
    "while the variance \n",
    "$$\n",
    "\\sigma^2 = \\mathbb{E}(k^2) - \\mu^2 \\\\\n",
    "= \\sum\\limits_{k=1}^\\infty k^2 \\frac{\\lambda^k}{k!}e^{-\\lambda} - \\mu^2\\\\\n",
    "= e^{-\\lambda} \\lambda \\frac{d}{d\\lambda}  \\lambda \\frac{d}{d\\lambda} e^{\\lambda}- \\mu^2\\\\\n",
    "= e^{-\\lambda} \\lambda \\frac{d}{d\\lambda}  \\lambda e^{\\lambda}- \\mu^2\\\\\n",
    "= e^{-\\lambda} \\lambda (  \\lambda e^{\\lambda}+ e^{\\lambda})- \\mu^2\\\\\n",
    "=  \\lambda (  \\lambda + 1)- \\mu^2\\\\\n",
    "=  \\lambda^2 +\\lambda - \\lambda^2 = \\lambda.\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31403ab-c0cd-46ad-9c8d-739559a0abf8",
   "metadata": {},
   "source": [
    "The bias of $\\hat \\lambda$ is \n",
    "$$\\mathbb{E}(\\hat \\lambda) - \\mu =0\n",
    "$$\n",
    "while the standard error is \n",
    "$$\n",
    "\\mathbb{E}[(\\hat \\lambda - \\mathbb{E}(\\hat \\lambda))^2]\\\\\n",
    "=\\mathbb{E}[(\\hat \\lambda)^2] - \\mu^2\\\\\n",
    "= \\frac1{n^2}\\mathbb{E}\\left[ \\sum\\limits_{i=1}^n X_i^2 + 2\\sum\\limits_{1\\leq i<j\\leq n}X_iX_j \\right] - \\mu^2\\\\\n",
    "= \\frac1{n^2}\\left[ n\\left( \\sigma^2 + \\mu^2 \\right) + 2 \\frac{n(n-1)}{2} \\mu^2\\right] - \\mu^2\\\\\n",
    "= \\frac{\\sigma^2}{n} + \\mu^2\\left[ \\frac1n +\\frac{n(n-1)}{n} -1 \\right] \\\\\n",
    "=  \\frac{\\sigma^2}{n}\\\\ \n",
    "=  \\frac{\\lambda}{n} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ab85d3-2348-4018-8a2a-89e329df67de",
   "metadata": {},
   "source": [
    "The $\\text{mse} = \\text{bias}^2 + \\text{se} = 0 + \\frac{\\lambda}{n}$. $\\square$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c513ab4-bcdb-4d09-abaa-06c24bae2be5",
   "metadata": {},
   "source": [
    "6.6.2 \n",
    "Problem: Let $X_1,...,X_n ∼ \\text{Uniform}(0,\\theta)$ and let $\\hat{\\theta}_n= \\text{max}\\{X_1,...,X_n\\}$. Find the bias, se, and mse of this estimator.\n",
    "\n",
    "Solution: \n",
    "If the greatest random variable is $X_M$ then \n",
    "$$\n",
    "\\mathbb{P}(\\hat{\\theta} > x) \n",
    "= \\mathbb{P}(X_M > x)\n",
    "= \\mathbb{P}\\left(( \\forall  i \\in \\{i,\\dots ,n \\}) X_i > x\\right)\n",
    "$$\n",
    "By independence of the $X_i$ we have that\n",
    "$$\\text{CDF}_{\\hat{\\theta}}(x) = \\mathbb{P}(\\hat{\\theta} > x) \n",
    "=\\prod\\limits_{i=1}^n \\mathbb{P}(X_i>x)\n",
    "=\\prod\\limits_{i=1}^n \\text{CDF}_{\\text{Uniform}(0,\\theta)}(x)\n",
    "$$\n",
    "$$=\n",
    "\\left\\{\\begin{array}{l}\n",
    "0 \\text{ if } x<0 \\\\ \n",
    "\\prod\\limits_{i=1}^n \\frac{x}{\\theta} \\text{ if } x\\in[0,\\theta]\\\\\n",
    "1 \\text{ if } x\\in(\\theta,\\infty)\\\\\n",
    "\\end{array}\\right\\}\n",
    "=\n",
    "\\left\\{\\begin{array}{l}\n",
    "0 \\text{ if } x<0 \\\\ \n",
    "\\left( \\frac{x}{\\theta}\\right)^n \\text{ if } x\\in[0,\\theta]\\\\\n",
    "1 \\text{ if } x\\in(\\theta,\\infty)\\\\\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "and thus \n",
    "$$\\text{PDF}_{\\hat{\\theta}}(x) = \n",
    "\\left\\{\\begin{array}{l}\n",
    "0 \\text{ if } x<0 \\\\ \n",
    "\\frac{n}{\\theta} \\left(\\frac{x}\\theta \\right)^{n-1} \\text{ if } x\\in[0,\\theta]\\\\\n",
    "0 \\text{ if } x>\\theta\n",
    "\\end{array}\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4a230-a37c-4596-b238-107f436ab67b",
   "metadata": {},
   "source": [
    "Then \n",
    "$$\\mathbb{E}(\\hat\\theta) = \\int_0^\\theta x \\frac{n}{\\theta^n} x^{n-1} dx \n",
    "= \\frac{n}{n+1} \\frac{\\theta^{n+1} }{\\theta^n} \n",
    "= \\frac{n}{n+1} \\theta.\n",
    "$$\n",
    "Thus, the the estimator $\\hat{\\theta}$ of the parameter $\\theta$ is underbiased with \n",
    "$$\\text{bias} = \\mathbb{E}(\\hat{\\theta}) - \\theta = \\frac{-1}{n+1}\\theta.$$\n",
    "This seems reasonable; \n",
    "- the expected max of a sample is less than the least upper bound of the interval. \n",
    "- the bias goes to zero as $n\\to\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "735c6bf2-2087-417a-97fe-b20213e8eb1b",
   "metadata": {},
   "source": [
    "The standard error of $\\hat \\theta$ is \n",
    "$$\n",
    "\\text{se}(\\hat\\theta) = \\mathbb{E}\\left[  (\\hat \\theta)^2  - \\left(\\mathbb{E}(\\hat \\theta) \\right)^2\\right]\\\\\n",
    "=\\int_0^\\theta x^2 \\frac{n}{\\theta^n} x^{n-1} dx - \\left(   \\frac{n}{n+1} \\right)^2\\theta^2\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777bccf4-0e8b-4e1d-b2e6-4d5d5f49afa4",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\frac{n}{n+2} \\theta^2  - \\left(   \\frac{n}{n+1} \\right)^2 \\theta^2 \\\\\n",
    "= \\left(\\frac{n}{n+2}  -    \\frac{n^2}{(n+1)^2} \\right)^2 \\theta^2\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ff013b-d46a-498b-98de-2487ec493d18",
   "metadata": {},
   "source": [
    "$$\n",
    "= \\left(\\frac{n(n+1)^2 - n^2(n+2)}{(n+2) (n+1)^2} \\right) \\theta^2 \\\\\n",
    "= \\left(\\frac{n }{(n+2) (n+1)^2} \\right) \\theta^2 \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92deb8ad-f12a-4189-b9a2-660a29aeafeb",
   "metadata": {},
   "source": [
    "It is reasonable that the SE goes to zero as $n\\to\\infty$. \n",
    "\n",
    "The mean squared error is then \n",
    "$$\\text{mse}(\\hat\\theta) \n",
    "= \\text{bias}^2 + \\text{se} \n",
    "= \\left( \n",
    "\\frac{1}{(n+1)^2} + \\frac{n}{(n+2)(n+1)^2}\n",
    "\\right) \n",
    "\\theta^2\\\\\n",
    "=\\frac{2}{(n+1)(n+2)}\\theta^2.\n",
    "$$\n",
    "Again, it is reasonable that MSE goes to zero as $n\\to\\infty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbdb21e-ea91-43bc-9505-f0a68c78cc6d",
   "metadata": {},
   "source": [
    "**6.6.3** \n",
    "\n",
    "Problem: Let $X_1,...,X_n \\sim \\text{Uniform}(0,\\theta)$ and let $\\hat{\\theta} = 2\\bar{X}_n$. Find the bias, se, and mse of this estimator of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec92b836-338a-42f3-b289-bb1ca049f756",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "With $\\text{pdf}(x) = \\frac1\\theta$ on its support $[0,\\theta]$ we have\n",
    "$$\n",
    "\\mathbb{E}(X) = \\int_0^\\theta x \\frac1\\theta dx = \\frac12 \\frac{\\theta^2}{\\theta}\n",
    "=\\frac{\\theta}{2}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\mathbb{E}(X^2) = \\int_0^\\theta x^2 \\frac1\\theta dx\n",
    "=\\frac13 \\frac{\\theta^3}{\\theta}=\\frac{\\theta^2}{3}\n",
    "$$\n",
    "and \n",
    "$$\n",
    "\\mathbb{V}(X) = \\mathbb{E}(X^2) - \\left( \\mathbb{E}(X) \\right)^2\n",
    "=\\frac{\\theta^2}{3} -\\frac{\\theta^2}{4} = \\frac{1}{12}\\theta^2.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76162c9-90cb-44a5-aefb-d923158f20f3",
   "metadata": {},
   "source": [
    "Therefore \n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\text{bias}(\\hat{\\theta}) \n",
    "    &= \\mathbb{E}(\\hat{\\theta})  - \\theta \\\\\n",
    "    &= \\mathbb{E}(2\\bar X)  - \\theta \\\\\n",
    "    &= 2 \\frac{\\theta}{2}  - \\theta =0 \n",
    "\\end{array}\n",
    "$$\n",
    "but\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\text{se}(\\hat{\\theta})  \n",
    "    &= \\mathbb{V}(\\hat{\\theta}) \\\\\n",
    "    &= \\mathbb{V}(2\\bar{X}) \\\\\n",
    "    &= \\mathbb{V}\\left(\\frac{2}{n}  \\sum\\limits_{i=1}^n X_i\\right) \\\\\n",
    "    &=\\frac{4}{n^2} \\sum\\limits_{i=1}^n \\mathbb{V}(X_i)\\\\\n",
    "    &=\\frac{4}{n^2} n \\frac{\\theta^2}{12 } \\\\\n",
    "    &=\\frac{\\theta^2}{3n}\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855add5d-ee9b-4f3c-9a94-327ccc97abd6",
   "metadata": {},
   "source": [
    "Of course, since the estimator is unbiased, its $\\text{se}$ is equal to its $\\text{mse}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c566af-f001-4d22-8566-c87e3d4cdf05",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "\n",
    "# Ch 7 Estimating the CDF and Statistical Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deab7f5-2a96-49f6-93b3-61775d5c18ab",
   "metadata": {},
   "source": [
    "When we perform an experiment with a random variable $X$ we often do not know the CDF of $X$. We now turn to infering/estimating the CDF of a random variable from a random sample.\n",
    "\n",
    "**Definition:** The **emperical distribution function** $\\hat{F}_n:\\mathbb{R}\\to [0,1]$ of the random variable $X$ is the distribution that puts weight $1/n$ at each of the $n$ data points in a random sample;\n",
    "$$\n",
    "\\hat{F}_n(x) = \\frac{1}{n} \\sum_{i=1}^n I(x\\geq X_i ).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48551cc-1615-4554-b5a9-e7c2dc065019",
   "metadata": {},
   "source": [
    "The emperical distributionm function is often called the emperical cumulative distribution function (eCDF) to distinguish it from it's differential $d\\hat{F}_n$. I'd call the latter the emperical mass function (eMF) which, for a continuous random variable $X$ is an estimator of a PDF.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df10ffa7-a2ef-4a53-84a3-f9317d7298ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = [1,2,3]\n",
    "ds = [0] + ds[0:-1]\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4dace73c-61f9-4520-9b25-45a6fab122e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8540641-c37e-4f47-b9b1-1c789a7a4382",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a0397a8-c82e-4baa-af85-4c83f4144f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20676140648017916"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate and sort random points and the eCDF from them. \n",
    "def pdf(xs):\n",
    "    # Using f(x) = x\n",
    "    return xs\n",
    "\n",
    "def generate_distribution(n_points=10):\n",
    "    # Generate points according to a uniform distribution on [0,1]\n",
    "    xs = sorted(np.random.rand(n_points))\n",
    "    ecdf = np.asarray([i/n_points for i,x in enumerate(xs)])\n",
    "    max_deltas = max(abs(ecdf - pdf(xs)))\n",
    "    return xs, ecdf, max_deltas\n",
    "\n",
    "def double_points(points, ordinate = False):\n",
    "    # Generate dots to connect for visualization of piecewise constant function.\n",
    "    ds = list()\n",
    "    for p in points:\n",
    "        ds += [p,p]\n",
    "    # If input to this function is ordinate, to make piecewise constant function\n",
    "    # first value is zero and last value is not needed.\n",
    "    if ordinate == True:\n",
    "        ds = [0] + ds[0:-1]\n",
    "    return ds\n",
    "\n",
    "def generate_piecewise_data(n_points):\n",
    "    xs, ecdf, max_deltas = generate_distribution(n_points)\n",
    "    xs_doubled = double_points(xs)    \n",
    "    ecdf_doubled = double_points(ecdf, ordinate=True)\n",
    "    # print(ecdf_doubled[0])\n",
    "    return xs_doubled, ecdf_doubled, max_deltas\n",
    "\n",
    "generate_piecewise_data(10)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3305e48f-924f-4954-ad9d-c5120dd54a4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 2, 2, 3]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "double_points([1,2,3],ordinate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b84d776c-5e80-4802-ad67-2894e03e80ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABCBUlEQVR4nO3deXhU1fnA8e9LSAgJEEggsoTdEBZZZVHrWlQWrYh1K60orVXbaq21Am4VlbrvdeGHC1hXlEUREXEFFBdAMCFhDwQStoSEBBJCljm/P+4kToZJMpPMTTIz7+d5eMjMvTPz3slk3nvOuec9YoxBKaVU6GrW2AEopZRqXJoIlFIqxGkiUEqpEKeJQCmlQpwmAqWUCnGaCJRSKsRpIggBIjJLRO6t53OcKyKZ/orJTiIyV0Rm1uPxR0Wklz9jaozXFpG7ROQV5889RMSISHM/PXc3Z6xh/ni+pkREfi8iyxs7joakicBPRGSXiBxz/nFU/Hu+seMCMMbcZIx50M7XEMvfRWSjiBSKSKaIvC8iA+183foSka9F5HrX+4wxrYwx6X5+nXNFxOHy2cgUkfdEZISvr+1tUjbGPGSMub62/bzh/Hyf7/Lcu52xlvvj+d1eyzg/QxXv1WF/v4bLa52QII0xbxljLrTrNZsiTQT+9RvnH0fFv5sbO6AGPGN7FrgV+DsQC/QBPgAuaqDXDwR7jTGtgNbAacBmYJWIjPb3C/nrzL8RDXb5O2rb2MEEPWOM/vPDP2AXcH41264DvgWeBg4D6cAZzvv3AAeBa132nwvMAj4DjgArgO4u2/s6t+UCW4Ar3R77ErAUKATOd94302WfCcAGoADYAYx13j8F2OR8zXTgRpfHnAtkVnN8iUA5MLKG9+dr4Hq39+Qbl9sG+Cuwzfn6DwK9ge+ccb4HRHh6rMvjT3Z5D2Y6f24HLAGygTznzwnObf9xxl0MHAWed30urC/r/UCYy+tMBJKdPzcDpjvfw0POGGOrOX6P7x/wPLC2muMYD6Q5348s4F9ANHAMcDhjPgp0BmYA84E3ne/X9c773nQ+Vw/nc98A7AX2Abe7fW5meooXeMP5esecrzfV5fmaO/fpDCzG+kxuB/7s8lwznO/N/5zHkgoMr+GzUvke1HS/2+/5XCATuB3r72kfMMVl35bAk0AGkA9847xvt/N5K97L0znxs3kGsMb5uDXAGW6f6wex/r6PAMuB9o39feTrP20RNJxRQDIQB7wNvAuMwPrC+QPwvIi0ctn/91gfsPZYX9pvAYhINFYSeBuIB34HvCgiA1weOwnrS6411ge+koiMxPqDvANoC5yNlcTA+gO6GGiDlRSeFpFhXhzbaKwvjR+92LcmY4FTsb6ApwKzsd6HrsApWMfqq2bAHKA70A3ry+x5AGPM3cAq4GbjoQVnjPkeK5n+2uXuSVjvPVitn0uBc7C+CPOAF3yMbyEwzPl7dfcqVjJujXX8XxpjCoFxOFsXzn97nftPwEoGbXF+Xjw4DytxXwhMd+3uqY4x5hqsL8yKFu9jHnZ7B+uLuDNwOfCQW0vnEqzPfFushGFHt2lHIAboAvwJeEFE2jm3PYH12ToDq8U6FSu5ne3c3tZ5bN+5PqGIxAIfA89h/e0+BXwsInEuu03C+nuJByKwEnZA0UTgXx+IyGGXf3922bbTGDPHWH2q87C+3B4wxhw3xiwHSrCSQoWPjTErjTHHgbuB00WkK9YX9S7nc5UZY34CFmD98VX40BjzrTHGYYwpdovxT8BrxpjPnNuzjDGbAYwxHxtjdhjLCqyzm7O8OO44rDOw+nrUGFNgjEkFNgLLjTHpxph84BNgqK9PaIw5ZIxZYIwpMsYcwUqQ5/jwFO/gTEAi0hrrLP0d57YbgbuNMZnO39MM4HIfu2X2AoL1BemuFOgvIm2MMXnO33VNvjPGfOD8vR6rZp/7jTGFxpgUrARZl+RahfNzeSYwzRhTbIzZALwCXOOy2zfGmKXOz/8bwOBanvYnl7+j57wMpRTrb6rUGLMU6ww/SUSaAX8EbnV+3suNMaudv7PaXARsM8a84fx7ewerS+83LvvMMcZsdb7n7wFDvIy3ydBE4F+XGmPauvx72WXbAZefjwEYY9zvc20R7Kn4wRhzFKvJ3RnrzHaUa8LBOmvu6OmxHnTF6so4gYiME5HvRSTX+bzjsVoktTkEdPJiv9q4vx81vT9eEZEoEfk/EckQkQJgJdDWh7GTt4HLRKQFcBnwkzEmw7mtO7DI5fewCaur6SQfQuyC1TVx2MO232L9DjJEZIWInF7Lc9X0e/e0TwbWZ6q+OgO5zkTr+txdXG7vd/m5CIisJWEOc/k7+ruXcRwyxpS5vU4rrM9wJNV87mvRGetYXNV2bD5/ThubJoKmq2vFD84uo1iss8c9wAq3hNPKGPMXl8fWVFJ2D1bfexXOL7oFWE3ok4w1QLcU62y1Nl8ACSIyvIZ9CoEol9sdq9vRC1WeS0Rqeq7bgSRglDGmDb90BVQcV43ld40xaVh/+OOo2i0E1ns5zu13EWmMyfLhWCZiJZdCD6+9xhgzAavL4QOss82aYvamlHBXl5+7YX2moPbfT03PvReIdbaYXJ/bl/fBG0XU7TOUgzUOdMLnntrfs71YCd+VHcfWqDQRNF3jReRMEYnAGiv4wRizB2uws4+IXCMi4c5/I0Skn5fP+yowRURGi0gzEekiIn2x+jZbYA2qlonIOKx+5FoZY7YBLwLvOC9tjBCRSBG5WkSmO3fbgHVmHSUiJ2N1UdXVz8AAERkiIpFYXTLVaY3Vmjjs7O+9z237AaC26/bfxhoPOBt43+X+WcB/RKQ7gIh0EJEJtQXvvNS2i4jchzWoe5eHfSKc17PHGGNKsQaAKy7VPADEiUhMba/lwb3O38EArH7tec77N2B95mKdifUfbo+r9n1yfi5XAw87f++DsH6/1Y1T1NUGYJKIhInIWLzs4jPGOIDXgKdEpLPz8ac7T36yscYKqvsMLMX6e5skIs1F5CqgP9bfYdDQROBfH0nVeQSL6vFcb2N9aeViDXL9HsDZ/L4QuBrrbGU/8CjWl3itnAO6U7CuYMrnlyuSjmB92b2HNeg5CWtQz1t/xxoAfAGrm2MH1tnuR87tT2ONgxwAXqceXxLGmK3AA8DnWFcZfVPD7s9gXR2SA3wPLHPb/ixWv35eDX3R72BdlfKlMSbH7bGLgeUicsT5/KNqiKWziFRcnbIGGAic6xwj8uQaYJezS+smrIsKcI7pvAOkO7ulfOneWYF1Vc8XwBMur/0GVoLdhTU2NM/tcQ8D9zhfz9Ng6O+wriTaCywC7jPGfOZDXN64Fatv/jDW38MHPjz2X0AK1vuei/U308wYU4Q1bvSt89hOc32QMeYQ1rjc7VhdoFOBi90+BwFPjNGFaZoaEZmLdRXOPY0di1Iq+GmLQCmlQpwmAqWUCnHaNaSUUiFOWwRKKRXiAq4wVfv27U2PHj0aOwyllAoo69atyzHGdPC0LeASQY8ePVi7dm1jh6GUUgFFRNxnSFfSriGllApxmgiUUirEaSJQSqkQF3BjBJ6UlpaSmZlJcbF7xWVlt8jISBISEggPD2/sUJRSdRQUiSAzM5PWrVvTo0cPRLwplqn8wRjDoUOHyMzMpGfPno0djlKqjmzrGhKR10TkoIhsrGa7iMhzIrJdRJK9XAnLo+LiYuLi4jQJNDARIS4uTltiSgU4O8cI5mItPVidcVhL5iViraP6Un1eTJNA49D3XanAZ1siMMasxCr3Wp0JwP+cyyJ+j7VqlD9WuVJKqaBSWu7gxa+38/Oew7Y8f2NeNdSFqsvmZVJ1+bdKInKDiKwVkbXZ2dkNElxd7N+/n6uvvprevXvTv39/xo8fz9atW2nZsiVDhw6lX79+jBw5ktdff73yMXPnzqVDhw4MGTKEIUOGMHny5EY8AqVUU7MxK59LX/iWx5Zt4ZON+2t/QB005mCxpz4FjxXwjDGzgdkAw4cPb5JV8owxTJw4kWuvvZZ3330XgA0bNnDgwAF69+7N+vXrAUhPT+eyyy7D4XAwZcoUAK666iqef/75RotdKdX0FJeW898vtzFrRTrtoiJ46ffDGDfQnk6TxkwEmVRdPzWBX9ZPDThfffUV4eHh3HTTTZX3DRkyhF27dlXZr1evXjz11FPcfvvtlYlAKaUAVr23FYCWI9szdUEy6dmFXHFqAvdc1J+YKPsu0W7MRLAYuFlE3sVa3i/fGLOvvk96/0eppO0tqHdwrvp3bsN9vxlQ4z4bN27k1FNP9er5hg0bxubNmytvz5s3j2++sVZbvPXWWzVBKBWiDuw+wp7cIp5bv43OMS353x9HcnYfj3Xi/Mq2RCAiFeu8theRTKz1d8MBjDGzsBaFHo+1fmoR1jq6IcF9DQjtGlIqdKSuymLrjwcqb5fs3g1AUYdOHM4q5EBYOdde2IM7xiQR3aJhztVtexVjzO9q2W6Av/n7dWs7c7fLgAEDmD9/vlf7rl+/nn79+tkckVKqKdr64wFyMo/SPqEVAOWFhRwvc7C5LJqWkWGcfU53xl/Sp0Fj0lpDfvLrX/+a48eP8/LLL1fet2bNGjIyqlZ+3bVrF//617+45ZZbGjpEpVQT0T6hFRNvH0bkhZ2I3Pou0dvn0eGSbkx/7BzGX9qwSQCCpMREUyAiLFq0iH/84x888sgjREZG0qNHD5555hl27NjB0KFDKS4upnXr1txyyy06DqBUkHLv+nGXk3mUmE5R3PTGOpal7uf55s3o2yGaK8ckNWCUVWki8KPOnTvz3nvvnXD/sWPHqn3Mddddx3XXXWdjVEqphuTe9ePOxISzICeX9QXlTBvbl1OyYjxeS9+QNBEopZSPajrrr0gCE2+vWj5tT24Rdy1KodWapVybncL9HaJpmRFG8ebNRPbtW+1rPfrjowBMGznNfwfgRhOBUkr5qKaz/vYJregz8qTK2+UOw/++28Xjn25BgDnHthBTsJfIztaXf2TfvrS5+OJqX2tz7uZqt/mLJgKllKoDT2f97rYfPMK0BSmsy8jjnD4deOiygZTd8ja06Uv3N/7XQJHWThOBUkp5wbU7qKYxALCKxP3fih0898V2olqE8fRVg7l0SBdEhGpXkG9EmgiUUsoLrt1B7t0/rlIy85m6IJlN+wq4aFAn7r9kAO1btWjgaH2jiUApFdJqu9yzQnWDwBWKS8t55vNtvLwqnbjoCP7vmlMZM6AjAHnz3qNgyRJrv1oGhxuDTiiz2dGjR7nxxhvp3bs3AwYM4Oyzz+aHH34AICwsjCFDhjBgwAAGDx7MU089hcPhAODrr78mJiamsjz1+eefb1uMK1euZNiwYTRv3vyE2dGvv/46iYmJJCYmVimfrVSwqDjTr01NrYAf0g8x7tlVzFqxg8uHJfDZP8+pTAIABUuWUOysL1bb4HBj0BaBza6//np69uzJtm3baNasGenp6WzatAmAli1bsmHDBgAOHjzIpEmTyM/P5/777wfgrLPOYonzLMJO3bp1Y+7cuTzxxBNV7s/NzeX+++9n7dq1iAinnnoql1xyCe3atbM9JqUakjcDv54cKS7lsWVbeOP7DLrGtuSt60fxq5Pbe9w3sm/TGiB2pYnAT958802ee+45SkpKGDVqFC+++CK7du3ihx9+4K233qJZM6vx1atXL3r16nXC4+Pj45k9ezYjRoxgxowZPr/+3LlzWbx4MUVFRezYsYOJEyfy2GOPefXYHj16AFTGWOHTTz/lggsuIDY2FoALLriAZcuW8bvf1VhGSqkmy1M3UG0Dv9X5astB7l6Ywr6CYv74q578a0wfoiIC8ys1MKOuySfTYX+Kf5+z40AY90i1mzdt2sS8efP49ttvCQ8P569//StvvfUWbdu2ZciQIYSFhXn1Mr169cLhcHDw4EEAVq1axZAhQwC44ooruPvuu2t8/IYNG1i/fj0tWrQgKSmJW265ha5du3LVVVexZcuWE/b/5z//WeOKaFlZWXTt+suSEQkJCWRlZXl1LEo1RZ6u/6+py8eTvMISHlySxsL1WSTGt2LBX85gWLfAbiUHXyJoBF988QXr1q1jxIgRgFVSIj4+nmHDfG9qupao9rVraPTo0cTExADQv39/MjIy6Nq1K/PmzfM5DvdYKuhi9SqQuLcAahvwrYkxho9T9nHfh6nkHyvl76MT+dt5vWnR3OVE75Pp1v/OE8eKQWJfBojf3/o+S9OXVt7ekruFpFh76xAFXyKo4czdLsYYrr32Wh5++OEq9+/YsYOff/4Zh8NxQreLJ+np6YSFhREfH185juCLFi1+uUQtLCyMsrIygDq3CBISEvj6668rb2dmZnLuuef6HJdSjcW9BeDr2X+FAwXF3PPBRj5LO8CghBjevH4U/Tq1OXFHt94I1yTg7QDx0vSlVb78k2KTGN9rvM8x+yL4EkEjGD16NBMmTOC2224jPj6e3Nxcjhw5Qu/evRk+fDj33XcfDzzwACLCtm3bSEtLY8KECVWeIzs7m5tuuombb765xrPuRYsW8eOPP56QdGpS1xbBmDFjuOuuu8jLywNg+fLlPr2uUo0pdVUWe7cdpnNi2zq1AMA6yXtv7R5mfryJkjIHd43vyx9/1ZPmYd5fcFmXQeKk2CTmjJ3ja7h1ponAD/r378/MmTO58MILcTgchIeH88ILL9C9e3deeeUVbr/9dk4++WSioqKIi4vj8ccfB6wupCFDhlBaWkrz5s255ppr+Oc//1nja+3YsYM2bTycidTDmjVrmDhxInl5eXz00Ufcd999pKamEhsby7333lvZ5fXvf/+7cuBYqaauokuoLi0AgN2Hipi+MJnVOw4xqmcsj/52ED3aR/szxCZDPPUDN2XDhw83a9eurXLfpk2bQmbFrz/84Q88/fTTdOhg/zqm3gql918FjkVP/gTgc2ug3GGYu3oXT3y6hbBmwp3j+/K7Ed1o1syL8bE5F1n/T/kYgIxrrK5XX1oEU5ZZa5X4u0UgIuuMMcM9bdMWQYB58803GzsEpZq0igHiulwWuvXAEabOT2bDnsP8um88/2YL8vxb7PH2Cfbvtf7/0koATXEWsSc6s1gpFVRck4C33UIlZQ6e/XwbFz23it25RTx79RBevXY48sXyyhnBddEUZxF7oi0CpVRQcG8JeNsl9POew0xbkMzm/Ue4ZHBn7vtNf+JcisT5NNhb2TXUNGcQV0cTgVIqKPjaEjhWUs7Tn2/llVXpxLeO5JXJwzm/f90GlgOdJgKlVNDwtiXw3Y5D3LkwmV2HivjdyG7cOb4vbSLDGyDCpkkTgVIq4NS1ZlBBcSmPfLKZt3/YTfe4KN7+8yjO6O25SFzevPcoWrOGKOfl0/7kPnvYVUPMJHang8U2C4Qy1E899RT9+/dn0KBBjB49moyMX9ZQ0jLUqinyVDq6ti6hLzYd4MKnVvLuj7u54exeLLv17GqTAFC5foAdg70Vs4c9aYiZxO60RWCzQChDPXToUNauXUtUVBQvvfQSU6dOZd68eVqGWjUJNZ39e9MNdOjoce7/KI3FP+8l6aTWzLrmVIZ0bevVa0eNGEG7q66sS9i1aujZwzXRFoGfvPnmm4wcOZIhQ4Zw4403Ul5ezo4dO/jhhx+YOXNmlTLUF1100QmPryhD/fzzz3ss9labuXPnctlllzF27FgSExOZOnWq148977zziIqKAuC0004jMzMTqFqGul27dpVlqJVqSHU5+werPMSHG7K44OmVfLJxH7ed34ePbjnT6yQQSoKuRfDoj4+yObfu1/160je2L9NGTqt2ezCVoX711VcZN24coGWoVdPha8XQffnHuGfRRr7YfJDBXdvy2G8HkdSxtY0RBragSwSNIVjKUL/55pusXbuWFStWnBBLBS1DrZoyh8Pw7po9PLx0E6UOB/dc1I8pv+pJmFt5CNc1hKsTKLOC/SHoEkFNZ+52CYYy1J9//jn/+c9/WLFiReXzaBlqFUh25RQyfWEy36fnckbvOB6+bCDd4zwXifNmjYBAmRXsD0GXCBpDoJehXr9+PTfeeCPLli0jPj6+8n4tQ60aQ3WLyVSnrNzBa9/u5MnlW4kIa8Yjlw3kqhFda229NuU1hBuarYlARMYCzwJhwCvGmEfctscAbwLdnLE8YYxpGsPoPgj0MtR33HEHR48e5YorrgCsxewXL16sZahVo/BlMZnN+wuYNj+ZnzPzOb/fScy89BQ6xkQ2ZLhBwbYy1CISBmwFLgAygTXA74wxaS773AXEGGOmiUgHYAvQ0RhTUt3zahlqLUOtgps35aOPl5Xzwlc7ePGr7cS0DGfGJQO4eFAnr8ew6lIe2ituZairY1ep6Zo0VhnqkcB2Y0y6M4h3gQlAmss+Bmgt1m+vFZALlNkYU8DTMtQqmNRlhvD63XlMW5DM1gNHeazHOiaGf0f4T83gJ8/7520ooCCt6uWnxQdLiIyP+OWL24P3OcpSKfT+YABKCyEiGpxf9NVpjNnDNbFzHkEXqFLGO9N5n6vngX7AXiAFuNUY43B/IhG5QUTWisja7Oxsu+JVSjUwX+YIFJWU8eCSNC57aTVHist47brhXNniB8IPptb4GgVpRyk+WLWTITI+gjb9ay5HsVQK2UK1nROeRURDdO2t9caYPVwTO1sEntpo7v1QY4ANwK+B3sBnIrLKGFNQ5UHGzAZmg9U15P9QlVINzZc1hVdvz2H6whR25xbxh9O6MW1sX1pHhsN3QMeBNXfFfDmZyI516AZaNoUkGrb7prHYmQgyga4utxOwzvxdTQEeMdZAxXYR2Qn0BX60MS6lVBPgzZrC+cdKeXjpJt5ds4ee7aOZd8NpjOoV11Ahhgw7E8EaIFFEegJZwNXAJLd9dgOjgVUichKQBKTbGJNSqgnpnNiWAWe59xhblqfu554PNpJz9Dg3ntOL287vQ2S4d7P0lW9sSwTGmDIRuRn4FOvy0deMMakicpNz+yzgQWCuiKRgdSVNM8bk2BWTUqrheBoIdlXdoHDO0ePMWJzKkuR99O3YmleuHc6ghLZ1isHOUtLBxNaic8aYpcaYPsaY3saY/zjvm+VMAhhj9hpjLjTGDDTGnGKMCbpLYgKhDHWF+fPnIyK4Xp6rZahVXXkaCHblPihsjGHR+kzOf2oFy1MPcPsFVpG4uiYBsLeUdDDRmcU2C4Qy1ABHjhzhueeeY9SoUZX3aRlqVZ3azvbBt1LRew8f4+5FKXy1JZuh3awicYkn+adInJ2lpIOFlqH2k0AuQw1w7733MnXqVCIjf5mVqWWoVXVqO9sH70pFOxyGN77P4IKnVvB9ei73/aY/8286w29JQHkn6FoE+x96iOOb/FuGukW/vnS8665qtwd6Ger169ezZ88eLr74Yp544onK7VqGWtXE19LQ7tKzjzJ9QQo/7srlzJPb8/BlA+kaG+XHCJW3gi4RNIZALkPtcDi47bbbmDt3bo2xVNAy1KHLtTvIm/WBq1NW7uCVb3by9GdbadG8GY9dPogrTk3wy2fLvbx0XUpJV6wn3NRm/9op6BJBTWfudgnkMtQTJkxg48aNleWl9+/fzyWXXMLixYu1DLWqwrUYnDfdPp6k7S1g6oKf2ZhVwJgBJ/HghFOIb+O/InHu5aXrUkraNQk0pdm/dgq6RNAYAr0MdU7OL1fsnnvuuTzxxBMMHz6cXr16aRlqBfg2C9iT42XlPP/ldl76egdto8J58ffDGHdKR1tamP4oL92U1hNuCJoI/CDQy1BXR8tQqwrezAKuzrqMXKYtSGH7waP8dlgC91zUj3bREf4OUdWDbWWo7aJlqLUMtWp43pSGdld4vIzHP93C69/tonNMSx66bCDn9PHz59at7LM/yks3RonohtBYZaiVDbQMtbJbXUpDu1u1LZs7F6aQmXeMa0/vzh1j+9Kqhb1fNzqLuO40ESilqnBfIQy8mxMAkF9UysyP03h/XSa9OkTz/k2nM6JHw3Qn6iziutNEoFQIq+ns39dB4WUb93PvhxvJLSzhr+f25u+jExu8SJzOIq4bTQRKhbD6nP1XOHikmBmLU1masp/+ndow57oRnNIlxo5wlU00ESgV4uo6Q9gYw4KfsnhwSRrHSsu5Y0wSN5zdi/AwrVwTaDQRKBUi/DEIXCEzr4i7Fm1k5dZshndvxyO/HcTJ8d4/j/sMYACO7IdCH5eiLXGuEfzlZJ9nEVfMIHYXSjOKK2jqtlkglKHevXs35513HkOHDmXQoEEsXfrLH4eWoQ4evqwPXB2Hw/D66l1c+PRK1u7K5f5LBvDejaf7lATglxnAVRRmW1/svnBZI9jXWcQVM4jdhdKM4graIrBZIJShnjlzJldeeSV/+ctfSEtLY/z48ezatUvLUAeh+hSK25F9lGnzk1mbkcfZfTrw0MRTSGhX9yJxJ8wAdpsT0BBCbQZxdbRF4CeBXIZaRCgoKAAgPz+fzp07A1qGWllKyx288NV2xj27im0Hj/LEFYN5fcqIeiUB1bQEXYtg1XtbydlTc510X7Xv2oqzruxT7fZAL0M9Y8YMLrzwQv773/9SWFjI559/DmgZ6kDmr/GAjVn5TJ2fTNq+AsYP7MiMSwYQ39r3InH+qAqq7BN0iaAxBHIZaoB33nmH6667jttvv53vvvuOa665ho0bN2oZ6gBW38tCi0vLefaLbcxemU5sdASz/jCMsad0qnM8/qgKquwTdImgpjN3uwRyGerJkyfz6quvVnb5nH766RQXF5OTk6NlqANcXccD1uzKZdr8ZNJzCrni1ATuuag/MVHh9Y7HH1VBlT10jMAPRo8ezfz58yu7dHJzc8nIyKhShrri7Hrbtm18+OGHJzyHL2Wo77zzTp/imzdvHhs2bDjh3+TJVoGubt268cUXXwBWN1dxcTEdOnRgzJgxLF++nLy8PPLy8li+fDljxozx6bVVw0pdlcWiJ3+qdRlJT44eL+PfH27kilnfUVLu4I0/jeTxKwb7JQmopi3oWgSNIdDLUD/55JP8+c9/5umnn0ZEmDt3LiKiZagDkGuXkC+Xha7Yms1dC1PYm3+M687owR1jkoi2uUicajq0DHWA0TLUqoI/6gQdLirhgSVpLPwpi94donns8kGc2v3EZF/d5Ct3g1cfoN+6nBPuj88q4mCXKN69ZUD1D96fYv3fcaBXsddXxcSxULl8VMtQBxEtQ60q1GdA2BjDJxv38+8PN3K4qJSbzzuZm399crVF4rxdw7ffupzKL31XB7tEsenU9l4cVcMJxYlj1dFEoFQAq8uA8MGCYu79cCOfph7glC5teP2PIxnQufYicd6cPWe8NRliYaiHQeFaR5cqJpSFyBl6UxI0icAYo5c2NoJA61oMFq5rCHvLGMP76zKZuSSN42UOpo/ry/Vn9qS5FokLeUGRCCIjIzl06BBxcXGaDBqQMYZDhw4RGen7BCNVP76uIbwnt4g7F6bwzfYcRvaI5ZHfDqRXB9+LzangFBSJICEhgczMTLKzfaxcqOotMjKShISExg4jZFQMEOdkHqVzYlsGnNWlxv3LHYb/fbeLx5ZtoZnAg5eewu9HdqNZM/+eMFXMHNYZw4EpKBJBeHg4PXv2bOwwlLKdL5eHbjtwhGkLkvlp92HOTerAfyYOpEvblrbE5ZoEdMZw4AmKRKBUKKltgLi03MGsr3fw3y+3E90ijKevGsylQ7rY3m2qM4cDl62JQETGAs8CYcArxphHPOxzLvAMEA7kGGPOsTMmpYJZSmY+d8z/mc37j3DxoE7MuGQA7Vu1qP2BKqTZlghEJAx4AbgAyATWiMhiY0yayz5tgReBscaY3SISb1c8SgWz4tJynv58Ky+vTKd9qxbMvuZULhzQsbHDUgHCzhbBSGC7MSYdQETeBSYAaS77TAIWGmN2AxhjDtoYj1JNkqcZwtXxVEr6h/RDTF+Yws6cQu41Wzg3bT3NNwsZnp6gmuUgsynnEOXVvu4lGKIQMp4c6nF78cESIuMjfpkLUBf7UxpsVrGqys4LiLsAe1xuZzrvc9UHaCciX4vIOhGZ7OmJROQGEVkrImv1yiAVbDwtIVkd10HiI8Wl3PNBClfN/p4yh4O3rh/F+Xs3ULb1xEqzlapZDvIQ5RRR/ZyQKIQ4ql9XIzI+gjb963k5aseBMPDy+j2HqhM7WwSeRqbcP2nNgVOB0UBL4DsR+d4Ys7XKg4yZDcwGq9aQDbEq1ah8nSH81eaD3LUohf0FxfzpzJ7cfmEfoiKak0Etg7bVLAc5Y9kUa7PO6g1JdiaCTKCry+0EYK+HfXKMMYVAoYisBAYDW1EqBPg6Qzi3sIQHPkrlgw17SYxvxYK/nMGwbrqGtKofrxOBcyD3V0Bn4BiwEVhrjHFU85A1QKKI9ASygKuxxgRcfQg8LyLNgQhgFPC0T0egVADzdoawMYYlyfuYsTiV/GOl3Do6kb+e15sWzb1bBlWpmtSaCETkPGA6EAusBw4CkcClQG8RmQ88aYwpcH2cMaZMRG4GPsW6fPQ1Y0yqiNzk3D7LGLNJRJYByYAD6xLTjX47OqWaGPeBYW9mCB8oKObuRRv5fNMBBiXE8NafR9G3o7Umha4FrPzBmxbBeODPFVf2uHKeyV+MdYnoAvftxpilwFK3+2a53X4ceNyHmJUKWO6lo2uaIWyMYd6aPfxn6SZKyhzcPb4fU37Vo0qROF0LWPlDrYnAGHNHDdvKgA/8GZBSwc6bgeGMQ4XcuTCF1TsOMapnLI/+dhA92kd73Fdn9Kr68mWM4A3gZmNMvvN2D+BVY8xom2JTKmi4FotznwfgqtxhmPPtTp5YvoXmzZrx0MSBXD2iq9+LxCnlyperhr4BfhCRf2LNB7gDuN2WqJQKMt4Ui9uy/whTFyTz857DjO4bz8yJp9Apxp4icUq58joRGGP+T0RSga+AHGCoMWa/bZEpFSRcLxH11CVUUubgxa+388JX22kdGc6zVw/hksGdEZETBoPd+TI4/P7W91kqzoFq57yBCt4sQ6mCly9dQ9cA9wKTgUHAUhGZYoz52a7glAoGNV0i+vOew0ydn8yWA0eYMKQz/764P3EuReJqq/Hvy+Dw0vSlbKGEJCJO2Kbr94Y2X7qGfguc6awH9I6ILALmAp6LjyilKrlfInqspJynPtvCq9/sJL51JK9MHs75/T13GflzMDiJCOaYk3RdYFWFL11Dl7rd/lFERvk9IqWaOF+KxMGJheJW78jhzoUpZBwqYtKobkwf15c2keF2hKqUV7yZUHYP8KIxJtd9mzGmRER+DUQZY6rvyFQqiHhz9Y+rigHiguJSHl66mXd+3E33uCje/vMozujd3uZolaqdNy2CFOAjESkGfgKysWYWJwJDgM+Bh+wKUKnG5mk2sK9F4j5PO8Afn1pB9pHj3HB2L247vw8tI2ouD5E37z2K1qwhasSIOseulDe8mVD2IfChiCRi1RrqBBQAbwI3GGOO2RuiUo3Ll9nA7g4dPc79H6Wx+Oe99O3YmtnXDGdw17ZePbbiaiGdKazs5k3XUHNjTJkxZhuwrQFiUqrJ8bUFYIxh8c97mbE4laPHy7jt/D785dzeRDT3bQmQqBEjaHfVlb6Gq5RPvPlU/ljxg4j818ZYlGpyKuYA+GJf/jGuf30tt767ge5x0Xz897O49fxEn5OAUg3FmzEC17ntv7IrEKWaIm/LRAM4HIZ31uzm4aWbKXM4uOeifkz5VU/CtDyEauK8SQS6IpgKKa6Dw96UiQbYmVPI9AXJ/LAzlzN6x/HIZYPoFhdVZZ/3t77P0vSl1TzDia7O3Qw4Vw+rZq1hX2yhhKSSUtArVZUbbxJBXxFJxmoZ9Hb+jPO2McYMsi06pRqB6+BwbQPDZeUOXvt2J08u30pE82Y8+tuBXDm8KyIntgKWpi+teymHirWGIzxXIPVGEhGMD2+n6wKrE3iTCPrZHoVSTYw3g8Ob9hUwbUEyyZn5XND/JGZeegontYms8TFJsUlerwuc8dZkwLmO8JyLrDP56z6u+UFK1YE3l49mAIhIW6y5AwBbK8pRKxUsvC0VfbysnBe+2sGLX20npmU4z08aykUDO3lsBSgVCLy5fDQCmI21NOVOrC6h7s5aQzcZY0psjVCpBuJNqeifducxbX4y2w4eZeLQLvz74v60iz6xiJtSgcSbrqF7sBqlXY0xRwBEpDXwAlY10nvtC08p+/gyY7iopIwnPt3KnNU76dgmkjnXjeC8vvENGa5StvEmEVwGjDTGFFXcYYw5IiJ/Bb5HE4EKUN7OGP52ew7TFyazJ/cY15zWnaljk2itReJUEPEmEThck0AFY8xREdFLS1XAcR8LqG5QOP9YKQ99vIl5a/fQs3008244jVG94ho4WqXs59U8AhFpR9WJZRUcfo5HKdt5MxawPHU/93ywkUOFJdx0Tm/+cX4ikeE1F4lTKlB5kwhigHV4TgTaIlABqbqWQPaR48z4KJWPk/fRr1MbXr12BAMTYhohQqUajjeXj/ZogDiUsl1Nl4caY1i0PosHlqRRdLycf13YhxvP6U14WPX1gTzNFB68+gD91uV43P+SsmNENW9ZOT+gNr6sR6xUfXhz+egYoLUxZr7b/ZOAbGPMZ3YFp5Q/VdcllHX4GHcvSuHrLdkM69aWxy4fxMnxrWt9Pk8zhfutyyE+q4iDXaJO2D+qeUviWno/xuDLesRK1Yc3XUP3A7/xcP+XwCJAE4FqcjwtJ+k+OOxwGN76IYNHPtmMw8B9v+nP5NN7+FQkzn2mcMZbkyEWhvppjWGlGoI3iSDKGHNCtStjzH4RqXvhE6Vs5KkLyLUlkJ59lOkLUvhxVy5nJbbnoYkD6Rp74lm8UqHAm0QQWbE4jeudIhIOtLQnLKXqz9OAcFm5g5e+3sHTn28lsnkzHr98EJefmqDlIVRI8yYRLAReFpGbjTGFAM6WwHPObUo1GTUNCKfuzWfagmQ2ZhUwZsBJPDjhFOJrKRLnC11jWAUqb0tMzAQyRCTDeV834FV0VrFqYjwNCBeXlvPfL7cxa0U67aIieOn3wxg3sJPfX1vXGFaBypvLR8uA6SJyP3Cy8+7tumi9agpqqxe0LiOXqfOT2ZFdyG+HJXDvxf1oG2VfkThdY1gFoloXURWRqQDOL/6+xpiUiiQgIg/V8tixIrJFRLaLyPQa9hshIuUioitmKJ9UtAAqVLQECo+XMWNxKpfP+o7iUgev/3EkT1452NYkoFSg8qZr6GrgMefPdwLvu2wbC9zl6UEiEoZVofQCIBNYIyKLjTFpHvZ7FPjUt9CVsrgPCq/cms0NT69kb/4xJp/WnTvG9qVVC28+6kqFJl8Xr3e/tKKmSy1GYnUhpQOIyLvABCDNbb9bgAWAjrCFqrVzIGV+7fu5ST04kL07L6Rz6z0w517KHA5mF+XyRXgxndsJvePD2J0n3PKODTHjXAOYCJhzEXkbCihak0NU10hrNTF/258CHQf6/3mVwouuIarWE3KvLVRTraEuwB6X25nO+yqJSBdgIjCrpgBE5AYRWSsia7Oz67eAt2qCUuZbX3Q+2ppjraLap/0mcguP83NmPl+EF5PVwtCqRXOfJobVRRIRjDfWVJqCNKt7qk3/6lc2q5eOA3WtYWUbb1oEg0WkAOvsv6XzZ5y3a7r2zpsidc8A04wx5TVdx22MmY21ShrDhw/XQndBJHVVFlvTrgSuhAjfznhzyo7SoVcUz3e+gk82nkX/Tm1o1Wk2/Vo093pdYL/5cjJRHaHdszqjWAUeb64aqmvt3Uygq8vtBGCv2z7DgXedSaA9MF5EyowxH9TxNVWA2frjAXKKOtA+yveWnokJZ8GhPNYXlDF1bBJ/PqsXN3z2mg1RKhXc7BxBWwMkikhPIAtr0HmS6w7GmJ4VP4vIXGCJJoHQ0z4qm4n934Mp13q1/57cIu5alMKq7FxG9GzHJ78dRO8ONnXJKBUCbEsExpgyEbkZ62qgMOA1Y0yqiNzk3F7juIAKblVmAHv5KXQ4DP/7bhePfboFAR6YMIA/jOpOMxvHAvLmvVc5UawmWjJaBTJbr6kzxiwFlrrd5zEBGGOuszMW1bRUmQFctqnW/bcfPMr0Bcmszcjj7D4deGjiKSS0s79IXMGSJV59yWvJaBXI9OJq1eBSV2Wxd9thOie2ta7/n1N9pZLScgezV6bz7OfbaBkRxpNXDOayYV0atEhcZN++dNey0iqIaSJQDa6iJER16wVX2JiVz9T5yaTtK2D8wI7cf8kpdGjdoiFCVCqkaCJQjaJzYlsGnNXF47bi0nKe/WIbs1emExsdwaw/nMrYUzo2cIRKhQ5NBKrePK0GVhNPJaIrrNmVy7T5yaTnFHLl8ATuHt+fmKjwGp/Pde1g96UjfeU+OKyDwCoUeDOzWKkauRd+q437msEA5cbw7w83csWs7ygpd/Dmn0bx2OWDa00C8MvawWAtHTm+13jfDsBFxeBwBR0EVqFAWwSqXk4Y+K2DvGMl7Mwu5I1tGUz5VQ/+dWES0T4WiXNfO7g+dHBYhRpNBKpevB349SSvsIQHl6Rx5f4jtAwPY/5NZ3Bq93b+DlEpVQtNBKreahr49cQYw9KU/dy3eCOHi0q5rX1LurRtSTNNAko1Ck0Eymeug8M1Dfx6crCgmHs+2MjytAMM7BLD//44iq6fvmBLnN7OCnalg8MqFGkiUD5znRXsaeDXE2MM76/N5MGP0ygpc3DnuL786cyeNA+z73oFb2cFu9LBYRWKNBEor1WpD+S2KlhN9uQWcefCFL7ZnsPInrE8ctlAejVQkTgd+FWqdpoIlNeq1AfyohVQ7jC8vnoXj3+6hbBmwsxLT2HSyG62FolTSvlOE4HyibctgW0HjjB1QTLrdx/m3KQOPDRxIJ3btmyACJVSvtJEoGrl3iVUwXVGbwVj4PDB3YQdyyGsGZyZGIZIM+7+oIYXKC2EiGhYNsWnuAavPkC/dTlcUnaMqOYtyXhrcpXtOvCrlHd0ZrGqVXVdQq4zegEKj5eRkpVP2LEcWslxWrVoTrg3g8ER0RDdwee4+q3LIT6riKjmLYlrGXfCdh34Vco72iJQQM31gmoaHE6KTeKl0a/w9Gdbefn7dDq0bsHLMY8SGxUBUz62NeaMtyZDLAzVwWCl6kVbBAqouV5QTYPDBcWljH1mJf+3Mp2rRnRl+W3nWElAKRUwtEWgKvlySeiR4lJ25hRyoKCYDgbevn4UZ5zc3uYIlVJ20ESgfPbl5gPcvWgj+W2L6RTTkiXXn0VUhP0fJS0RrZQ9NBEor+UWlvDAR6l8sGEvfU5qRULnGFq1aN4gSQBOnCmsg8FK+YcmAlWllLQnxhg+St7HjMWpHCku5dbRifztvJO58fO5DRon6ExhpeygiUDVWEp6f75VJO7zTQcYnBDDo5ePom/HNg0dolLKRpoIgpCniV4V2u9KJG5Pjyr3tcyP5VhcLk8UvgHLfrn/4JHj7D5UiAPoOzSKdjGRPLrhl+31XRbSF3nz3qNozRqiRoxokNdTKpTo5aNByH2il6u4PT1omR9b5b5jMbkc6rqr8nZxaTlp+wpIzz5KVIvmDOoSQ6eYSNwrBNV3WUhfVAwS65iAUv6nLYIgVd3SjYtSf4JYmHj72BO2lTsMc77dyRPLtxDerBn3ju/H1SO6NpkicVEjRtDuqisbOwylgo4mgiDVflcii5786YT7q1tIZst+q0jcz3sOM7pvPDMnnkKnGC0Sp1Qo0EQQpOL29CCn6MQvffdZwiVlDl78ejsvfLWd1pHhPPe7ofxmUCdEmkYrQCllP00EQay2mcIb9hxm2vxkthw4woQhnbnvNwOIjW5a5SEqJpHp5DGl7KOJIAQdKynnyeVbeO3bncS3juTVa4czul/tC800BtckoAPFStlDE0GIWb0jh+kLUtidW8SkUd2YPq4vbSLDGzusGukkMqXsZevloyIyVkS2iMh2EZnuYfvvRSTZ+W+1iAy2M55Q0X5XIq0PdaxyX0FxKXcuTGbSyz8gAu/8+TQemjiwyScBpZT9bGsRiEgY8AJwAZAJrBGRxcaYNJfddgLnGGPyRGQcMBsYZVdMoaJiwljFoPDnaQe4+4MUso8c58aze/GP8/vQMiKsESNUSjUldnYNjQS2G2PSAUTkXWACUJkIjDGrXfb/HkiwMZ6AU9MM4eq035VIj0OncSRuPx2H/opb3lnPRz/vpW/H1rw8eTiDEtraEyzA2jmQMh/2p0DHgSdUC60LHSRWyn52dg11Afa43M503ledPwGfeNogIjeIyFoRWZudne3HEJu2mmYIV6eiNVDevRnnP7WCZRv38c8L+rD45jPtTQJQJQkw8PLKgd760EFipexnZ4vA04XoxuOOIudhJYIzPW03xszG6jZi+PDhHp8jWFU3Q7g6835ey86SQl5Ob82QrtE8dvkg+pzU2sYI3XQc6LJE5Vc60KtUALAzEWQCXV1uJwB73XcSkUHAK8A4Y8whG+MJag6H4e0fd5OWeRiAe6/qz3Vn9CCsiZSHUEo1XXYmgjVAooj0BLKAq4FJrjuISDdgIXCNMWarjbEEtZ05hUxfkMwPO3O5oUU0vTpEc/WZPRs7LKVUgLAtERhjykTkZuBTIAx4zRiTKiI3ObfPAv4NxAEvOksalBljhtsVU7ApK3fw6jc7+fSj7fQ7HsbouFgkv5QWzf1/RZBXA7/7nQ2+LycDOtCrVKCwdUKZMWYpsNTtvlkuP18PXG9nDMEqbW8B0xYkk5KVz1+ataJdGHRo3QJat/C4wEx91aXMgw70KhUYdGZxgDleVs7zX27npa930DYqnBcmDaPks30ANdYV8odaB37nXGT9P0UHh5UKJJoIAsi6jDymLUhm+8GjXDa0C/de3J920REsciYCpZSqC00EAaCopIzHP93C3NW76NQmkjlTRnBeUnxjh6WUChKaCJqo97e+z9oDa0lsM5gLn15JZt4xrjmtO1PHJrF7zUEWLfll0ZnqFpupi+oGhXXgV6ngpWsWN1GLt1uTslK29CI8rBnv3Xg6D156Cq0jw9n64wFyMo9W7uu+2Ex9VDcbWAd+lQpe2iJogj5N3U9y5mHKy3tx/ZBJ3Do6kcjwqpeE1rboTH3obGClQosmgiYk+8hxZixO5eOUfcQlNiPppGimjf2lOyZ1VVZla8BfXUFKKaWJoAkwxrDwpyweWJLGsZJy7hiTxJriGNyXDXZNAnbMFVBKhSZNBI0s6/Ax7lqYwoqt2Qzr1pbHLh/EyfGtmbLM2l7RCoBfBoX92SXkPjisg8JKhR5NBI3E4TC8+UMGj36yGQPM+E1/rjn9xCJxrq0AO1oC7jOGdVBYqdCjiaAR7Mg+yvQFyazZlcdZie15aOJAusZGVbu/nQPDoIPDSoU6TQQNqLTcwcur0nnm821ENm/G45cP4vJTExC3wYDUVVkkrboAgJwiHRhWStlLE0ED2ZiVz7QFyaTuLWDsgI48cOkA4ltHetx3648HaJkfy7GYXB0YVkrZThOBDVzXGnYYQ1beMfbmF9O8hTB4RDTHoyOY9u2Jj2u/K5G4PT1omR/Loegs9pz1DdPHTjpxRx/UVj7ab4PDa+dAxjfQ3eMic0qpJkxnFtugYq3hI8VlpGTlk3X4GO1bRTC4a1tioyOqfVxFEjgWk8uxngcY32t8vWOpbd1gvw0Op8y3/h94ef2fSynVoLRFYINyh6GFSWDdD1fTOaYlT182kHP6dKj1cYtSf4JYmHj7WL/G02CDwd3PhOFT7H8dpZRfaSLwsxVbs0nOzKekvJxrT+/BHWOSiG5R/dvsaZ6AUko1JE0EfnK4qIQHl2xiwU+ZxJ4M/eNjmHHJgFofZ/c8AaWUqo0mAj/4JGUf936YSl5RCX87rzcbHTE0c68PQdWz/wp2zBZWSilf6GBxPRwsKOamN9bxl7d+4qQ2LVh886+4Y0xfj0kAOKF8NPi3hLRSStWFtgjqwBjD/HWZPLgkjeIyB9PG9uX6s3oSHlZ7XtWzf6VUU6OJwEd7cou4a1EKq7blMKJHO/7WrSN56w6zZN2Gyn2Scq1ZwYtSf6ryWB0MVko1Rdo15KVyh2HutzsZ88xKfsrI48EJA5h3w+nkbTp8QndPdbQbSCnVFGmLwAtfLd3Bt1/s5khxGddERdKzfTQtVufy4ercyrP8st/sqJxNvCV3C0mxSfWeFeytmmYPa1lppVRttEVQg9JyB89/uY3lS3cSVeTg5PhW9O3YhhbNf1k2suIsv2I2MUBSbJJfZgV7q6bZw1pWWilVG20RVGNjVj53zE9m074C/hrdioS4aK6cOrz6ByyzEsCcsXMaLkgXWkpaKVVXmgjcFJeW88IrG8hOzWN4mHB5XByOvBKvrghSSqlApInAxY87c5m+IJkRO0tJkOZ0TGhD82YC0RE6yKuUClqaCIB1X+5m5WcZ7C8o5szwMDo1D6djtzZ+v96/tpLQdaUDwkqp+gj5RPDVloN89eE2YkqgU7tIusZG0UzElhaA+/rA/qIDwkqp+gjZRJBXWMKDS9LY/v1+xhyPoHW3Vky+a6Ttr6uDukqppsbWEVARGSsiW0Rku4hM97BdROQ55/ZkEbG99oIxhiXJezn/qRUs/nkvF0RbM31PPauL3S+tlFJNkm2JQETCgBeAcUB/4Hci0t9tt3FAovPfDcBLdsUDcKCgmBvfWMfNb6+nc9uWfHTLmSS0i6JzYlsGaCJQSoUoO7uGRgLbjTHpACLyLjABSHPZZwLwP2OMAb4XkbYi0skYs8/fwXy1+SB/f3c9JWUOzhz5Dc1b7uexr9JJ2v8HAN74w7XEH3DU+fkvwRCFkPHk0Gr3KT5YQmR8BMy5qM6v02TtT4GOAxs7CqVUHdjZNdQF2ONyO9N5n6/7ICI3iMhaEVmbnZ1dp2B6to9mWLd2LPvH2QxMaEtFpeii6L0URe+t03O6ikKII6zGfSLjI2jTP0iLznUcqOsVKxWg7GwReCrKb+qwD8aY2cBsgOHDh5+w3Rs92kfz+h+tweBp7ad52OO+ujytUkoFPDtbBJlAV5fbCYD7qbc3+yillLKRnYlgDZAoIj1FJAK4Gljsts9iYLLz6qHTgHw7xgeUUkpVz7auIWNMmYjcDHwKhAGvGWNSReQm5/ZZwFJgPLAdKAKm2BWPUkopz2ydUGaMWYr1Ze963yyXnw3wNztjUEopVTMtqamUUiFOE4FSSoU4TQRKKRXiNBEopVSIE2u8NnCISDaQUceHtwdy/BhOINBjDg16zKGhPsfc3RjTwdOGgEsE9SEia40xNSw8HHz0mEODHnNosOuYtWtIKaVCnCYCpZQKcaGWCGY3dgCNQI85NOgxhwZbjjmkxgiUUkqdKNRaBEoppdxoIlBKqRAXlIlARMaKyBYR2S4i0z1sFxF5zrk9WUSGNUac/uTFMf/eeazJIrJaRAY3Rpz+VNsxu+w3QkTKRSTgl1Dz5phF5FwR2SAiqSKyoqFj9DcvPtsxIvKRiPzsPOaArmIsIq+JyEER2VjNdv9/fxljguofVsnrHUAvIAL4Gejvts944BOsFdJOA35o7Lgb4JjPANo5fx4XCsfsst+XWFVwL2/suBvg99wWa13wbs7b8Y0ddwMc813Ao86fOwC5QERjx16PYz4bGAZsrGa737+/grFFMBLYboxJN8aUAO8CE9z2mQD8z1i+B9qKSKeGDtSPaj1mY8xqY0ye8+b3WKvBBTJvfs8AtwALgIMNGZxNvDnmScBCY8xuAGNMoB+3N8dsgNYiIkArrERQ1rBh+o8xZiXWMVTH799fwZgIugB7XG5nOu/zdZ9A4uvx/AnrjCKQ1XrMItIFmAjMIjh483vuA7QTka9FZJ2ITG6w6OzhzTE/D/TDWuY2BbjVGONomPAahd+/v2xdmKaRiIf73K+R9WafQOL18YjIeViJ4ExbI7KfN8f8DDDNGFNunSwGPG+OuTlwKjAaaAl8JyLfG2O22h2cTbw55jHABuDXQG/gMxFZZYwpsDm2xuL3769gTASZQFeX2wlYZwq+7hNIvDoeERkEvAKMM8YcaqDY7OLNMQ8H3nUmgfbAeBEpM8Z80CAR+p+3n+0cY0whUCgiK4HBQKAmAm+OeQrwiLE60LeLyE6gL/Bjw4TY4Pz+/RWMXUNrgEQR6SkiEcDVwGK3fRYDk52j76cB+caYfQ0dqB/Veswi0g1YCFwTwGeHrmo9ZmNMT2NMD2NMD2A+8NcATgLg3Wf7Q+AsEWkuIlHAKGBTA8fpT94c826sFhAichKQBKQ3aJQNy+/fX0HXIjDGlInIzcCnWFccvGaMSRWRm5zbZ2FdQTIe2A4UYZ1RBCwvj/nfQBzwovMMucwEcOVGL485qHhzzMaYTSKyDEgGHMArxhiPlyEGAi9/zw8Cc0UkBavbZJoxJmDLU4vIO8C5QHsRyQTuA8LBvu8vLTGhlFIhLhi7hpRSSvlAE4FSSoU4TQRKKRXiNBEopVSI00SglFIhThOBUkqFOE0ESikV4jQRKFVPzvUOkkUkUkSinTXxT2nsuJTylk4oU8oPRGQmEIlV6C3TGPNwI4eklNc0ESjlB846OGuAYuAMY0x5I4eklNe0a0gp/4jFWhSlNVbLQKmAoS0CpfxARBZjrZ7VE+hkjLm5kUNSymtBV31UqYbmXAWszBjztoiEAatF5NfGmC8bOzalvKEtAqWUCnE6RqCUUiFOE4FSSoU4TQRKKRXiNBEopVSI00SglFIhThOBUkqFOE0ESikV4v4fybJZBJL5iuMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([0,1],[0,1],label=\"CDF\")\n",
    "ns = [10,20,40, 80]\n",
    "max_deltas = ns.copy() #initializing\n",
    "for i,n in enumerate(ns):\n",
    "    data = generate_piecewise_data(n)\n",
    "    plt.plot(*data[0:2], label=f\"eCDF, n={n}\")\n",
    "    max_deltas[i] = data[2]\n",
    "plt.title(\"Emperical Cumulative Distribution Function\")\n",
    "plt.ylabel(\"ECDF(x)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e686b7de-fb76-4ec4-b359-a31e6ebb1de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel(\"n\")\n",
    "plt.ylabel(\"Max Delta\")\n",
    "plt.title(\"Max Absolute Error of eCDF_n\")\n",
    "plt.plot(ns, max_deltas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5cbd6e-05e2-45d5-a7e5-8e22a0478ac6",
   "metadata": {},
   "source": [
    "**Theorem** For any value of $x$ \n",
    "1. $\\mathbb{E} \\left(\\hat F_n(x)\\right) = F(x)$\n",
    "2. $\\mathbb{V} \\left(\\hat F_n(x)\\right) = \\frac{F(x)(1-F(x))}{n}$ \n",
    "3. $\\text{MSE}\\left( \\hat F_n(x)\\right) \\stackrel{1}{=} \\mathbb{V} \\left(\\hat F_n(x)\\right)\n",
    "\\to 0 \\text{ as } n\\to \\infty   $ \n",
    "4. $\\hat F_n(x) \\stackrel{P}{\\to} F(x) \\text{ as } n\\to \\infty.$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b2266e-c1cd-445e-9041-2e75544de62f",
   "metadata": {},
   "source": [
    "That is, \n",
    "- by 1, $\\hat F_n(x)$ is an unbiased estimator of $F(x)$,\n",
    "- by 4, $\\hat F_n(x)$ is a consistant estimator of $F(x)$. \n",
    "\n",
    "But is this pointwise consistency uniform? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51423db2-a177-42b1-82ea-6e5cbe81d4ae",
   "metadata": {},
   "source": [
    "**Glivenko-Cantelli Theorem:** If $X_1,...,X_n \\sim F$ then \n",
    "$$\\sup\\limits_x \\left| \\hat{F_n}(x) - F (x)\\right| \\stackrel{a.s.}{\\to} 0 \\text{ as } n\\to\\infty.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bccebe-96b8-49b6-b123-b73e107260bb",
   "metadata": {},
   "source": [
    "Interpretation: for data with non-zero probability, the function $\\hat F_n$ is a consistent estimator of the function $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042573e6-d495-45e2-ba6c-3dbb0832f6c7",
   "metadata": {},
   "source": [
    "The details of this convergence, shown in the next two theorems, provide a foundation for construction of a confidence set based on Markov, Chebyshev, and Hoeffding’s inequalities (culminating in theorem 4.5). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796f57be-ef10-41b2-b1de-ab2827674e7b",
   "metadata": {},
   "source": [
    "**Theorem 4.5** (Hoeffding’s Inequality, part 2) Let $X_1 , . . . , X_n \\sim \\text{Bernoulli}(p)$. Then, for any $\\epsilon > 0$,\n",
    "\n",
    "$$\\mathbb{P} ( |\\bar{X}_n − p| > \\epsilon ) \n",
    "\\leq  2e^{−2n \\epsilon^2}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca3c7c6-3e84-4f95-ae98-9f0c740c4d4c",
   "metadata": {},
   "source": [
    "Since $I(X>x)$ is a Bernouli random variable, \n",
    "$\\hat F_n(x)$ is a binomial random variable with mean $F(x)$. \n",
    "Thus, for all $x$, the point values $\\hat F_n(x) $ and $F(x)$ can be subsituted into theorem 4.5. Since the right is independent of the value of $x$... "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64ae09-943e-4396-a042-3acb15f77cfb",
   "metadata": {},
   "source": [
    "**Theorem: Dvoretzky-Kiefer-Wolfowitz (DKW) Inequality** \n",
    "$$\\mathbb{P}\\left(  \\sup\\limits_x \\vert  \\hat{F_n}(x) + F (x) | > \\epsilon \\right) ≤ 2e^{−2n\\epsilon^2 }  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e91277-c60f-443a-b5e8-1a702db922ea",
   "metadata": {},
   "source": [
    "That gives the following widely used result:\n",
    "\n",
    "## A Nonparametric $1 − \\alpha~$ Confidence Band for A CDF:\n",
    "\n",
    "Let \n",
    "$$L(x) = \\max\\left\\{\\hat{F_n}(x)−\\epsilon_{\\alpha,n}\\, , \\,0\\right\\}$$ \n",
    "and \n",
    "$$U(x) = \\min\\left\\{\\hat{F_n}(x) + \\epsilon_{\\alpha,n} \\, , \\, 1\\right\\} $$\n",
    "\n",
    "\n",
    "where \n",
    "$$\\epsilon_{\\alpha,n} = \\sqrt{  \\frac{1}{2n} \\log \\left(  \\frac{2}{\\alpha} \\right) }.$$\n",
    "Then \n",
    "$$\\mathbb{P}\\big( L(x)≤F(x)≤U(x)\\text{ for all x } \\big) \\geq 1−\\alpha.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1135acc2-a7e6-4b3c-9abd-944823882b73",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de47186-4f8d-4006-9fb0-04dd8f45a581",
   "metadata": {},
   "source": [
    "That is, random sampling allows approximation of the CDF of a random variable;\n",
    "- take $n$ samples and construct the emperical distribution function $\\hat F_n$. \n",
    "- There is a $1-\\alpha$ probability that both \n",
    "    - $\\hat F_n + \\epsilon_{\\alpha,n}$ bounds the entire CDF above \n",
    "    - $\\hat F_n - \\epsilon_{\\alpha,n}$ bounds the entire CDF below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef9edbae-04f2-4d00-98f0-715cbda761f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, cauchy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n = 100\n",
    "alpha = 0.05\n",
    "epsilon = math.sqrt((1 / (2 * n)) * math.log(2 / alpha))\n",
    "\n",
    "# Wtih Normal distribution\n",
    "def generate():\n",
    "    # Randomly sample\n",
    "    samples = norm.rvs(size=n)\n",
    "    sorted_samples = sorted(samples)\n",
    "\n",
    "    # Fraction of samples less than x\n",
    "    F_n = lambda x : sum(sorted_samples < x) / n\n",
    "    # Bounds\n",
    "    L_n = lambda x : max(F_n(x) - epsilon, 0)\n",
    "    U_n = lambda x : min(F_n(x) + epsilon, 1)\n",
    "\n",
    "    # collect into df\n",
    "    df = pd.DataFrame({\n",
    "            'x': sorted_samples, \n",
    "            'F_n': np.array(list(map(F_n, sorted_samples))), \n",
    "            'U_n': np.array(list(map(U_n, sorted_samples))), \n",
    "            'L_n': np.array(list(map(L_n, sorted_samples))), \n",
    "            'CDF': np.array(list(map(norm.cdf, sorted_samples)))\n",
    "            })\n",
    "    #column to label out parts of CDF outside ob bounds.\n",
    "    df['in_bounds'] = (df['U_n'] >= df['CDF']) & (df['CDF'] >= df['L_n'])\n",
    "\n",
    "    bound_broken = np.any(~df['in_bounds'])\n",
    "    return df, bound_broken\n",
    "\n",
    "def plot(df, bound_broken):\n",
    "    plt.plot( 'x', 'L_n', data=df, color='red')\n",
    "    plt.plot( 'x', 'U_n', data=df, color='green')\n",
    "    plt.plot( 'x', 'CDF', data=df, color='purple')\n",
    "    plt.title(f'It is {bound_broken} that the CDF crosses the 95% confidence bounds.')\n",
    "    plt.legend();\n",
    "\n",
    "plot(*generate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1471ef33-41a6-427e-b1db-a938c1ea10c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.1 s, sys: 116 ms, total: 14.2 s\n",
      "Wall time: 14.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.043"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# calculate the fraction of the time that the bound is broken. \n",
    "# It is a.s. less than alpha = 0.05\n",
    "break_booleans = [generate()[1] for _ in range(1000)]\n",
    "sum(break_booleans)/len(break_booleans) # got 0.026, 0.035"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853f54e-e0e2-485b-8079-0a36eb6a56f9",
   "metadata": {},
   "source": [
    "## 7.2 Statistical functionals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7734ab19-6113-4212-91d3-8430793d56be",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Definition:** In general any function $T$ of the CDF $F$ is called a **statistical functional**. \n",
    "\n",
    "**e.g.s** \n",
    "1. Variance is the statistical functional $\\mathbb{V}$ that assigns to the distibution $F$ (regardless of the random variable it goes with) the number\n",
    "$$\\int x^2 dF(x) −\\left( \\int xdF(x)\\right)^2$$\n",
    "\n",
    "2. Median is the statistical functional that assigns to the distribution $F$ the number\n",
    "$$F^{−1}(1/2).$$\n",
    "\n",
    "3. Sampling distributions $F_{\\hat\\theta_n}$ of estimates $\\hat{\\theta}_n$ of a parameter $\\theta$ are examples of statistical functionals. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059125a3-abbb-4de9-94ee-e756d4309a17",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Definition:** A statistical functional of the from $T(F) = \\int r(x) dF(x)$ is a <u>linear statistical functional</u>. \n",
    "\n",
    "Why? Because $T(ar +bs)=aT(r) +bT(s)$, and likely any homogeneous degreee one addition preserving statistical functional can be realized this way, so keep an eye out in future reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af8ec1d-0e92-4e55-826d-c7c8eb97f840",
   "metadata": {
    "tags": []
   },
   "source": [
    "**e.g.s Of Linear StatisticalFunctionals** \n",
    "1. Probability $\\mathbb{P}([a,b])$ on an interval $[a,b]$ is a linear statistical functional; $\\mathbb{P}_F( [a,b]) = \\int_{\\mathbb{R}} I(x\\in [a,b])dF(x) = F(b)-F(a)$. \n",
    "2. Expectation value of a random variable $X$ is a linear statistical functional that assigns to the distribution $F$ the number \n",
    "$$\\int x dF(x).$$\n",
    "2.  The expectation of any function (really expression) $R(X)$ of $X$ is a linear statistical functional since $\\mathbb{E}(R(X)):= \\int r dF_R(r)= \\stackrel{\\text{LOTUS}}{=} \\int r(x) dF(x)$  with $r$ being the first $n-1$ integrals.\n",
    "3. According to <a href src=\"https://www.math.kth.se/matstat/gru/sf2955/statfunctnl.pdf\">Koski,Example 4.2 </a>, \"variance with known mean\" is a linear statistical functional; $\\mathbb{V}(F) = \\int \\left(x- \\mu \\right)^2 dF(x)$\n",
    "4. $\\text{mse}\\left(\\hat \\theta_n\\right) = \\mathbb{E}_{\\hat \\theta_n}(  \\hat{\\theta}_n − \\theta)^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8bb959-3b6e-441e-9ca5-2fd02f094327",
   "metadata": {
    "tags": []
   },
   "source": [
    "**non-e.g.s of Linear Statistical Functionals** \n",
    " \n",
    "- \"variance with unknown mean\" $\\mathbb{V}(F) = \\int \\left(x- \\int x dF(x) \\right)^2 dF(x)$, is non-linear in F. \n",
    "- The squared standard error $\\text{se}^2(\\hat{\\theta}_n) = {\\mathbb{V}_{\\hat \\theta_n } (\\hat{\\theta}_n)} = {\\int \\left( \\hat\\theta_n  - \\mathbb{E}_{\\hat \\theta_n}(\\hat \\theta_n) \\right)^2 dF_{\\hat\\theta_n}(x)}.$\n",
    "- median is an inverse of a CDF, and thus not in general homogeneous. \n",
    "    - For example the uniform distribution $F$ on $[0,1]$ has $F^{-1}(1/2) = 1/2$ but $(2F)^{-1}(1/2)=1/4$, so $\\text{Median}(2F) = \\frac12 \\text{Median}(F)$. \n",
    "- More generally than medians, aka the 50% quantile, all quantiles $Q_q$ such that $Q_q(F) = F^{-1}(q)$ are not linear statistical functionals.\n",
    "- Sampling distributions $F_{\\hat\\theta_n} =\\idotsint_{A_t} \\prod\\limits_{i=1}^n dF_X(x_i;\\theta)$ of a statistic $\\hat{\\theta}_n(X_1,...,X_n)$ are homogeneous degree $n$ in $F_X$. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35483fb9-0aca-41b4-9f7c-1a149690e660",
   "metadata": {},
   "source": [
    "## Plug In Estimators \n",
    "of Statistical Functionals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68749dc6-2459-43ea-a2dd-8ba1fb8083bd",
   "metadata": {},
   "source": [
    "**Definition** The **plug-in estimator** of the statistical functional $\\theta = T (F )$ is the statistic $\\hat{\\theta}_n = T \\left( \\hat F_n \\right)$ .\n",
    "\n",
    "In other words, just plug in the emperical distribution $\\hat F_n$ for the unknown distribution $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d442ee2a-e750-4935-9429-64514f79d1d8",
   "metadata": {},
   "source": [
    "**Thm 7.9** The plug-in estimator for linear statistical functional $T$ such that\n",
    "$ T (F ) =\\int r(x)dF (x) ~\\forall \\text{ distribution } F$ is the statistic\n",
    "$$ T\\left(\\hat{F_n}\\right) = \\frac1n \\sum\\limits_{i=1}^n  r(X_i).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee86a5ae-d4f9-46bf-90de-50ec56725672",
   "metadata": {},
   "source": [
    "**Proof:** Using the definition of the Dirac delta function in terms of the Heaviside function, \n",
    "$$\n",
    "\\delta(x-a) = \\frac{d}{dx} I(x\\geq a)\n",
    "$$\n",
    "We have that \n",
    "$$\n",
    "T(\\hat F) = \\int r(x)d\\hat{F_n}(x) \n",
    "= \\int_\\mathbb{R} r(x) d\\left( \\frac1n \\sum\\limits_{i=1}^n I(x\\geq X_i)\\right)\\\\\n",
    "= \\int_\\mathbb{R} \\frac1n r(x) \\sum\\limits_{i=1}^n \\delta(x-X_i) dx \n",
    "= \\frac1n \\sum\\limits_{i=1}^n r(X_i). \\square\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea805df-d67d-4a0b-a622-2de5d6a8d98f",
   "metadata": {},
   "source": [
    "**Theorem:** The plug in estimator $\\hat{\\mathbb{V}}_n$ of the linear statistical function known as the \"variance with known mean\"\"variance with unknown mean\" $\\int \\left(x- \\mu \\right)^2 dF(x)$ is the \"population variance\" of the random sample $X^n$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e60a24e-7252-4249-8910-81463e6027a2",
   "metadata": {},
   "source": [
    "**Proof:**  $\\hat{\\mathbb{V}}_n(F) = \\int \\left(x- \\mu \\right)^2 d\\hat{F}_n(x) = \\frac1n \\sum_{i=1}^n(X_i -\\mu)^2$.\n",
    "\n",
    "$\\square$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257ea814-b1fe-40c7-a8c2-d59bbbeecd06",
   "metadata": {},
   "source": [
    "Point of confusion: the \"variance with unknown mean\" $\\mathbb{V}(F) = \\int \\left(x- \\int x dF(x) \\right)^2 dF(x)$ is not a linear statistical functional. However, the expectation value appearing within is, and somehow people make use of that to obtain\n",
    "$$\n",
    "\\hat{\\mathbb{V}}_n(\\hat F_n) \n",
    "= \\int \\left(x- \\int x d\\hat F_n(x)\\right)^2 d\\hat F_n(x)\\\\\n",
    "= \\int \\left(x - \\sum\\limits_{i=1}^n  X_i  \\frac 1n \\right)^2 d\\hat F_n(x)\\\\\n",
    "= \\frac 1n \\sum\\limits_{j=1}^n \\left(X_j- \\bar{X}_n   \\right)^2. \n",
    "$$ \n",
    "and I do not know how to describe that object; it is not a plug in estimator because of the non-linearity.\n",
    "\n",
    "Also, I do not know how to resolve the two ideas that \n",
    "- $\\mu = \\int x dF_X(x)$ (= means is the same thing?...)\n",
    "- the variance with known mean is a different object than the variance with unknown mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef5eac-fe61-4ef0-ada6-6ba8b401d995",
   "metadata": {},
   "source": [
    "**Note:** The plug in estimator of variance is\n",
    "- is NOT the sample variance; the sample variance $S^2_n :=\\frac{1}{n-1}\\sum\\limits_{j=1}^n(X_i-\\bar{X}_n)$  is a statistic and an unbaised estimator of variance of $X$.\n",
    "- is the population variance with the emperical distribution function thrown in place of the distribution, even if the population was continuous and the sample was finite.\n",
    "- is a biased estimator of the variance of $X\\sim F$ since $\\mathbb{E}(\\hat{\\mathbb{V}}_n - \\sigma^2) = \\frac1n \\sigma^2$.  \n",
    "- is a consistant estimator of the variance since $\\mathbb{E}(\\hat{\\mathbb{V}}_n - \\sigma^2) = \\frac1n \\sigma^2 \\to 0$ as $n\\to \\infty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5143102-389b-483c-8bf6-59d1e682a1aa",
   "metadata": {},
   "source": [
    "---\n",
    "**e.g.of plug in estimate with a joint distribution** \n",
    "\n",
    "**Definition** (in eg 7.13): The **sample correlation** is the plug in estimator for the  statistical functional called the population correlation with known means and variances $\\text{Cov}(X,Y)$. \n",
    "\n",
    "$\\text{Cov}(X,Y)$ uses $Z=(X,Y)\\sim F_Z$ and is the statistical functional \n",
    "$$\n",
    "T(F_Z)=\\rho_{F_Z}(X,Y) \\\\\n",
    "= \\frac{\\mathbb{E}_Z\\left[(X - \\mu_X)(Y-\\mu_Y)\\right]}{\\sigma_X\\sigma_Y}\\\\\n",
    "=  \\frac{\\int (x - \\mu_X)(y-\\mu_Y) dF_Z(x,y)}{\\sigma_X\\sigma_Y} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff1bdb0-26d1-4e47-8da7-c7639bbef9cd",
   "metadata": {},
   "source": [
    "The differential of the eCFD\n",
    "$$\n",
    "d\\hat{F}_Z(x,y) \n",
    "    =\\frac{\\partial^2}{\\partial x\\partial y}\\hat{F}_Z(x,y) dxdy\\\\\n",
    "= \\frac{\\partial^2}{\\partial x\\partial y} \\frac1n\\sum_{i=1}^n I(X_i>x)I(Y_i>y) dxdy\\\\\n",
    "=\\frac{\\partial^2}{\\partial x\\partial y}\\frac1n\\sum_{i=1}^n I(X_i>x)I(Y_i>y) dxdy\\\\\n",
    "=\\frac1n\\sum_{i=1}^n \\delta(X_i-x)\\delta(Y_i-y) dxdy\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c514497f-a0d2-4bc4-8667-c108581118c8",
   "metadata": {},
   "source": [
    "So, the plug in estimator of correlation with known means and variances is the statistic \n",
    "$$\\hat{\\rho}_n(X^n,Y^n) = \n",
    "\\frac\n",
    "{\\frac1n \\sum\\limits_{i=1}^n(X_i - \\mu_X)(Y_i - \\mu_Y)}\n",
    "{\\sigma_X \\sigma_Y}\n",
    "$$\n",
    "\n",
    "which is \n",
    "- not covariance divided by sample standard deviations \n",
    "- is  covariance divided by population standard deviations. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea44b0-ff3c-484d-a685-3330bd539a32",
   "metadata": {},
   "source": [
    "**Point of confusion:**\n",
    "\n",
    "The population correlation with  unknown variances and known means appears to be a non-linear functional;\n",
    "$$\n",
    "T(F_Z)=\\rho_{F_Z}(X,Y) \\\\\n",
    "= \\frac{\\mathbb{E}_Z\\left[(X - \\mu_X)(Y-\\mu_Y)\\right]}\n",
    "{\n",
    "    \\sqrt{\\mathbb{E}((X- \\mu_X)^2)\\mathbb{E}((Y- \\mu_Y)^2)}\n",
    "}\\\\\n",
    "=  \\frac{\\int (x - \\mu_X)(y-\\mu_Y) dF_Z(X,Y)}{\n",
    "\\sqrt{\\int (x- \\mu_X)^2 dF_X(x)}\n",
    "\\sqrt{\\int (y- \\mu_Y)^2 dF_Y(y)}\n",
    "} \n",
    "$$\n",
    "has estimator that is not a plug in estimator\n",
    "$$\\hat{\\rho}_n(X^n,Y^n) = \n",
    "\\frac\n",
    "{\\sum\\limits_{i=1}^n(X_i - \\mu_X)(Y_i - \\mu_Y)}\n",
    "{\\sqrt{\\sum\\limits_{i=1}^n(X-\\mu_X)^2 \\sum\\limits_{j=1}^n(Y-\\mu_Y)^2}}\n",
    "$$\n",
    "\n",
    "Similarly the population correlation with unknown means and unknown variances has estimator... \n",
    "$$\\hat{\\rho}_n(X^n,Y^n) = \n",
    "\\frac\n",
    "{\\sum\\limits_{i=1}^n(X_i - \\bar{X}_n)(Y_i - \\bar{Y}_n)}\n",
    "{\\sqrt{\\sum\\limits_{i=1}^n(X-\\bar{X}_n)^2 \\sum\\limits_{j=1}^n(Y-\\bar{Y}_n)^2}}\n",
    "$$\n",
    "\n",
    "And the population vorrelation with unknown means and known variances \n",
    "$$\\hat{\\rho}_n(X^n,Y^n) = \n",
    "\\frac\n",
    "{\\frac1n\\sum\\limits_{i=1}^n(X_i - \\bar{X}_n)(Y_i - \\bar{Y}_n)}\n",
    "{\\sigma_X \\sigma_Y}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35c731-1b15-4273-99f3-19a8d94da82b",
   "metadata": {},
   "source": [
    "## Multivariate emperical distributions\n",
    "\n",
    "This is not in Wasserman, but I want to make sure it works out.\n",
    "\n",
    "A multivariate cumulative distribution on the random variable $\\vec X \\in \\{f:\\Omega \\to \\mathbb{R}^d \\}$ is \n",
    "$$F(\\vec x) =   \\mathbb{P}\\left( \\wedge_{j=1}^n (X_j \\leq x_j) \\right).\n",
    "$$\n",
    "\n",
    "In what follows I will denote \n",
    "$$\n",
    "\\wedge_{j=1}^d(X_j\\leq x_j) \\text{ as }   \\vec X \\leq \\vec x.\n",
    "$$\n",
    "\n",
    "The associated PDF is\n",
    "$$\n",
    "f(\\vec x) = \\frac{\\partial^d}{\\prod_{j=1}^n dx_j} F(\\vec x)\n",
    "$$\n",
    "and \n",
    "$$F(\\vec x) = \\int_{-\\infty}^{x_1} \\cdots \\int_{-\\infty}^{x_d} f(\\vec x) \\prod_{j=1}^d dx_j.$$\n",
    "\n",
    "An emperical distribution function on a random sample $\\vec X_1,\\dots,\\vec X_i,\\dots,\\vec X_n \\in \\{ f: \\Omega \\to \\mathbb{R}^d\\}$ of size $n$ is \n",
    "$$\n",
    "\\hat F \\left(\\vec x \\right) \n",
    "= \\frac1n \\sum\\limits_{i=1}^n I\\left( \n",
    "\\vec x \\leq \\vec X_i\n",
    "\\right)\\\\\n",
    "= \n",
    "\\frac1n \\sum\\limits_{i=1}^n I\\left( \n",
    "\\wedge_{j=1}^d  \\left( x_{j} \\leq  X_{ij} \\right)\n",
    "\\right)\\\\\n",
    "= \n",
    "\\frac1n \\sum\\limits_{i=1}^n \\prod\\limits_{j=1}^d I\\left( \n",
    " x_{j} \\leq  X_{ij}\n",
    "\\right)\\\\\n",
    "$$\n",
    "\n",
    "\n",
    "For a linear statistical functional $T$ with kernel $K(\\vec x)$ the plug in estimator is \n",
    "$$\n",
    "\\hat T \n",
    "= \\int K(\\vec x )d\\hat F(\\vec x) \\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\int K(\\vec x )\\frac{\\partial^d}{\\prod_{j=1}^d dx_j}\\hat F(\\vec x) \\prod_{j=1}^d dx_j\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac1n \\sum\\limits_{i=1}^n \n",
    "\\int K(\\vec x )\n",
    "\\frac{\\partial^d}{\n",
    "      \\prod_{j=1}^d dx_j\n",
    "      }\n",
    "\\prod\\limits_{j'=1}^d H(x_{j'} - X_{ij'})\n",
    "\\prod_{j=1}^d dx_j\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac1n \\sum\\limits_{i=1}^n \n",
    "\\int K(\\vec x )\n",
    "\\frac{\\partial^d}{\\prod_{j=2}^n dx_j}\n",
    "\\delta(x_{1} - X_{i1})\\prod\\limits_{j'= 2}^d H(x_{j'} - X_{ij'})\n",
    "\\prod_{j=1}^d dx_j\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac1n \\sum\\limits_{i=1}^n \n",
    "\\int K(\\vec x )\n",
    "\\prod_{j=1}^d\n",
    "\\delta(x_{j} - X_{ij})\n",
    "\\prod_{j=1}^d dx_j\\\\\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\frac1n \\sum\\limits_{i=1}^n  K(\\vec{X}_i )\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789dde9a-fe27-42e0-bd25-9281518f1cff",
   "metadata": {},
   "source": [
    "That is to say, it does indeed work out :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1dd2fd-8035-41f1-b44a-c0c1eaf691bb",
   "metadata": {},
   "source": [
    "I'd love to plot a two variable eCDF. \n",
    "\n",
    "statsmodels <a href src=\"https://www.statsmodels.org/dev/distributions.html#module-statsmodels.distributions.empirical_distribution\">does not </a> have this feature yet.\n",
    "\n",
    "<a href src=\"https://stackoverflow.com/questions/69240432/is-there-a-python-implementation-of-multidimensional-ecdfs\">This guy</a> said he'd make it in 2021.... \n",
    "\n",
    "<a href src=\"https://arxiv.org/pdf/2005.03246.pdf\">This paper</a> discusses the complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "35afc4fe-fc73-4946-aaa7-427ba944850e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What does statsmodels have for eCDF? \n",
    "import numpy as np \n",
    "from statsmodels.distributions import empirical_distribution as eds\n",
    "\n",
    "# Draw samples according to a unifrom distribution on [0,1]^2\n",
    "# or a normal dist on R^2\n",
    "n=100\n",
    "xs = np.sort(np.random.rand(n)) #not drawn according to a dist \n",
    "\n",
    "# construct a rectangle wise constant function \n",
    "E = eds.ECDF(xs) # does no have a multivariate version yet. \n",
    "plt.plot(xs,E(xs));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9ece4-dacb-413a-b50c-eff2dab8b77d",
   "metadata": {},
   "source": [
    "## Quantile Functional\n",
    "**Definition:** The statistical functional $Q_p$ such that $Q_p(F) = \\inf F^{-1}(p)$ the <u>p-th quantile</u>. \n",
    "\n",
    "Actually to avoid ambiguity where the CDF is constant, we defined \n",
    "$Q_p(F) = \\inf\\{x \\,|\\,F(x)< p\\}$. That especially matters for what follows. I note that this infimum does not apply to multivariable cases. \n",
    "\n",
    "**Definition:** The number $Q_p(\\hat{F_n} )$ is the $p$th **sample quantile** of the CDF $F$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c04eb7-562a-445d-872a-dbb6f0c71e8f",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "# Ch8 The Bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b3dbc5-2858-4eff-9197-b2873ae397a1",
   "metadata": {},
   "source": [
    "**Definition:** A <u>resampling</u> of the random sample $X_1,...,X_n$ of the random variable $X$ is a sequence of $n$ randomly chosen elements of the random sample:  $(X_{1,j}^*,...,X_{n,j}^*)$ with $X_{i,j}^* \\in \\{X_1,...,X_n\\}$.\n",
    "\n",
    "I denote a random sample by $X^n$ and a resampling of that random sample as $X^{n*}$. One can generate a finite sequence of $B$ re-samplings $X^{n*}_1,...,X^{n*}_B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c644fe56-8a8b-435b-a026-6bb56706a687",
   "metadata": {},
   "source": [
    "**Definition:** A **simulation** of size $B$ of a statistic $T_n=T_n(X_1,...,X_n)$ of a random variable $X$ is a sample $T_{n,1}^∗, ..., T_{n,B}^∗$ of $T_n$ generated by re-sampling;  $T_{n,j}^* = T_n(X_{1,j}^*,...,X_{n,j}^*)$ for $j=1,...,B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da1c523-74b8-44f8-859b-d80c4e3d94a2",
   "metadata": {},
   "source": [
    "Simulations privide eCDFs of a statistic. \n",
    "$$\n",
    "\\hat{F}_{T_n}(t) = \\frac1B \\sum_{j=1}^B I(T^*_{n,j}<t) \\stackrel{p}{\\to} F_{T_n}(t) \\text{ as } B\\to \\infty.\n",
    "$$\n",
    "This is the heart of bootstrapping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a25722-04fb-4b25-88f5-898b1946c7ba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Bootstrap Variance Estimation\n",
    "\n",
    "The \"plug in estimator\" for variance with unknown mean from bootstrapping is \n",
    "$$v_{\\text{boot}} = \\frac1B \\sum\\limits_{i=1}^B (T_{n,i}^∗-\\overline{T_n^*}_B)^2\\\\ \\stackrel{P}{\\to}\\mathbb{E}_{T_n}((T_{n}-\\mu_{T_n})^2) = \\mathbb{V}_{T_n}(T_n)\n",
    "\\text{ as } B\\to \\infty.$$\n",
    "\n",
    "(Note that \"plug in estimator\" is an over-use of the word because the vairance with unknown mean is not a linear functional.)\n",
    "\n",
    "Thus, we can approximate the variance $\\mathbb{V}_{T_n}(T_n)$ arbitrarily well by using a large enough $B$ bootstrap sample $T_{n,1}^∗, ..., T_{n,B}^∗$ of $T_n$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "59f3270e-3e63-4fce-a206-40b35eb3d148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal--------------------------------------------------\n",
      "The variance of max_statistic is approximately 0.05323181733762108.\n",
      "The variance of mean_statistic is approximately 0.009374808231446754.\n",
      "The variance of variance_statistic is approximately 0.018114690859227442.\n",
      "Power--------------------------------------------------\n",
      "The variance of max_statistic is approximately 7.597733660298064e+35.\n",
      "The variance of mean_statistic is approximately 4.597637923397931e+32.\n",
      "The variance of variance_statistic is approximately 1.770560614204026e+69.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "n, B = 100, 10_000\n",
    "# Obtain one random sample (from each example distribution). \n",
    "norm_data = stats.norm().rvs(n) \n",
    "uniform_data = stats.uniform().rvs(n) \n",
    "powerlaw_data = stats.pareto(b=0.1).rvs(n)# b/x^{b+1}, so b<=1 implies E(X) DNE.\n",
    "\n",
    "def resample(data): \n",
    "    return np.random.choice(data, size = n,replace = True)\n",
    "\n",
    "statistics =     [np.max,         np.mean,         np.var]\n",
    "statistics_str = [\"max_statistic\",\"mean_statistic\",\"variance_statistic\"]\n",
    "\n",
    "def simulation(data, statistic):\n",
    "    simulation_of_statistic = [statistic(resample(data)) for _ in range(B)]\n",
    "    return simulation_of_statistic\n",
    "\n",
    "def bootstrap_estimation_of_variance(data, statistic):\n",
    "    simulation_of_statistic = simulation(data, statistic)\n",
    "    # Return variation of simulation as approximation of variation of statistic.\n",
    "    v_boost = np.var(simulation_of_statistic) \n",
    "    return v_boost\n",
    "\n",
    "bev = bootstrap_estimation_of_variance\n",
    "\n",
    "print(\"Normal\"+\"-\"*50)\n",
    "for i, statistic in enumerate(statistics):\n",
    "    # Variance of max, mean, and variance are small for a normal distribution. \n",
    "    print(f\"The variance of {statistics_str[i]} \"\n",
    "          + f\"is approximately {bev(norm_data,statistic)}.\")\n",
    "\n",
    "print(\"Power\"+\"-\"*50)\n",
    "for i, statistic in enumerate(statistics):\n",
    "    # but large for that power law f(x) = p/x^{p+1}, p<1 on x>1.\n",
    "    # In particular, all three of these are estimates of infinity.\n",
    "    print(f\"The variance of {statistics_str[i]}\"\n",
    "          + f\" is approximately {bev(powerlaw_data,statistic)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3293f328-c9b9-469e-acf1-e4cca0e9e46c",
   "metadata": {},
   "source": [
    "## 8.3 Bootstrap Confidence Intervals\n",
    "\n",
    "Or \"confidence intervals for estimators where the confidence intervals are derived from bootstrapping.\" \n",
    "\n",
    "Three common ways to get confidence intervals from boot strapping:\n",
    "1. The normal interval method\n",
    "2. Using a pivotal quantity\n",
    "3. Percentile intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c60acd5-7b1d-4fa3-8955-e2a26cf07b45",
   "metadata": {},
   "source": [
    "### 1. The Normal interval method\n",
    "If $\\hat{\\theta}_n$ is an estimator of a parameter $\\theta$ and the distribution of the estimator $\\hat{\\theta}_n$ is close to normal, then \n",
    "$$\n",
    "\\left(\n",
    "\\hat{\\theta}_n- F_{\\text{Norm}}^{-1}(1-\\alpha/2) \\sqrt{ \\mathbb{V}_{\\rm boot}(\\hat{\\theta}_n) }\n",
    "\\,,\\,\n",
    "\\hat{\\theta}_n + F_{\\text{Norm}}^{-1}(1-\\alpha/2)\\sqrt{ \\mathbb{V}_{\\rm boot}(\\hat{\\theta}_n) }\n",
    "\\right)\n",
    "$$ \n",
    "is an approximate $1-\\alpha$ confidence interval for the parameter $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a841b371-49b6-4a23-807b-136c8b4dcaf3",
   "metadata": {},
   "source": [
    "### 2. Pivotal Quantity or Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1289bd65-50d7-48d9-b93c-6587506b6522",
   "metadata": {},
   "source": [
    "Recall:\n",
    "\n",
    "**Definition:** Let $\\hat{\\theta}_n(X^n)$ be a point estimator of the parameter $\\theta$. Assume that $X\\sim F_{(X|\\theta)}$, meaning the distribution for $X$ has a parameter $\\theta$. A statistic $R\\left(\\hat{\\theta}_n|\\theta\\right)$ is a **pivotal quantity** of $\\theta$ if its distribution $F_{R\\left(\\hat{\\theta}_n|\\theta\\right)}$ is independent of the parameter $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5736bb-3d38-43fc-9bfc-e7bf25b804cc",
   "metadata": {},
   "source": [
    "Let $T$ be a statistical functional, let $\\theta := T(F)$ for some particular $F$,  and let $\\hat{\\theta}_n = T(\\hat{F}_n)$ be the plug in estimator of $\\theta$. Then $R_n := \\hat{\\theta}_n − \\theta$ is a pivotal quantity for $\\theta$; the distribution $F_{R_n}$ does not depend on $\\theta$. (How can I see that? )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818027fc-4145-4d5b-85f7-6efdfd430dce",
   "metadata": {},
   "source": [
    "Then\n",
    "$$\n",
    "\\mathbb{P}(a\\leq R_n \\leq b) = 1-\\alpha\\\\\n",
    "\\Leftrightarrow \n",
    "\\mathbb{P}(a\\leq \\hat{\\theta}_n − \\theta \\leq b) = 1-\\alpha\\\\\n",
    "\\Leftrightarrow \n",
    "\\mathbb{P}( \\hat{\\theta}_n -b \\leq   \\theta \\leq \\hat{\\theta}_n-a) = 1-\\alpha\\\\\n",
    "$$\n",
    "We need a choice of $a$ and $b$. One choice is to let $H$ denote the CDF **of the pivot**, $H(r) := \\mathbb{P}_F \\left(R_n \\leq r\\right)$, and choose $a=H^{-1}\\left( \\frac{\\alpha}{2} \\right)$ and $b=H^{-1}\\left(1-\\frac{\\alpha}{2} \\right)$, giving the $1-\\alpha$ confidence interval \n",
    "$$\n",
    "(L,U) = \\left(      \n",
    "\\hat{\\theta}_n - H^{-1}\\left(1-\\frac{\\alpha}{2} \\right), \n",
    "\\hat{\\theta}_n - H^{-1}\\left(  \\frac{\\alpha}{2} \\right)\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f28c5f-67e5-46ae-be9b-0840e9fa1bba",
   "metadata": {},
   "source": [
    "However, we do no know $H$. We can form a bootstrap estimate for the CDF of $R$\n",
    "$$\n",
    "H_B(r) = \\frac1B \\sum\\limits_{j=1}^B I\\left(R^*_{n,j}\\leq r\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06141a91-c17c-4d2d-bd5e-463c77b09ac0",
   "metadata": {},
   "source": [
    "where $R^*_{n,j} = \\hat{\\theta}^*_{n,j} - \\theta $ is computed from the bootstrap replications $ \\theta_{n,1}^∗, . . . , \\theta_{n,B}^∗$ of the statistic $\\hat{\\theta}_n(X_1,\\dots,X_n)$. \n",
    "\n",
    "Further, since $\\theta$ is unknown, it must be estimated. The two choices you might consider are \n",
    "1. the value at the original sample $\\hat{\\theta}_n = \\hat{\\theta}_n(X_1,...,X_n)$\n",
    "2. the average value over the simulation, $\\bar{\\theta}_n^* = \\frac1B \\sum_{j=1}^B \\hat{\\theta}_{n,j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542d5b3-0a4a-442e-8b35-65d0889bb985",
   "metadata": {},
   "source": [
    "Option 2 looks appealing because of  it's averaging like appearance, but option 1 is correct because we aim to center a interval around $\\hat{\\theta}_n$. Thus\n",
    "$$R^*_{n,j} \\approx \\hat{\\theta}^*_{n,j} -  \\hat{\\theta}_n $$\n",
    "\n",
    "This gives the estimate \n",
    "$$\n",
    "(L_B,U_B) = \\left(      \n",
    "\\hat{\\theta}_n - H_B^{-1}\\left(1-\\frac{\\alpha}{2} \\right), \n",
    "\\hat{\\theta}_n - H_B^{-1}\\left(  \\frac{\\alpha}{2} \\right)\n",
    "\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cb2d92-980c-46ee-b37c-801baf403923",
   "metadata": {},
   "source": [
    "**Definition** The interval $(L_B,U_B)$ is the $1-\\alpha$  <u>bootstrap pivotal confidence interval</u> for $\\theta$. \n",
    "\n",
    "Note that the article in that definition is \"the\" and not \"a\" because this interval is a statistic; the interval will be different each time data is obtained and bootstrapping is performed, but this interval valued statistic is the abstraction away from that data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9e2a43-fb56-4636-8c8e-aae0b704818f",
   "metadata": {},
   "source": [
    "#### e.g. 95% pivotal confidence interval for the max statistic of Expon\n",
    "Point of confusion:\n",
    "- I'm supposed to start with a particular linear functional $T$ and paricular distribution $F$ and let $\\theta = T(F)$, and then form the plug in estimate of $\\theta$. I did not do that. \n",
    "    - I'm confused about the use of a linear statistical functional here; statistical functionals that take a CDF F and compute a quantity for a sample of size n are homogeneous degree n. For example, if T maps F  to sample mean for a sample of size n, then $T(F) = \\int \\bar{X}_n \\prod_{i=1}^n dF_X(x_i)$ and so $T$ is homogeneous degree n. So, the suggestion does not make sense to me. \n",
    "    - The max statistic is an estimator of the expectation value of the max statistic. So $T(F) = \\int m dF_M(m)$ where $F_M(m) = \\mathbb{P}(\\wedge_{i=1}^n X_i<m) = \\prod_{i=1}^m  \\mathbb{P}( X_i<m) =  \\prod_{i=1}^m F_X(m) = F^n_X(m)$. Thus $T(F) = \\int m dF^n_X(m)$ is homogeneous degree n, not linear. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7139a508-8684-40ab-bec6-80c2000076a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "alpha = .05 # Confidence level\n",
    "n = 100 # Sample size\n",
    "B = 10_000 # Simulation size\n",
    "\n",
    "# A sample form the underlying dist of Xs.\n",
    "#data = stats.norm().rvs(n) \n",
    "data = stats.expon().rvs(n) \n",
    "\n",
    "def statistic(xs):\n",
    "    return np.max(xs)\n",
    "\n",
    "theta_n_hat = statistic(data)\n",
    "\n",
    "def sample(data): \n",
    "    # Tool for bootstrappling\n",
    "    return np.random.choice(data,size = len(data),replace = True)\n",
    "\n",
    "# Simulate \\hat{\\theta}_n.\n",
    "theta_n_star_hats = [statistic(sample(data)) for _ in range(B)]\n",
    "\n",
    "# Simulate the pivot R. \n",
    "# Since we do not know theta, we put in theta_n_hat as an estimate.\n",
    "R_star_ns = [theta_n_star_hat - theta_n_hat \n",
    "                 for theta_n_star_hat in theta_n_star_hats] \n",
    "\n",
    "# CDF for R_star_ns for construction of CI.\n",
    "m = min(R_star_ns)\n",
    "M = max(R_star_ns)\n",
    "H_abscisa = np.linspace(m-1,M+1, 1_000)\n",
    "H = np.array([sum(R_star_ns <= r)/B for r in H_abscisa])\n",
    "\n",
    "# How to invert H when it is discrete:\n",
    "# Where is dist between H and y smallest?\n",
    "def H_inverse(y):\n",
    "    # distance to x\n",
    "    d = np.abs(H - y)\n",
    "    return H_abscisa[np.argmin(d)]\n",
    "\n",
    "# Calculate CI (a,b)\n",
    "L_B = theta_n_hat - H_inverse(1-alpha/2)\n",
    "U_B = theta_n_hat - H_inverse(alpha/2)\n",
    "\n",
    "## eCDF for theta_n_stars for visualization.\n",
    "p = min(theta_n_star_hats)\n",
    "q = max(theta_n_star_hats)\n",
    "# Set window for visualizing F\n",
    "a = min([p,L_B])\n",
    "b = max([q,U_B])\n",
    "F_abscisa = np.linspace(a,b, 1_000)\n",
    "F = np.array([sum(theta_n_star_hats <= r)/B for r in F_abscisa])\n",
    "\n",
    "# Visualize the max of the simulation lying in the interval.\n",
    "# It does not show up well, so I'll explore in the next cell.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(F_abscisa,F)\n",
    "plt.title(\"CDF of theta*ns \")\n",
    "plt.axvline(x=L_B,label = \"L_B\", color = 'green', linestyle = '--')\n",
    "plt.axvline(x=U_B, label = 'U_B', color='blue', linestyle = '--')\n",
    "# plt.axvline(x=1, label = 'true', color = 'red')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3236184-ab23-464c-bedb-3a3a64d3247d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0018770835637895722, 5.978384653430292)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H_inverse(1-alpha/2), theta_n_hat - H_inverse(alpha/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0cc92341-19e0-4082-b4e7-c191300caa37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is True that L_B <= theta_n_hat since 4.186478945182607 <= 4.188356028746397.\n",
      "It is True that theta_n_hat <= U_B since 4.188356028746397 <= 5.978384653430292.\n",
      "The min and max values of the simulation are  2.2626678652827197, 4.188356028746397.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4.186478945182607, 4.188356028746397, 5.978384653430292)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify\n",
    "print(f\"It is {L_B<= theta_n_hat} that L_B <= theta_n_hat since {L_B} <= {theta_n_hat}.\")\n",
    "print(f\"It is {theta_n_hat<= U_B} that theta_n_hat <= U_B since {theta_n_hat} <= {U_B}.\")\n",
    "print(f\"The min and max values of the simulation are  {min(theta_n_star_hats)}, {max(theta_n_star_hats)}.\")\n",
    "L_B,max(data),U_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cd1b18cd-0ed0-4295-b991-edaaf0c98456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# There is a lot of mass at the max of the original sample; \n",
    "# most resamples contain the largest element of the original sample.\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(F_abscisa[:-1],(F[1:]-F[:-1]) / (F_abscisa[1:]-F_abscisa[:-1]))\n",
    "plt.title(\"PDF of theta*ns\")\n",
    "plt.axvline(x=L_B,label = \"L_B\", color = 'green', linestyle = '--')\n",
    "plt.axvline(x=U_B, label = 'U_B', color='blue', linestyle = '--')\n",
    "# plt.axvline(x=1, label = 'true', color = 'red')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bd027-fd85-4c0e-8589-ced32c270466",
   "metadata": {},
   "source": [
    "### 3. Percentile intervals\n",
    "Never went through this; pg 116. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e62f2-641a-4e84-a3ac-7b452ca7b588",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f4929b1-2a91-4a1c-ab54-e39fbdcbeb3d",
   "metadata": {
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Ch 9 Parametric Inference\n",
    "\n",
    "How do we estimate parameters from samples when we suspect the distribution $f$ of is from a parametric model $\\mathfrak{F} = \\{ f(x,\\theta)\\,|\\, \\theta \\in \\Theta\\}$? \n",
    "\n",
    "## 9.2 The Method of Moments\n",
    "If the parameter $\\theta \\in \\mathbb{R}^k$ then solve the system of $k$ equations  that equate the  $j$th moment $\\alpha_j(\\theta) := \\int x^j dF_\\theta(X)$ to the $j$th sample moment $\\hat{\\alpha}_j:= \\frac1n \\sum\\limits_{i=1}^n X^j_i.$ That is solve the system of equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8e7d85-bdb9-4344-bbbb-9afe14a99864",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left\\{ \\begin{array}{c} \n",
    "\\alpha_1(\\theta) = \\hat{\\alpha}_1 \\\\\n",
    "\\vdots\\\\ \n",
    "\\alpha_k(\\theta) = \\hat{\\alpha}_k \n",
    "\\end{array} \\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103d2765-11da-4790-b6a3-c206939538ad",
   "metadata": {},
   "source": [
    "for the $k$ parameters $\\theta$ and call the solution $\\hat{\\theta}_n^{\\text{MOM}}$ the method of moments estimator of $\\theta$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6d1a1d-7a2f-4a42-b137-d0391c6d3897",
   "metadata": {},
   "source": [
    "**e.g.** If $X_1,...,X_n\\sim N(\\mu,\\sigma^2)$ then solve for $(\\mu,\\sigma)$ in \n",
    "$$\n",
    "\\left\\{\\begin{array}{c}\n",
    "\\int x dF = \\frac1n \\sum\\limits_{i=1}^n X_i\\\\\n",
    "\\int x^2 dF = \\frac1n \\sum\\limits_{i=1}^nX_i^2\n",
    "\\end{array}\\right\\}\n",
    "\\Leftrightarrow\n",
    "\\left\\{\\begin{array}{c}\n",
    "\\mu = \\frac1n \\sum\\limits_{i=1}^n X_i\\\\\n",
    "{\\sigma}^2-{\\mu}^2 = \\frac1n \\sum\\limits_{i=1}^nX_i^2\n",
    "\\end{array}\\right\\}\n",
    "\\Leftrightarrow\n",
    "\\left\\{\\begin{array}{c}\n",
    "{\\mu} = \\frac1n \\sum\\limits_{i=1}^n X_i\\\\\n",
    "{\\sigma}= \\frac1n \\sum\\limits_{i=1}^n (X_i - \\bar{X}_n)^2\n",
    "\\end{array}\\right\\}.\n",
    "$$\n",
    "The solution is $\\hat{\\theta}_n^{\\text{MOM}} = (\\hat{\\mu}_n^{\\text{MOM}},\\hat{\\sigma}_n^{\\text{MOM}}) : = \\left(  \\frac1n \\sum\\limits_{i=1}^n X_i \\,,~  \\frac1n \\sum\\limits_{i=1}^n (X_i - \\bar{X}_n)^2 \\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a690a3c7-316c-4956-9fa3-77f234c6791b",
   "metadata": {},
   "source": [
    "That is, in this case the MOM estimator of the mean and variance are the equal to the plugin estimators. This will not always happen. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6519a3-39ae-4881-bdc9-7662d8dd9389",
   "metadata": {},
   "source": [
    "## 9.3 Maximum Likelihood\n",
    "\n",
    "**Definition** The **likelihood function** of a simaple $X_1,...,X_n$ of a random variable $X \\sim f(\\cdot;\\theta)$ is the statistic \n",
    "$\\prod\\limits_{i=1}^n f(X_i;\\theta)$ thought of as a function of $\\theta$.\n",
    "\n",
    "Note the abuse of notation; $\\theta$ stands for a fixed number, and in MLE people use it as an algebraic variable. Sometimes people introduce notation like $\\theta^*$ is the actual value of $\\theta$.... I'll try not to, and live in my discomfort with ambiguity.\n",
    "\n",
    "**Notation** The likelihood function is denoted ${\\cal L}_n(\\theta) $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4651c8ff-59b9-49e7-a53b-81a83fe8d97e",
   "metadata": {},
   "source": [
    "**Characterization** The likelihood function is the joint density of the data treated as a function of the parameter $\\theta$.\n",
    "\n",
    "**Nature** \n",
    "Putting in a value of theta does not give a number, but rather a statistic $\\Omega^n \\to \\mathbb{R}$ where $\\Omega$ is the sample space. \n",
    "- Putting in any partcular value from $\\Omega^n$ gives a real valued function of $\\theta$. \n",
    "- Not putting in such a value still allows for calculating formal derivatives. Thus \"maximization\" through differentiation is possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b810a5-8cb5-466a-84a3-b857aedcfaf4",
   "metadata": {},
   "source": [
    "**Definition** The **maximum likelihood estimator** (mle) of the parameter $\\theta$  is the value $\\hat{\\theta}^{\\text{MLE}}_n$ of $\\theta$ that (formally) \"maximizes\" ${\\cal L}_n(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297dfa9c-45d9-472c-ae42-726a6e84e8ef",
   "metadata": {},
   "source": [
    "**Definition** The **log-likelyhood function** is $\\cal{l}_n = \\ln \\cal{L}_n$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa602b9-7d1d-4ad3-9301-55da75db04ad",
   "metadata": {},
   "source": [
    "---\n",
    "e.g. If $X_1, . . . , X_n ∼ \\text{Bernoulli}(p)$  then \n",
    "$$\n",
    "{\\cal L}_n(p) = \\prod\\limits_{i=1}^n p^{X_i}(1-p)^{1-X_i} = p^S(1-p)^{n-S}, \\\\\n",
    "\\text{ and }\\\\\n",
    "{\\cal l}_n(p) =S\\log{p} +(n-S)\\log(1-p)\\\\\n",
    "\\text{ where } S = \\sum\\limits_{i=1}^n X_i.\n",
    "$$\n",
    "Solving\n",
    "$$\n",
    "{\\cal l'}_n(p) = 0  \\Leftrightarrow p = S/n \n",
    "$$\n",
    "The solution is now obviously $ S/n$, which is a way of writing $\\bar{X}_n$,  and so we define\n",
    "$$\n",
    "\\hat{p}^{\\text{MLE}}_n  = \\bar{X}_n.\n",
    "$$\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7b8072-96a6-42a6-a730-b3fea9d5827d",
   "metadata": {},
   "source": [
    "e.g. If $X=(X_1,...,X_c) \\sim \\text{Mult}(n,p)$ is the counts from each of $c$ categories where category $k$ has probability $p_k$ then the likelihood function is\n",
    "$$\n",
    "{\\cal L}(p) = \\prod\\limits_{k=1}^c (p_k)^{X_k}\n",
    "$$\n",
    "and the log likelyhood is \n",
    "$$\n",
    "l(p) = \\sum\\limits_{k=1}^c X_k\\ln p_k \\,.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ba94e8-da40-4001-9251-813426f3376c",
   "metadata": {},
   "source": [
    "The MLE is the solution to the optimization with constraint\n",
    "$$\n",
    "\\underset{p| \\sum p_k=1}{\\text{argmax}} \\, l(p) \\, \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e997bc-e8c4-48a6-bfa2-ff78ab5edcec",
   "metadata": {},
   "source": [
    "The lagrangian is \n",
    "\n",
    "$$\n",
    "L(p, \\lambda) = l(p) +\\lambda(\\sum_k p_k-1)\n",
    "$$\n",
    "\n",
    "with stationary conditions\n",
    "\n",
    "$$\n",
    "(\\forall k)\\,\\frac{x_k}{p_k}+\\lambda =0 \\\\\n",
    "\\sum_kp_k=1\n",
    "$$\n",
    "\n",
    "Rearranging the first line, summing over $k$, and inposing the second line gives\n",
    "\n",
    "$$\n",
    "\\sum X_k = -\\lambda \\iff \\lambda = -n \\, \n",
    "$$\n",
    "\n",
    "Therefore the MLE is \n",
    "\n",
    "$$\n",
    "\\hat{P}_l = \\frac{X_k}{n}\\,.\n",
    "$$\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1c82bc-efd0-4824-bd7f-bacb45f8baed",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb975f-89fd-42c1-8ae9-305d8bc569e2",
   "metadata": {},
   "source": [
    "**e.g.** Let $X\\sim f(x)$ where $F(x)= \\frac{x^3}{\\theta^3} I(x\\in[0,\\theta]) \\Rightarrow f(x) = \\frac{3x^2}{\\theta^3}I(x\\in[0,\\theta])$ and let $\\xi = F^{-1}(.5)$ be the median. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53a4262-ad75-4b36-8947-3d1ea3a343ad",
   "metadata": {},
   "source": [
    "The MLE $\\hat\\xi$ of $\\xi$ is the formal expression for function of the random sample $X_1,\\dots,X_n$ that maximizes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22262517-2453-4438-9abe-d68db5aa5fe0",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\cal {L}}(\\theta) = \\prod\\limits_{i=1}^n f(X_i)\\\\\n",
    "= \\frac{3^n}{\\theta^{3n}} \\prod\\limits_{i=1}^n X_i^2 I\\left(X_i\\in[0,\\theta]\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887a13e-cd80-4a28-a145-f7794126c185",
   "metadata": {},
   "source": [
    "The smaller $\\theta$ is the larger this likelihood until $\\theta$ dips below one of the $X_i$, since this brings $\\cal L$ to zero. To try to make this concrete, think in terms of data $(x_1,\\dots,x_n)$. That is, we need to impose the constraint on $\\theta$ that \n",
    "$$0\\leq x_1,\\dots,x_n \\leq \\theta \\\\\n",
    "\\Leftrightarrow 0\\leq\\text{min}\\{x_1,...,x_n\\} \\wedge \\text{max} \\{x_1,...,x_n\\}\\leq \\theta.$$\n",
    "The smallest allowed value of $\\theta$ is $\\text{max} \\{x_1,...,x_n\\}$. Abstracting away from particular data, the job of random variables, the maximizer of the likelihood function is \n",
    "$$\n",
    "\\hat{\\theta}^{\\text{MLE}}_n  = \\text{max} \\{x_1,...,x_n\\}.\n",
    "$$\n",
    "\n",
    "This leads to an MLE of the median $\\xi$; since \n",
    "$$\n",
    "\\xi = F^{-1}(0.5) = \\frac{(.5)^3}{\\theta^3} = 2^{-1/3}\\theta^{-3}\n",
    "$$\n",
    "the MLE of $\\xi$ is \n",
    "$$\n",
    "\\hat{\\xi}^{\\text{MLE}} = 2^{-1/3}\\left(\\text{max} \\{x_1,...,x_n\\}\\right)^{-3}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1b0bc4-e922-4f0c-89ec-fd33850c5142",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59bc292-2bfc-4ebb-9d46-fca1a8fb75d1",
   "metadata": {
    "tags": []
   },
   "source": [
    "MLEs have some amazing properties: \n",
    "1. Consistant: $\\hat{\\theta}_n \\stackrel{P}{\\to}\\theta \\text{ as } n\\to \\infty$\n",
    "2. equivariant: $g(\\hat{\\theta}^{\\text{MLE}}_n)$ is the mle of $g(\\theta)$;\n",
    "3. asymptotically Normal: $\\frac{\\hat{\\theta}^{\\text{MLE}}_n−\\theta}{\\hat{\\text{se}}\\left(\\hat{\\theta}_n^{\\text{MLE}}\\right)} \\sim N(0,1)$;\n",
    "4. asymptotically optimal: among all estimators, the mle has the smallest variance \n",
    "5. The mle is approximately the Bayes estimator. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1974500-3358-48ee-b223-969ed18d0c22",
   "metadata": {},
   "source": [
    "These thorems are nicely understood in terms of the following objects;\n",
    "\n",
    "**Definition:** The <u>score</u> function of the model ${\\cal F}=\\{f(\\cdot;\\theta) | \\theta \\in \\Theta\\}$ is \n",
    "$$s(\\theta) =  \\frac{\\partial}{\\partial \\theta} \\ln \\left(f(X,\\theta)\\right) \\,.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5caee1-b6d1-4f08-a63a-b9ce837eb7f3",
   "metadata": {},
   "source": [
    "Note that the expectation of the score function is zero; \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}[s(\\theta)] \n",
    " &= \\int s(\\theta) dF(x;\\theta) \\\\\n",
    " &= \\int\\frac{\\frac{\\partial }{\\partial \\theta} f(x;\\theta)}{f(x;\\theta)} f(x;\\theta) dx \\\\\n",
    "    & = \\frac{\\partial }{\\partial \\theta} \\int dF(x;\\theta)\\\\ \n",
    "    & = \\frac{\\partial }{\\partial \\theta} 1 =0\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8abd584-d296-4d18-8b01-7950b60a1f92",
   "metadata": {},
   "source": [
    "Note that I would prefer that the score be defined as under a random sample\n",
    "$$\n",
    "s_n(\\theta) = \\frac{\\partial}{\\partial \\theta}  \\sum_{i=1}^n \\ln(f(X_i;\\theta))\n",
    "$$\n",
    "since this is just the derivative of the log likelyhood, and then one can think of the score as the rate of change of the log likelihood with respect to parameter, and the MLE is the value of the parameter at which the score is zero. <a href src=\"https://en.wikipedia.org/wiki/Fisher_information#Definition\">Wikipedia's</a> page on Fisher information does define the score this way. I resolve this with the subscript $n$ notation. \n",
    "\n",
    "Also notice that if $\\theta$ is a vector then the gradient with respect to that vector is the appropriate generalization.\n",
    "\n",
    "What of the second derivative?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70b6649-0314-47fe-8127-f9fb1e549c41",
   "metadata": {},
   "source": [
    "**Definition:** The <u>Fisher information</u> of the model ${\\cal F}$ under the random sample $X^n$ is the function\n",
    "$$\n",
    "{\\cal I}_n(\\theta) = \\mathbb{V}(s_n(\\theta)) \\, . \n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30067b9d-a09f-4b8d-b2b6-c2e11bf8068e",
   "metadata": {},
   "source": [
    "How is this the second derivative? \n",
    "\n",
    "**Theorem:** \n",
    "${\\cal I}_n(\\theta) = - \\mathbb{E}[\\partial_\\theta s_n(\\theta)]$. \n",
    "\n",
    "**Proof:**\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathbb{E}\\left( \\partial_\\theta^2 \\ln f \\right) \n",
    " & = \\mathbb{E}\\left( \\frac{f f'' - f'f'}{f^2}\\right)\\\\\n",
    " & =\\mathbb{E}\\left( \\frac{f''}{f} - \\frac{f'^2}{f^2} \\right)\\\\\n",
    " & =\\mathbb{E}\\left( \\frac{f''}{f}     \\right) \n",
    "  - \\mathbb{E} \\left(\\partial_\\theta s \\right)\\\\\n",
    " & =\\int \\frac{f''}{f} f dx \n",
    "  - \\mathbb{E} \\left(  s'^2 \\right)\\\\\n",
    " & = \\partial_\\theta^2 \\int  f dx\n",
    "   - \\mathbb{E} \\left( s'^2 \\right)\\\\\n",
    " & =  - \\mathbb{E} \\left( s'^2 \\right)\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668c0073-ec3f-4733-9df3-7576f3f14b9c",
   "metadata": {},
   "source": [
    "So, the Fisher informatino matrix is alternatively\n",
    "- The variance of the score, where the score is therate of change of the log likelyhood with respect to parameter(s).\n",
    "- The negative Hessian of the log likelyhood, thus giving the concavity of the log likelyhood.\n",
    "\n",
    "There is also an information theoretic interpretation that I do not know yet. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db75518-80b8-47b8-83f1-b876ed750755",
   "metadata": {},
   "source": [
    "## Cramer-Rao Lower bound on variance of estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8020111f-33e8-4ce8-b4bb-63bd7b481984",
   "metadata": {},
   "source": [
    "**Theorem:** (Cramer-Rao Lower Bound) \n",
    "Let $T(X_1,\\dots,X_n)$ be an an estimator of $\\theta$ such that differentiation and integration of the joint distribution $f_\\theta(x_1,\\dots x_n)$  with respect to $\\theta$ are defined. The varience of $T$ is bounded in terms of the  score function $S=\\frac{d}{d\\theta} \\log f_\\theta $ as\n",
    "$$\n",
    "\\mathbb{V}[T] \\geq \n",
    "\\frac{ \n",
    "\\left(  \\frac{d}{d\\theta} \\mathbb{E}[T] \\right)^2\n",
    "}\n",
    "{\\mathbb{E}[S^2]}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d4258f-87d2-4c65-8518-818a835a3863",
   "metadata": {},
   "source": [
    "**Proof:**\n",
    "Note that the expectation value of the score function is zero; letting $x^n$ denote $(x_1,\\dots,x_n)$ we have\n",
    "$$\n",
    "\\mathbb{E}[S] \n",
    "= \\int \\left( \\frac{d}{d\\theta} \\log \\left(f_\\theta(x^n)\\right) \\right) dF_\\theta(x^n)\n",
    "= \\int  \\left(\\frac{d}{d\\theta} \n",
    "f_\\theta(x^n) \\right)\n",
    " \\frac{1}{ f_\\theta(x) }  f_\\theta(x^n) dx^n\n",
    " =\\frac{d}{d\\theta} 1 = 0 \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aee660-0550-4b3d-b34c-ddf7748cf7fa",
   "metadata": {},
   "source": [
    "Let $\\langle \\cdot,\\cdot \\rangle = \\int \\cdot \\cdot dF_\\theta(x^n)$ denote note the expectation of the product of two random variables over $f_\\theta$. Them by the Cauchy-Schwartz inequality \n",
    "$$\n",
    "\\langle T-\\bar T , S -\\bar S \\rangle^2 \\leq \n",
    "\\langle T-\\bar T, T-\\bar T \\rangle \\langle S - \\bar S  , S - \\bar S \\rangle\\\\\n",
    "\\Leftrightarrow (\\text{Cov}[T,S])^2 \\leq \\mathbb{V}[T] \\mathbb{V}[S]\\\\\n",
    "\\Leftrightarrow \\mathbb{V}[T] \\geq \\frac { \\left(\\text{Cov}[T,S]\\right)^2}{\\mathbb{V}[S]}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048591e-28bd-4634-be81-ede70d7dfea6",
   "metadata": {},
   "source": [
    "The numerator is the square of\n",
    "$$\n",
    "\\text{Cov}[T,S] = \\mathbb{E}[(T-\\bar T)(S-\\bar S)] \n",
    "=\\mathbb{E}[(TS-\\bar T S] \n",
    "=\\mathbb{E}[(TS] \n",
    "= \\int T S dF_\\theta(x^n)\\\\\n",
    "=\\int T \\left(  \n",
    "\\frac{ \n",
    "\\frac{d}{d\\theta} f_\\theta}{f_\\theta}\n",
    "\\right) f_\\theta dx^n\n",
    "=\\frac{d}{d\\theta}\\mathbb{E}[T].\n",
    "$$\n",
    "The denominator \n",
    "$$\\mathbb{V}[S] = \\mathbb{E}[S^2] - \n",
    "(\\bar S)^2= \\mathbb{E}[S^2]. \\square\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406b0b1a-2d99-409d-849c-d25c34e06d84",
   "metadata": {},
   "source": [
    "## 9.13.3 Exponential Families\n",
    "Fix functions \n",
    "- $h:\\mathbb{R} \\to \\mathbb{R}$ \n",
    "- $T:\\mathbb{R} \\to \\mathbb{R}$ \n",
    "- $\\eta:\\mathbb{R}^n \\to \\mathbb{R}$   \n",
    "- $B:\\mathbb{R}^n \\to \\mathbb{R}$ \n",
    "\n",
    "and you have a paramterized model \n",
    "$\\mathfrak{F} = \\left\\{ f(x;\\theta) = h(x)e^{\\eta(\\theta)T(x)−B(\\theta)} | \\theta \\in \\Theta\\right\\}$ \n",
    "with parameter space $\\Theta \\subseteq \\mathbb{R}^n$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71702568-3386-46ca-b53f-ccad78cbfabc",
   "metadata": {
    "tags": []
   },
   "source": [
    "### e.g.s \n",
    "1. For fixed $n$ the Binomial  distributions \n",
    "$\\left(\\begin{array}{c} n\\\\x \\end{array}\\right) \n",
    "\\theta^x(1−\\theta)^{n−x}  \n",
    "= \\left(\\begin{array}{c} n\\\\x \\end{array}\\right) \n",
    " \\exp\\left\\{ x\\log\\left(\\frac{\\theta}{1-\\theta } \\right) +n\\log(1−\\theta)\\right\\}$\n",
    " has \n",
    " - $h(x) = \\left(\\begin{array}{c} n\\\\x \\end{array}\\right)$ \n",
    "- $T(x)=x$ \n",
    "- $\\eta(\\theta)= \\log\\left(\\frac{\\theta}{1-\\theta } \\right)$   \n",
    "- $B(\\theta) = - n\\log(1−\\theta)$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb96ab3-2b3d-4feb-929b-6dcbe4986913",
   "metadata": {
    "tags": []
   },
   "source": [
    "2. Poisson distributions \n",
    "$f(x;\\theta)= \\frac{\\theta^x e^{-\\theta}}{x!} = \\frac1{x!}e^{x\\log(\\theta)- \\theta}$\n",
    " has \n",
    " - $h(x) = \\frac1{x!}$ \n",
    "- $T(x)=x$ \n",
    "- $\\eta(\\theta)= \\log(\\theta)  $   \n",
    "- $B(\\theta) =\\theta $ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b7b7f6-163e-4a4e-b1fb-d63521e9bc49",
   "metadata": {
    "tags": []
   },
   "source": [
    "An exponential family can be re-written as \n",
    "$$f (x; \\eta) = h(x)e^{\\eta T(x)−A(\\eta)}$$ \n",
    "with \n",
    "$$A(\\eta) =  \\log \\int h(x)e^{ \\eta T(x)} dx$$ \n",
    "where $A$ is pretty slick.\n",
    "\n",
    "( I can t follow how that integral in that exponential does what is described.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f938075-1a8b-4659-8933-5c3d8303a5c4",
   "metadata": {},
   "source": [
    "**Theorem** Let $X$ have density in an exponential family. Then, \n",
    "$\\mathbb{E}(T (X)) = A'(\\eta)$, and  $\\mathbb{V}( T(X)) = A''(\\eta)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea203042-2979-42ea-af75-b1736113f5dc",
   "metadata": {},
   "source": [
    "**Definition** $\\eta = \\eta(\\theta)$ is called the **natural parameter** of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328bd974-1dd8-4996-93ba-13fe040af2fb",
   "metadata": {},
   "source": [
    "**Definition** A statistic is a **sufficient statistic** of a sample with respect to a statistical model and its associated unknown parameter if no other statistic that can be calculated from the same sample provides any additional information as to the value of the parameter. \n",
    "\n",
    "**Definition** The statistic $T_n(X^n):=\\sum_{i=1}^n T(X_i)$ where $T$ is from an exponential family is called the **natural sufficient statistic** of the model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f50798-db9a-44bf-8135-dade703c3046",
   "metadata": {},
   "source": [
    "---\n",
    "I was unable to wrap my head around what a sufficient statistic is from Wasserman alone, so I asked ChatGPT. It says an alternative definition is as follows. \n",
    "\n",
    "**Definition:** A statistic $T_n(X^n)$ is a <u>sufficient statistic</u> for the parameter $\\theta$ of the model ${\\cal F}= \\{ f_\\theta | \\theta \\in \\Theta\\}$ if $f_\\theta(X^n | T(X^n)=t)$ is independent of $\\theta$.\n",
    "\n",
    "For an arbitrary exponential model, the joint distribution\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f_\\theta(x^n | T(X^n)=t) \n",
    "&= \\frac1{\\cal N}\\prod_i h(x_i) \\exp\\left( \\eta(\\theta) \\sum_i T(X_i) -nB(\\theta)  \\right) \\\\ \n",
    "&= \\frac1{\\cal N}\\prod_i h(x_i) \\exp\\left( \\eta(\\theta) \\sum_i t -nB(\\theta)  \\right) \\\\ \n",
    "&= \\frac{\n",
    "            \\prod_i h(x_i) \\exp \\left( \n",
    "                \\eta(\\theta) \\sum_i t -nB(\\theta)  \n",
    "                \\right) \n",
    "        }\n",
    "        {\n",
    "        \\int \\prod_i h(x^n) \\exp\\left( \\eta(\\theta) \\sum_i t -nB(\\theta)  \\right) dx^n\n",
    "        }\\\\ \n",
    "&=\\prod_i h(x_i) \n",
    "\\end{align}\n",
    "$$ \n",
    "where ${\\cal N}$ stands for a normalization factor. \n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8094c520-b8ae-42a9-b9f7-d47f6950ec12",
   "metadata": {},
   "source": [
    "**Theorem** (Fisher's factorization theorem) The statistic $T$ of samples $x$ of $ X \\sim f_\\theta(x)$ is sufficient for the parameter $\\theta$ if and only if \n",
    "$  f_{\\theta }(x)=h(x) g_{\\theta }(T(x))$ \n",
    "for some nonnegative functions $g$ and $h$. \n",
    "   \n",
    "**Interpretation** No additional information can be obtained about $f$ beyond the information from $T(x)$ if $f$ be factored into a product such that one factor, $h$, does not depend on $\\theta$ and the other factor, which does depend on  $\\theta$, depends on $x$ only through $T(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bc87a6-ee01-44c3-848e-25ad7d796bde",
   "metadata": {},
   "source": [
    "**e.g.** The Poisson distributions have $T(x)=x$, as seen above, and factorization of the PDF $f (x; \\eta) = \\frac{\\theta^x e^{-\\theta}}{x!}= \\frac{1}{x!} e^{\\eta x−e^\\eta } =h(x)g_\\theta(T(x)) $ with $\\eta = \\log (\\theta)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ff6c55-f905-4b0a-85e9-ac99df25f2b8",
   "metadata": {},
   "source": [
    "**e.g.** This sufficient statistic formulation of exponential families makes it easy to see that the product of two distributiions from the same family is a distribution from another family. Let $X_1,...,X_n$ be iid from an exponential family and $x^n = (x_1,\\dots,x_n)$. Then $f(x^n;\\theta)$ is an exponential family:\n",
    "$$\n",
    "f(x^n; \\theta) = h_n(x^n)e^{\\eta(\\theta)T_n(x^n)−B_n(\\theta)}\n",
    "$$ \n",
    "where \n",
    "$$\n",
    "h_n(x^n) = \\prod_i h(x_i),~\\\\\n",
    "T_n(x^n) = \\sum_i T(x_i) \\text{, and }\\\\\n",
    "B_n(\\theta) = nB(\\theta).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bfa4f0e-0154-4a88-a14e-2723dd66029d",
   "metadata": {},
   "source": [
    "#### Mutivariable exponential families\n",
    "\n",
    "If $\\theta = (\\theta_1,...,\\theta_k)$ is a vector, then we say that $f(x;\\theta)$ has exponential family form if \n",
    "$$ f(x;\\theta) = h(x)\\exp\\left\\{ \n",
    "\\sum\\limits_{j=1}^k \\eta_j(\\theta) T_j(x) - B(\\theta).\n",
    "\\right\\}$$\n",
    "\n",
    "Again, $T = (T_1,...,T_k)$ is sufficient for $\\theta$. An iid sample of size n also has exponential form with sufficient statistic \n",
    "$\\left( \\sum\\limits_{i=1}^n T_1(X_i),..., \\sum\\limits_{i=1}^n T_k(X_i)\\right)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb85774-2427-454c-8b48-aa71624b4bd5",
   "metadata": {},
   "source": [
    "e.g. The normal family \n",
    "$$\n",
    "\\frac{1}{\\sqrt{2\\pi } \\sigma} \\exp\\left\\{ \\frac{-(x-\\mu)^2}{ 2\\sigma^2} \\right\\}\\\\\n",
    "=\\exp\\left\\{ \\frac{-(x-\\mu)^2}{ 2\\sigma^2} - \\frac12 \\log( 2\\pi \\sigma^2)  \\right\\}\\\\\n",
    "=\\exp\\left\\{ \\frac{\\mu}{\\sigma^2} x -\\frac1{2\\sigma^2} x^2 -\\frac{\\mu^2}{2\\sigma^2} - \\frac12 \\log( 2\\pi \\sigma^2)  \\right\\}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54ba444-b178-4b31-9447-2e25249108d0",
   "metadata": {},
   "source": [
    "has \n",
    "$$\\eta_1 = \\frac{\\mu}{\\sigma^2},~T_1(x) =x\\\\\n",
    "\\eta_2 =- \\frac{1}{2\\sigma^2},~T_2(x) = x^2\\\\\n",
    "B(\\theta) = -\\frac{\\mu^2}{2\\sigma^2} -\\frac12 \\log (2\\pi\\sigma^2),~ h(x)=1 \n",
    "$$\n",
    "so that with n iid samples, $\\left(\\sum\\limits_{i=1}^n X_i,\\sum\\limits_{i=1}^n X_i^2\\right)$ is sufficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae265e33-b0f4-4783-a3c5-3b4bcdd858f7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This was not enough to convince me that exponential families are awesome. So I asked ChatGPT and got the following \n",
    "\n",
    "#### Sufficiency of Statistic \n",
    "\n",
    "$T$ is a sufficient statistic.\n",
    "\n",
    "#### Conjugate priors\n",
    "\n",
    "In Bayesian statistics, if the prior is from ${\\cal F}$ then the posterior if from ${\\cal F}$. \n",
    "\n",
    "#### Closure under sampling\n",
    "\n",
    "$T(X)$ is from the same exponential family as $\\sum_i T(X_i)$.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76764ce6-6b46-4bca-8f88-dc4cb6bcc237",
   "metadata": {},
   "source": [
    "### Expectation-Maximization Algorithm (EM) \n",
    "\n",
    "Suppose we have data $Y$ whose density $f(y;\\theta)$ leads to a log-likelihood that is\n",
    "hard to maximize. But suppose we can find another \"hidden\" random variable $Z$ such that $f(y;\\theta) =\\int f(y,z;\\theta) dz$ is easy to maximize.\n",
    "\n",
    "We then set up a sequence of approximations $\\theta^i$  of $\\theta$ using the function \n",
    "$$\n",
    "J(\\theta|\\theta^j) \n",
    "= \\mathbb{E}_{\\theta^j} \\left(  \\log \\left( \n",
    "\\frac{f(Y^n,Z^n;\\theta   )}\n",
    "     {f(Y^n,Z^n;\\theta^j)} \\right) \\,\n",
    "     \\vert~ Y^n = y^n \\right)\n",
    "$$ \n",
    "where the expectation is over \n",
    "$Z^n$ (so $\\theta$ and $X$ are treated as constant by $\\mathbb{E}_{\\theta^j}$.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5e5e3-7739-4562-a066-e66ce89496a7",
   "metadata": {},
   "source": [
    "with the following algorithm\n",
    "\n",
    "0. Pick a starting value $\\theta_0$. Now for j = 1,2,..., repeat steps 1 and 2 below:\n",
    "1. Calculate $J(\\theta|\\theta^j)$ \n",
    "2. Find $\\theta_j+1$ to maximize $J(\\theta| \\theta_j)$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298fdf8-00e4-482f-b223-f205fae56d16",
   "metadata": {},
   "source": [
    "Note: I learned later that $J$ as defined above is the negative of the evidence lower bound, and the EM tries to maximize the evidence lower bound. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7da1f99-3faa-475c-9794-1f58f676c462",
   "metadata": {},
   "source": [
    "# Ch10 Hypothesis testing and p-values \n",
    "Suppose that we partition the parameter space $\\Theta \\subseteq \\mathbb{R}^k$ into two disjoint sets $\\Theta_0$ and $\\Theta_1$ and that we wish to test\n",
    "$$H_0 :\\theta \\in \\Theta_0 \\text{ null hypothesis },\\\\ \n",
    "  H_1 :\\theta \\in \\Theta_1 \\text{ the alternative  }.\n",
    "$$\n",
    "For notational clarity, let $\\theta^*$ be the true value of $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c08379-3fbc-439a-b418-6fb6e80bdfd4",
   "metadata": {},
   "source": [
    "**Definition** If we reject a hypothesis by the criteria of the form \n",
    "$X^n\\in R$ for some $R \\subset \\text{Range}(X^n)$, then we call $R$ the **rejection region**.\n",
    "\n",
    "**Note:** Typically a rejection region is specified by use of a statistic $T(X^n)$. A possible form is $R = \\{ x^n  \\,:\\,  T(x^n)> c\\}$ for some $c$.\n",
    "\n",
    "**e.g.** Let $X_1,\\dots,X_n \\sim N(\\theta,1)$ and consider testing $H_0: \\theta = 0$ with the rejection region \n",
    "$R = \\{x^n \\,:\\, |\\bar{x}_n| >c\\}$. That is, we will reject the hypothesis that the mean of the distribution is zero if the observed mean is larger than some value $c$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c00a73d7-7fab-435e-9789-ef1b67050c51",
   "metadata": {},
   "source": [
    "How can we construct rejection regions that give us confidence we correctly reject a  a hypothesis?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fd0f9-ffec-421b-9a52-8853d67664cf",
   "metadata": {},
   "source": [
    "**Definition**: If $\\theta^* \\in \\Theta_0$ but one rejects $H_0$ then one makes a **type 1 error**. \n",
    "\n",
    "**Definition**: If $\\theta^* \\in \\Theta_0^C$ but one doesn't reject $H_0$ then one makes a **type 2 error**. \n",
    "\n",
    "We want to construct experiments that  minimize the probability of type 1 and type 2 errors. Part of that is constructing rejection regions with a clear relationship between those error types. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f84070-27ca-45d2-a2a3-cdd64dccdf11",
   "metadata": {},
   "source": [
    "---\n",
    "## Power Function\n",
    "Warning: the definitions of power, size, and level vary between sources. This is my best attempt to keep Wasserman's notations. \n",
    "\n",
    "**Definition** The **power function** of a test with rejection region $R$ is the function $\\beta: \\Theta \\to [0,1]$ such that \n",
    "$\\beta(\\theta) = \\mathbb{P}_\\theta (X^n \\in R)$. \n",
    "\n",
    "**Interpretation:** The power function is the probability of rejecting $H_0$ given that (a) the rejection region is $R$ and that (b) the distribution $F_\\theta$ from the model ${\\cal F} = \\{F_\\theta : \\theta \\in \\Theta \\}$ is used to calculate probability. \n",
    "\n",
    "The power function has different interpretations in different subsets of the model parameter space $\\Theta$;\n",
    "- $\\beta|_{\\Theta_0} (\\theta)$ is the probability of a type 1 error, \n",
    "    - the probability of rejection when $\\theta$  is actually in the null hypothesis set, \n",
    "- $\\beta|_{\\Theta_0^C}(\\theta)$ is the probability of correctly rejecting $H_0$. \n",
    "    - the probability of rejection when $\\theta$ is actually not in the null hypothesis set. \n",
    "    - thus $1-\\beta|_{\\Theta_0^C} (\\theta)$ is the probability of a type 2 error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985b7552-f729-4a37-ac88-3f8d95a7fa3f",
   "metadata": {},
   "source": [
    "\n",
    "A good test is designed so that both type 1 and type 2 errors are low proabbility;\n",
    "$$\n",
    "\\beta(\\theta) \\approx \\left\\{  \\begin{array}{c}\n",
    "1 \\text{ if } \\theta \\in \\Theta_0^c \\\\ \n",
    "0 \\text{ if } \\theta \\in \\Theta_0  \n",
    "\\end{array} \\right.$$\n",
    "A nice example \n",
    "- $\\Theta_0 = [0,4]$\n",
    "- $\\Theta_0 \\cup \\Theta_0^c = [0,10]$\n",
    "- $\\beta:[0,10]\\to [0,1]$ with $\\beta(\\theta)=\\sigma(\\theta-5)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "976fe393-3dc6-4f92-b0a8-083853dbd6e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEpCAYAAAB1Fp6nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzA0lEQVR4nO3deXwV1fnH8c9D9hASloR933dRNhVR1Ir70paK1rW41a3W/qq2aqtttdVW61Zt1brvO7jjimJdIAgKQTYhQNgC2ci+nt8fM9FLDBAgydzkft+v133l3pm5M8/c3DvPnHNmzjHnHCIiEpnaBB2AiIgER0lARCSCKQmIiEQwJQERkQimJCAiEsGUBEREIpiSgIQdMzvXzD4JOo7WysyKzKx/E6y3u5m9Z2YFZrbUzI6oMz/On97Vf21mdquZ5ZrZOjM7PWTZk8zs2caOUX5ISSDCmFmmmZX6B4Lax7+CjquxmNkcMyvz92ubmb1sZt2CjquWmT1qZhV1Pv/pTbi9OWZ2fug051ySc251E2zuL0AR0Bk4H3iszvwLgY+dc5v91+cAxwODgJ8A95vZQD/GV4GRZja6CeKUEEoCkelE/0BQ+7gs6IAa2WXOuSRgMNAeuCOIIMwseiez/l7n83+uWQNrOuOAx5xz5c65T4EYM0sLmX8R8ETI6wuAfzrncpxz6cDLwC9C5j+DlzikCSkJyHfM7N9m9mLI61vN7H2/2N7BzF43s61mluc/7xmy7Bwzu8nMPvXPbl8zs05m9pSZbTez+WbWN2R5Z2a/MrPV/hn7P8ys3u+jmQ01s3f9aoPlZnZqQ/bHOZcLvASM9NdzsB9Hgf/3YH/64Wa2OGR775nZvJDXn5jZKf7z7mb2kv85rDGzX4Usd6OZvWhmT5rZduDchsTpv/dRM7sp5PUUM8sKeZ1pZr81s6/9+J8zs/iQ+Seb2SL/s/7WzI4xs5uBycC/Qkt8/mc/0H+eYmaP+/uz1syur/0/mF8tZ2a3+f/zNWZ27C52IwUo9N8bB3QAKv3XvYEBwBf+awPGA/8Lef88YELI6zl4JQVpQkoCEur/gNH+j38ycB5wjvP6FmkDPAL0AXoDpUDdaqTTgLOAHng/+M/893QEvgFuqLP8j/HOHg8ATgZm1A3IzNoC7wJP41UznA7cZ2YjdrczZpYK/BRYaGYdgTeAu4FOwD+BN8yskx/nQDNL9c/eRwI9zaydmSUAY4G5/sHxNeArfx+PBH5tZkeHbPZk4EW8EshTu4txD50KHAP0A0bjJxkzmwA8Dlzlb/dQINM5dx0wF79ktJMS3z14B+/+wGHA2ex4Nj4RWA6kAn8HHvIP4DtlZknAP4BvnHP5/uRRwGrnXJX/uhMQA6wPees6oGvI62+AvmaWvKvtyb5REohMM80sP+RxAYBzrgQ4E+8A+SRwuXMuy5+X45x7yTlX4pwrBG7GO2iEesQ5961zrgB4C/jWOfee/8N/Adi/zvK3OudynXPrgDvxDvB1nYB3QHvEOVflnPsS7+x+2i72724zy8c7WG8CfoN3RrnSOfeEv55ngGV4VWNlQDrewXMc8DXwCTAJONB/Xw7emWuac+7PzrkKv179QbzkV+sz59xM51yNc650J/H9NuSz37aL/fjBfjnnNvolnNeAMf7084CHnXPv+tvd4JxbtruVmVkUMB34vXOu0DmXCdyOl8hrrXXOPeicq8ar4+8GdNnNqrcAlwMfhZTu2uOXEurYWPtZAHUbgmuXb7+7fZG9t7M6S2ndTnHOvVffDOfcPDNbjXfW/XztdDNLxKtbPwavmA/Qzsyi/AMEeD/+WqX1vE6qs7nQs8C1QPd6QuoDTPQPErWi2bFuua5fOef+GzrBzLr72wi1Fu+MHuAjYAqQ5T/Pw0ty5f7r2li614klCu9su7592pnbnHPXN2C5ujaHPC/h+8+rF/DmXqwvFYhlx88l9DPZYZvOuRK/EFD3/1hXMjACeBT4I3Aj3ufZLmSZHLyqot7Oue3gVWkBl4YsU7t8fgP2RfaSSgKyAzO7FIgDNgJXh8z6P2AIMNE5l4x31gywy6qB3egV8ry3v8261gMfOefahzySnHMX7+G2NuIdxEP1Bjb4z2uTwKH+84/wksBhfJ8E1gNr6sTSzjl3XMg697Zb3mIgMeR1150tWI/1eNVv9dlVPNvwDsShn0voZ7JXnHPVzrmv8aqoxvuTvwb6+9Vt+FWM84CBIW8d4k+rNQyvFLh9X+KRXVMSkO+Y2WDgJrwqobOAq81sjD+7Hd7ZfL5fv163fn9vXGVeg3Mv4AqgvqtkXgcGm9lZZhbjP8ab2bA93Nab/np+bmbR5l2WOdxfP8CneAehCcA851wGfikE+NhfZh6w3cyuMbMEM4sys5FmNp59twg4zsw6mncd/a/34L0PAb8wsyPNrI2Z9TCzof68LXj1/T/gl+CeB2722z/64FWdPbm3OwHM8PehHV5V3lf+trKAlezY8Psg8Be/cXow3pVAj4TMPwyvWlGakJJAZHrNdrxO/RX/DO1JvHr6r5xzK4FrgSf8Kz3uBBLwzh4/B95uhDhmAQvwDoBv4B3MduC3P0zFq3ffiFc9cSteaaXB/Dr9E/BKNDl4pZwTnHPb/PnFwJdAhnOuwn/bZ3h14tn+MtXAiXh18WvwPov/4jWs7qsn8A6YmcA71J8Q6+Wcm4fXmHsHUIBXcqk9u78LmOZf3XN3PW+/HK8UshqvHeRp4OG92wUAegKr8PZjG97/qtb97Nje8DiQgVcF9QHwB+fctyHzT/ffI03INKiMBMHMHDDIObcq6FikcZhZJnD+ztqb/JOJhcCRzrlNu1nXicBZzrkGXQ4se08NwyLSLJxz5XhVcA1Z9jW8K6Ckiak6SEQkgqk6SEQkgqkkICISwVpUm0Bqaqrr27dv0GFImFq+fDkAQ4YMCTgSkfCyYMGCbc65tPrmtagk0LdvX9LT04MOQ8LUlClTAJgzZ06gcYiEGzOre7f8d1QdJCISwZQEREQimJKAiEgEUxIQEYlggSYBM3vYzLLNbEmQcYiIRKqgSwKP4vVPLyIiAQg0CTjnPgZyg4xBRCSShf19AmZ2IV4/4/Tu3TvgaEREGld5VTWFZVUUlVVRVF5FYVkVxeVVFFdUUVxeTUlFFSUV1fRPa8sJo+sbfG/fhH0ScM49ADwAMG7cOHV0JCJhyTlHQWkl24rK2VZUQW6x98grriC3pIL8kkrySyooKK0kv7SS7aVVFJZVUl5V06D1n7hf98hMAiIiQauoqmFTQSkb8kvZXFDGpoIyNheUsWV7GVsKy8neXsa2onIqq+s/T02Ki6Z9Yoz3SIilW0oCyQkxJCdEkxwfQ7v4aNrFR9M2Npqk+GiS4qJpG+f9TYyNIiEmiuiopqm9VxIQEQGKyqvI3FbM6m3FZG4rZm1OCetyi1mfW8qWwjLqdrickhBD1+R4OifHMTAtlbR2caS1iyM1KZbUpDg6to2lU9tY2ifGEhsd9DU4OxdoEjCzZ/AG9041syzgBufcD4YYFBFpLCUVVazYUsQ3m7azYkshq7KLWLmliM3by3ZYrktyHH06tmXSwFR6dEigZ4cEerRPoFtKPN1SEkiIjQpoDxpXoEnAOXd6kNsXkdatpKKKr7MKWJxVwOINBSzZUMCanOLvzuoTY6MY2DmJgwd2YkBaEgPS2tIvNYneHRNbzUF+d1QdJCKtxsb8UuZn5jJvTS4L1+WzfEsh1TXeEb97Sjwje6Rw8pgeDO3WjmFdk+nZIYE2bSzgqIOlJCAiLda2onI+/TaH/63cxv++3UZWXingNcTu37s9lw4bwJje7Rndsz2pSXEBRxuelAREpMWoqXEsyspnzrJsPly+lcUbCgBoFx/NQf07MWNSPyb068iwbslERfgZfkMpCYhIWKusruHTb3OYnbGZd5duYWthOW0MDujdgd9OHczkQWmM7JGig/5eUhIQkbBTU+OYl5nLq19t5K3Fm8grqSQxNoopQ9KYOrwrU4ak0T4xNugwWwUlAREJG+tzS3hhQRYvLchiQ34pCTFR/Gh4F04c3Y1DB6cRHxMZV+w0JyUBEQlUVXUN7y/L5snP1zJ35TbM4JCBqVx9zBCOGt6FxFgdppqSPl2RRnTVC1/xwbJsOiXF8s6Vh+10uf6/f4MhXZOprqlhYOckbv/ZGBJioyirrObsh+fxzAUHsjG/lC/X5XHymB5NGvOkWz7gtcsPoWPbWIb/8W2W/vkYcorKufL5r3h8xoQm225+SQVPfbGOJz9fy6aCMrqnxPObowbz07E96dE+ocm2KztSEhBpRNPG9uScg/vym+cX7XK5+Jgo3rpiMgBXPLuQp75Yy/mT+/N8+nqOGdGVqDZGVl4psxZtbPIkUJ9OSXF0bhdHemYu4/p2bNR1r88t4aFP1vDc/PWUVlYzeVAqfzppBEcM7dxk/ePIzikJiDSiif07sT63ZI/eM75vR5Zt3g7AzIUbuOu0/QG49e1lfJtdxLF3zeWnB/RgdsZmbjxpBCO6pwDw039/yk2njOTtJZtZl1vid2xWykWHDeD0CV636/d/9C1vLN5ERVUNU0d05TdHDW5wXFOHd2Hmog2NlgQytxVz74ereHnhBtoYnDymB+dP7sfQrsmNsn7ZO0oCIgGqqq5hzvKtHDYkjYqqGtblltKrYyIA1xwzlAfnrubhc8cD0D4xlhcXZDGiewqrtxZRUVXDsG7JvL1kM99s2s7MSydRUlHN8XfP5YihnVm+uZDMnGJmXToJ5+D8x9P5YnUOE/t3alBso3u25/Z3VuzzPmbllXDHuyt5ZWEWMVFtOPugPlx06AC6psTv87pl3ykJiASgrLKaY++aC8CEvh2YPq4XeSUVJCfs/Cd5/Khu3PPBSq49bhjPp2cxbWzP7+ZNHd6F+Jgo4mOiOKh/Jxatzyc9M5ePV2zjuLs/Abx+dDJzihucBDolxbKlsGz3C+5ETlE5//pwFU99vg4MfjGpHxcd1p/O7XTwDydKAiJNbGN+Kec9lg7AGRN7c+aBfXZoE6gVHx1FeeXOBxhJiI3ikIGpvLt0C28s3shrlx3y/Uzb8UYpA5yDSw4fwBkT++xV3OVVNcRH7/klmZXVNTz2aSZ3vbeS4ooqpo3tya9/NJjuauwNS0oCIk2se/uEHxzw65OSGEONc5RVVhMfE0VSXDRF5VU7LHPa+N6c99h8xvfruMPNUu8u3cIlUwZQWlHN56tzuObYocTHRHH7uys4ZUwP2sZFs7mgjOgoa3AfOmu2FjO4a7s92tePV2zlT69l8O3WYg4dnMYfjh/GoC57tg5pXkoCIo3o8mcW8vnqHPKKKzjwr+9z5VGDmD6+4WNjTx6USnpmHocMSmVot3ZEtzGOufNjpo3tyfmT+zOqZwpJ8dH8LKQqCGBMrxRmPDqfjfmlXH7kILokx9MlOZ5V2UX85L5PAUiMi+LO6WManAQ+W72NI4akNWjZrYXl/Pn1pbz21Ub6pbbl4XPHcfiQzpipK4dwZ67ucDlhbNy4cS49PT3oMCRMTZkyBYA5c+YEGse+WLKhgIc+WcMd08fUO3/L9jJOe+Bz3v/NYd91gXzHuytoGxfFhYcOaNRYTv3PZzx49jhSEmN2uoxzjufmr+evb35DWWUNlx4+kF9O6U/cXlQjSdMxswXOuXH1zVNJQCSMjOyRwkH9O1Fd437QIdpLC7K47Z3lXH/88CbvAz+nqJzzJvfbZQLYVFDKNS8t5uMVW5nYryN//ckoBqQlNWlc0vhUEpBWozWUBFoC5xwzF23gj7MyqKp2XHv8MM6c2FtVP2FMJQERaRRF5VVc/8piZi7ayLg+HbjtZ/vRN7Vt0GHJPlASEJEGWZxVwOXPfMm63BJ+c9RgLj18oPrwbwWUBERkl5xzPDNvPTe+mkGnpFievfAgJvRr3P6EJDhKAiKyU2WV1dwwK4Pn0tdz2OA07pw+hg5tNZhLa6IkICL12lxQxkVPpPNVVgGXHT6QK48arOqfVkhJQER+YMmGAs57bD5FZVXcf9ZYjh7RNeiQpIkoCYjIDt7J2MwVzy6iQ2IML158MMO6qavn1kxJQES+8/hnmdzwagaje6Tw4Nnj6JysHj9bOyUBEcE5xz/fXcE9H6ziR8O6cM/p+5MQq64fIoGSgEiEq65xXD9zCc/MW8ep43ry1x+P0jCPEURJQCSCVVbXcOVzi3j9601cevgAfjt1iLp/iDBKAiIRqqKqhsuf+ZLZGVv43bFD+eVhjdsLqbQMSgIiEai8qppLnvyS95dl88cThjPjkH5BhyQBURIQiTAVVTXfJYCbThnJmQfu3fCT0jqo9UckglRV13DFswuVAOQ7SgIiEaK6xvF/L3zFW0s284cThisBCKAkIBIRnPMuA521aCNXHT2E89QGID4lAZEIcMe7K3hm3joumTKASw8fGHQ4EkaUBERaucc+zeTuD1Zx2vheXHX0kKDDkTCjJCDSir3x9SZufC2DqcO7cNMpI3UjmPyAkoBIK7VgbS5XPr+IcX06cPfp+6srCKmXvhUirdDanGIueHwBPdon8MBZ44iPUWdwUj8lAZFWJr+kgl88Mp8a53j43PEaDlJ2SUlApBWprK7h4ie/JCuvlAfOGke/1LZBhyRhTt1GiLQiN72+lM9W53D7z/ZjQr+OQYcjLYBKAiKtxLPz1vHYZ2s5/5B+/HRsz6DDkRZCSUCkFUjPzOUPs5YweVAqvzt2aNDhSAuiJCDSwmVvL+Pip76kR/sE/nX6AboUVPaI2gREWrDK6houffpLisqqePK8iaQkxgQdkrQwSgIiLditby1jfmYed502hiFd2wUdjrRAKjeKtFBvfL2J/36yhnMO6sPJY3oEHY60UEoCIi1Q5rZirnnpa/bv3Z7rjh8edDjSgikJiLQw5VXVXPbMl0S1Mf718wOIjdbPWPae2gREWpi/vbmMJRu28+DZ4+jRPiHocKSF0ymESAvy9pLNPPppJjMm9eOo4V2CDkdaASUBkRZiY34pV7/4FaN7puiGMGk0SgIiLUB1jePK5xZRVeO4+7T91Q4gjUZtAiItwAMfr+aLNbn8fdpo+qpnUGlEOp0QCXNfZ+Vz+zvLOW5UV36mjuGkkSkJiISx0opqfv3sItLaxfHXH4/SGMHS6FQdJBLGbnnrG1ZvK+bp8yfSPlEjhEnjU0lAJEzNXbmVxz5by4xJ/Th4YGrQ4UgrpSQgEoYKSiq56oWvGZDWlquPGRJ0ONKKKQmIhKEbX8tga1E5d0wfQ3xMVNDhSCumJCASZmZnbOaVhRu47PCBjO7ZPuhwpJVTEhAJI3nFFVz3yhKGd0vmsiMGBh2ORABdHSQSRv70Wgb5JRU8PmMCMRomUpqBvmUiYeKdjM3MXLSRy44YyPDuyUGHIxFCSUAkDBSUVHLdzCUM65bMJVNUDSTNR9VBImHgpjeWkltcwSPnjlfncNKs9G0TCdjclVt5YUEWFx3an5E9UoIORyKMkoBIgIrLq/j9y4vpn9qWXx05KOhwJAKpOkgkQLe/s4KsvFJe+OVBuilMAqGSgEhAFq7L45FP13D2QX0Y37dj0OFIhFISEAlAZXUNv395MV3axXPV0eobSIKj6iCRADw4dzXLNhfy4NnjaBcfE3Q4EsFUEhBpZpnbirnrvZUcO7IrRw3vEnQ4EuGUBESakXOO62YuJjaqDTeeNCLocESUBESa0ysLN/C/VTlcfexQuiTHBx2OiJKASHPJK67gpje+4YDe7TljQu+gwxEBlAREms0tby2joLSSm388ijZtNGC8hAclAZFmMG9NLs+lr+f8yf0Y1k09hEr4UBIQaWIVVTVc98pierRP4Ap1DSFhRvcJiDSxB+euZmV2EQ+fO47EWP3kJLyoJCDShNbnlnDPBys5ZkRXjhiqewIk/CgJiDQR5xw3vJpBGzP+eOLwoMMRqZeSgEgTmZ2xhQ+WZXPljwbTvX1C0OGI1EtJQKQJFJdX8afXMhjatR3nTuobdDgiO6VWKpEmcNf7K9lUUMY9p+9PTJTOtSR86dsp0siWby7koU/WMH1cL8ZpnAAJc0oCIo3IOcf1MxfTLj6aa44dGnQ4IrulJCDSiF76cgPzM/P43TFD6dg2NuhwRHZLSUCkkeSXVPC3N70O4k4d1yvocEQaRA3DIo3kH7OXk1dSwePnTVAHcdJiqCQg0gi+Wp/P0/PWcc7BfRnRPSXocEQaTElAZB9V1ziun7mEtKQ4fnPU4KDDEdkjSgIi++jpeetYvKGA644fpkHjpcVREhDZB9uKyvnH28s4eEAnTtqve9DhiOwxJQGRffC3N5dRWlnNn08eiZkag6XlURIQ2UtfrM7hpS+zuGByfwZ2Tgo6HJG9oiQgshcqq2v4w6wl9GifwOVHaLQwabl0n4DIXnj4kzWs2FLEg2ePIyE2KuhwRPaaSgIie2hjfil3vreSHw3rzFHDNVqYtGxKAiJ76M+vLcXhuOHEEUGHIrLPlARE9sCHy7J5O2Mzlx8xiF4dE4MOR2SfKQmINFBpRTV/fHUJAzsnccHk/kGHI9Io1DAs0kD3friK9bmlPHPBgcRG6/xJWgd9k0UaYFV2Efd//C0/OaAHBw3oFHQ4Io1GSUBkN5xz/GHmEhJjo7n2uGFBhyPSqJQERHbj5S838NnqHK45ZiipSXFBhyPSqJQERHYhr7iCm9/8hrF9OnDaeI0WJq2PkoDILvztrW/YXlrJzT8eqdHCpFVSEhDZiS9W5/B8ehbnTe7H0K7JQYcj0iSUBETqUV5VzXUzvQ7irjhSHcRJ66X7BETq8Z85q1mVXcQj544nMVY/E2m9VBIQqWNVdhH3friKE/frzuFDOwcdjkiTUhIQCVFT47j25cXEx7ThjycMDzockSanJCAS4vn09czLzOW644eR1k73BEjrpyQg4sveXsZf3/yGCf06cuo43RMgkUFJQMT3h1lLKKuq4ZafjNKg8RIxlAREgLcWb2J2xhau/NFg+qdp0HiJHEoCEvHySyr4w6wMRvZI5oLJ/YIOR6RZ6QJoiXg3vfENeSUVPDZjPNFROi+SyKJvvES0D5dn8+KCLC46tD8juqcEHY5Is1MSkIi1vayS37+0mEGdk7jiR+oaQiKTkoBErJtf/4bswjJu+9l+xEVHBR2OSCCUBCQifbRiK8+lr+eiwwawX6/2QYcjEpiIahiuevS+oEOQJnTbmMHA7v/PVTU1JGQV8FKSMWpTJlWPftAc4Ynsk+hzL2mS9aokIBEnM6eEyuoaBqQl0UY3hUmEi6iSQFNlUgkPv50yBYA5dz6w02XeXrKJXz75Jb86chCTjhrcTJGJhC+VBCRibC0s59pXljCyRzKXHzEw6HBEwkJElQTUJtC67apNwOHI3lzEPVUVjI5LwZ5YTFVzByiyD9QmILIPthaWk1dSQe+OiSRopDCR7+z+12BWhHON26NWU6yzAdQm0LrtrE3g261FnHD3J4zt04HHZ0ygTRs1BovUUklAWrWKqhp+/ewi4mLacPup+ykBiNSxZ+Vis6uAU4E44BWcuwGzW4G1OHefv8yNQCHO3V7v8juurxvwHJDsx3Ixzs3dlx3aFbUJtG71tQlk5ZZwTX4pg7u0o+PLq9QOIC1W8G0CZlOBQcAEYAwwFrNDgWeB6SFLngq8sIvlQ/0cmI1zY4D9gEU/3KxdaGbpZpa+devWBocrUlBaycaCUjonx9GxbWzQ4YiEpT0pCUz1Hwv910nAIJx7CLPOmHUH0oA8nFuH2a/qXR4+DlnnfOBhzGKAmTi3qO5GnXMPAA8AjBs3zu1BvD+gNoHWLbRNYGthOcfeNZf2KTG8etkkotUYLFKvPfllGPA3nLu/nnkvAtOArnglg90t73HuY790cDzwBGb/wLnH9yAmkR+oqXFc+dwiCssqeer8iSQqAYjs1J40DM8GZmDmXdVj1gOzzv68Z4HT8BLBiw1YHn9aHyAb5x4EHgIO2LvdEPnevz/6lk9WbePGk0YwpGu7oMMRCWsNP0Vy7h3MhgGf4fW3UgSciXcQz8CsHbAB5zbtdvnvTQGuwqzSn3/2vu6QRLbtZZXc/s5yTtyvO6eN7xV0OCJhb/dJIPR6fufuAu7ayXKj6k4yGAVMd84trXedzj0GPNbwcEV2rqK6hpVbihjfqS1//fFITJ3DiexWk1aWOufOb8r1i9Sq9BNAdY3jP2eNpV18TNAhibQIjZYEzKwt8DzQE4gC/gJcDPwW6A782V80AYh1zvUzs7HAP/GuHNoGnOtqq5PqsXz5cqb4V4CIhFqbU0LOuuUkxERx4fQTgw5HpMVozDuGjwE2Ouf2c86NBN6uneGce9U5N8Z59wN8Bdxm3mWh9wDTnHNjgYeBm+uuNPQ+gcrKykYMV1qLbUXlbCooJTaqDTFRugleZE80ZnXQYryD+63A6865uXXrZM3saqDUOXevmY0ERgLv+stFAT8oBdS9T2DOnDmNGLK0dIuzCpj2n085sWcK2c9cixnoOyKyo121jzVaEnDOrfCrd44D/mZm79QJ4kjgZ0DtXcMGZDjnDmqsGCSybC0s58In0unUNpZ/nzmWac/u/j0isqNGKzubd8dwiXPuSeA2Qq75N+9+gPuAU51zpf7k5UCamR3kLxNjZiMaKx5p3cqrqrn4yQXklVTwwNnjSE2KCzokkRapMauDRgH/MLMaoBKvUfg2f965QCfgFb9YstE5d5yZTQPuNrMUP5Y7gYxGjElaIecc1768hPS1edxz+v6M7JESdEgiLVZjVgfNxrtLONQU/2868Kd63rOI76uHRBrkXx+s4qUvs/j1jwZx4n7dgw5HpEXTpRTSosxatIHb313Bj/fvwRVHDgo6HJEWT0lAWox5a3K56oWvmdCvI7f8dJTuCBZpBEoC0iIs27yd8x6bT8+OCTxw1ljioqOCDkmkVVASkLC3PreEsx+aR9vYaB6fMYH2iRogRqSxKAlIWMspKuech+dRVlnNYzMm0LNDYtAhibQqGm1DwlZBSSVnPTSPDfmlPHn+RI0NINIEVBKQsFRYVsnZj8xjZXYh9581lvF9OwYdkkirpCQgYaekoooZj84nY0MB9/78AKYM6bz7N4nIXlESkLBSXO4lgAVr87jztDFMHdE16JBEWjW1CUjYKCyr5BePzGfh+nzumD6GE0brbmCRpqYkIGGhoMRrA8jYUMA9p+/PcaO6BR2SSERQEpDAZW8v45xH5rMqu5D7zjhAVUAizUhJQAKVua2Ysx7+gpyiCv57zngOG5wWdEgiEUVJQAKzZEMB5z4yj+oax9MXHMiYXu2DDkkk4igJSCDeW7qFXz27kA6JsTw2YwIDOycFHZJIRFISkGblnOPh/2Vy0xtLGdk9hYfOGUfn5PigwxKJWEoC0mwqqmr402sZPPXFOo4e0YU7po8hMVZfQZEg6RcozWLL9jIufnIBX67L55eHDeDqo4fQpo3GAxAJmpKANLn5mblc8tSXFJdXce/PD+D40boHQCRcqNuIZtL/929w7F1zmXrHR1zy1AJKK6oBKKus5tT7P6O6xrE+t4RZizY0eSyTbvmA3OIKKqpqOPU/n1FVXdMk26mpcdz74SpOe+BzkuKimXnpJCUAkTCjJNBM4mOieOuKybxz5WHERLXhqS/WAvB8+nqOGdGVqDZGVl4psxZtbLaYYqPbcPDATrz+9aZGX3d2YRlnPzyPf8xezrEjuzLrskkM7qKuoEXCjaqDAjC+b0eWbd4OwMyFG7jrtP0BuPXtZXybXcSxd83lpwf0YHbGZm48aQQjuqcA8NN/f8pNp4zk7SWbWZdbwuaCMjYVlHLRYQM4fUJvAO7/6FveWLyJiqoapo7oym+OGrzLWKYO78rfZy/jlP17NNr+zc7YzLUvL6a4oopbfjKK6eN7aTxgkTClJNDMqqprmLN8K4cNSaOiqoZ1uaX06uiNlnXNMUN5cO5qHj53PADtE2N5cUEWI7qnsHprERVVNQzrlszbSzbzzabtzLx0EiUV1Rx/91yOGNqZ5ZsLycwpZtalk3AOzn88nS9W5zCxf6edxjOkazu+zipolH0rKK3kT69m8PLCDYzonswd08fo7F8kzCkJNJOyymqOvWsuABP6dmD6uF7klVSQnLDzf8Hxo7pxzwcrufa4YTyfnsW0sT2/mzd1eBfiY6KIj4nioP6dWLQ+n/TMXD5esY3j7v4E8Prlz8wp3mUSiGpjxEQZReVVJMXt/ddhdsZmbpiVwdaicq44chCXHTGQmCjVNoqEOyWBZlLbJrDDtOgoyit33iibEBvFIQNTeXfpFt5YvJHXLjvk+5l1qlcMcA4uOXwAZ0zss0exVVTVEBe9dwfsTQWl3DArg3eWbmFo13Y8cPZYRvdsv1frEpHmp1O1AKUkxlDjHGWV3pVCSXHRFJVX7bDMaeN7c+OrGYzu2Z72ibHfTX936RbKKqvJK67g89U57NerPYcOTuP59CyK/XVsLihjW1H5LmPIK66gY9vYPT5rL6+q5v6PvuWof37Mxyu38rtjh/La5YcoAYi0MCoJBGzyoFTSM/M4ZFAqQ7u1I7qNccydHzNtbE/On9yfUT1TSIqP5mchVUEAY3qlMOPR+WzML+XyIwfRJTmeLsnxrMou4if3fQpAYlwUd04fQ2pS3E63/9nqHA7fg+EbnXN8sCybv7y+lMycEo4c2pkbThxB706Je/cBiEiglASaydI/H1Pv9LMP6stDn6zhkEGpxES14ekLDtxh/pbtZTgHhw7asYvlfqlt+dtPRv9gfTMO6ceMQ/rtMpb//e6I757PWrSBq48Z2qB9+HJdHre+tYwv1uQyIK0tj/5ivMb/FWnhlAQCNrJHCgf170R1jSOqTjcKLy3I4rZ3lnP98cObpIuFiqoapg7vyoC0Xffg+c2m7dz53gpmZ2whNSmWP500gp9P7K2GX5FWwJxzQcfQYOPGjXPp6elBhxExMjYWcPf7K5mdsYWkuGgumNyf8yf3o+0+XEXUlKZMmQLAnDlzAo1DJNyY2QLn3Lj65oXnr1kC45zjf6tyeHDuaj5asZV28dH86shBzJjUd4eGaRFpHZQEBIDSimpe+2ojj3yayTebtpOaFMdvpw7mrIP6kpIQE3R4ItJElAQi3KrsQp6Zt54X0tezvayKwV2S+Pu00Zw8pjtx0VFBhyciTUxJIAIVlFbyxtebeGHBehauy/cuSx3ZlbMO7MOEfh3Vz49IBFESiBAlFVW8/002r361kY+Wb6WiuobBXZK47rhhnLJ/D9La7fxeAhFpvZQEWrG84greX5bN7IzNfLxiK+VVNXRuF8eZB/bh5DHdGd0zRWf9IhFOSaAVqa5xLN24nY9WZPPh8q0sXJdHjYOuyfGcNr4XR4/sysR+nX5wP4KIRC4lgRaspsaxMruIeWty+PTbHD5bnUN+SSUAo3umcNkRgzhiaGdG90jReL4iUi8lgRakqLyKr7PyWbjOe6Svzf3uoN8tJZ4fDevCIQNTmTQwVXX8ItIgSgJhKq+4gm82b+ebTYUs2VDA11n5rN5WTO0N3v1T23LUsC5M6NeRCf060rtjour3RWSPKQkEyDnH1sJyVm8rZvXWYlZmF7Iqu4gVWwrZsv37LqC7JMcxqkcKJ+7XnTG92jOmV3vdvSsijUJJoIkVllWyqaCMrLwSNuSVkpVXytqcEtbmlrAup5jiiurvlk2MjWJg5yQmDUxlWNdkhnZrx9CuyaraEZEmoySwF5xzFJRWklNcQU5RBVsLy9lWVE52YRlbtpezZXsZW7aXsSm/jMI6g8TERrWhV8cEendMZGK/jvRPa0u/VO/RPSVBDbgi0qwCTwJmdgxwFxAF/Nc5d0tzbLeiqobi8iqKQh6FZZUUllWxvbSS7WVVFJRWkl9SQUFpJXkl3vPcYu9vVc0Pe1+NamN0bhdH5+R4+nZqy8EDUumaEk+3lHh6dkikZ4cE0pLidKAXkbARaBIwsyjgXuAoIAuYb2avOueWNuZ2lm7czhXPLqSkopriiipKyqupqN752L614mPa0D4hlpSEGNonxtA/NYmxfWLpkBhDp6Q4OrWNpVNSLGnt4khLiqNDYqwO8CLSogRdEpgArHLOrQYws2eBk4FGTQJJcdEM6pJEYmw0bWOjSIiNJikuirZx0bSNi6ZdXDTt4mNoGxdFckIMyfExtIuPJj5GHaiJSOsWdBLoAawPeZ0FTAxdwMwuBC4E6N27915tpHenRO47Y+xehigi0noFPT5gfXUnO1S2O+cecM6Nc86NS0tLq2dxERHZW0EngSygV8jrnsDGgGIREYk4QSeB+cAgM+tnZrHAacCrAcckIhIxAm0TcM5VmdllwGy8S0Qfds5lBBmTiEgkCbphGOfcm8CbQcchIhKJgq4OEhGRACkJiIhEMCUBEZEIZs79sA+ccGVmW4G1QcchYW0EoIsLRDy1v4c+zrl6b7RqUUlAZHfMzDnn1IGTCA37Pag6SEQkgrWYJGBmS4KOQcKbviMie67FVAepmC+7Y2YOQN8TEY+qg0REZJeUBEREIpiSQAtkng5BxyFSH303W5bA+w7aA3m1db7iMVPVdx158H3bgARH382wkbe7BVpMw7B8z8wmAnc75ybudmGRZmZmXwFnO+e+CjoW2T1VB4mIRDAlARGRCKYkICISwZQEREQimJJAy7QV9ZQp4WsxkBN0ENIwujpIRCSCqSQgIhLBlARERCKYkoCISARTEhARiWBKAi2AmfU0swfNLMvMKsxsg/+6Z9CxSeTR97F1URIIc2bWH1gAjALOAQYCZ+INID3fzPoGF51Emn35PprZeDN7xcz+Y2Z3NEe8snu6RDTMmdlbwBhgkHOuKGR6IrASWOScOz6g8CTC7Mv30cw+AaY55zY3R6zSMCoJhDEz6wgcDdwb+oMDcM6VAPcBx5pZBzM7z8w+NbP/mdm4IOKV1q0Rvo864wxDLWk8gUg0CDAgw8yK6sxbC1zvzx8MXARMAroCzwCHNGOcEhn29fv4G+B+M9sMlDjnrmyuwGXnlARaBodXBA9VCYz1n08FPnTOVQLrzSzGzOKdc2XNGKNEjr39Ps4HTm6+MKUhlATC20q8H9wI59zMujPN7Ex//rdA75BZ+UAHYFPThygRRN/HVkhtAmHMOZcLzAYu8RvevuO/vhR4C8jF+5HVau9PE2k0+j62TkoC4e9SvP/Te2Z2hJn1MrMpwLt49a+XAV8Ah/vF7l5ApXOuPKiApVXT97GVUXVQmHPOrTaz8cANwBNAZ7yupN8EpjvnsgDM7H7gY6AGuCKgcKWV0/ex9dF9AiIiEUzVQSIiEUxJQEQkgikJiIhEMCUBEZEIpiQgIhLBlARkj5jZjWbmzGzlTuav8uff2Ejb27an6/Jj3LabZc7146x9ZJvZbDM7YJ8CDiNmNtXMft1M20o1s2fNrNDMtpjZTWYW1Rzbln2jJCB7owzoV7e3Uv/68T7+/JbiCOAgvA7P0oAPzax7sCE1mqnAr5t6I2ZmwCygL3Aq8Fvgl8Bfmnrbsu90s5jsjWLgS+A0ID1k+mnAB3zfkVhLML+2W2QzS8frDfMM4B97szIzS3DOlTZifGFjF50SngBMAHrVjhVgZmXAE2b2T+fcLktlEiyVBGRvPQuc6p8F1p4NnupP/wEzO9XMFptZuZmtN7ObzSy6zjKHmtlXZlZmZgvM7OCdrOtkM0v3l9tsZn83s5h93SHn3Hq8u1/7+tu5xY+5yB9K8Skz61onlkwzu93M/mBmWcB2f/pBZvaqmW00s2IzW2RmZ9R5b22V1AFmNsfMSvzlDjCztmb2iJkVmNlqMzt9Tz4Hvwrt/4A+IVVej4a89xAz+8jfZo55w0O2qye2CX5spcBVO/noTgbm1hks5jW848vRDfnsJThKArK3Xga68P24BZPxqlNeqbugmU0FnsMrPZwM3INXZfCvkGW6833nY9OA+4GngLodlZ3qb3secBLwJ+BC4G/7ukP+QbAjUHsw6wz8FTger1qlP/BBPXXdPwcOAy4BpvvT+gD/A84HTgReAh6p72AOPIbX5/5P8frfeRF4CNiI91l8ATxuIWP4NuBz+C/wtL8vB/mPv/jvnQS878+b5u/bccAj9cT2DPC6P//1euaDN7TkcjOLrn0AVcAaYORO3iPhwjmnhx4NfgA3Atv857PwRpkCb1Spmf7zbcCNIe/5HK9/+dD1XA1UAz39138HcoDEkGXOwOua+Eb/teFV1zxSZ10zgFKgU90Yd7Ef5/rrTsGrFu2Fl6iqgDH1LB8F9PDfc2jI9Ey8LpLjd7Et87dxP/BBPTGcEzLtOH/awyHTUvD66794Dz+H24DMeuKZW8//4wh/uyPrxHZFA74TK/xl63s8EPR3Vo9dP1QSkH3xLDDNzOLwzih/UBXknzUfALxQZ9ZzeCXRg/zXE4B3nTdMYa2X67xnMF4/9c/XOev8AIhn78468/EOsOvwDoQznHOL/NiPNW+IxAK85JAVEkeo912dunLzhli828zW+uuvxDtTr/te8M7Ka63y/35QO8E5V4BXTdUjZPt79TmY1+XzQfW89xN2HBim1hs7W1cdTwPj6zxqk4OEMTUMy754Fa/a4WagLV49cF2pQAywpc702tcd/b9dga9DF3DOldqOwxim+n/f3Ek8vRoW9g4OBUrwSi/rnXM18N2VTq/iVW/dAmTjHdA+xzvQhqq7bwCPAgfiVcEsxWsruJj6R9bKD3leUc+02um1292Xz6EDXqnmPv+xu/fWt2915QDFzrnQiwTwk4vGEQhzSgKy15xzxWb2OnAl8IJzrriexbbhnWF2rjO9i/+39iCxue4yZpYAJIVMql32QmBhPdta0/Dov7PQ1Rk03fdjvLPv6c6v8zCzPjtZxw5nu2YWj9eOcJlz7j8h0xur5L0vn0M+fhUb9SeRjXVeN+RMfgkwMHSC/7/rBSxuwPslQEoCsq/+DcQB/6lvpnOu2swWAD/zl611Kl5f85/5r+cDM8wsMaRK6Cd1Vrcc2AD0dc492Ejx70wC3mAooQfBM3a2cB1xeGfb3w2k4jc6n0TjVI809HMILT0A3yXuz4Ehzrk/N0IsADOBl82sh3Nugz9tGl6bz+xG2oY0ESUB2SfOuTnAnN0sdgMw28wewWs3GIVXTfKg8wchAe7EG7XqdTP7J9Ad+D1eQ2fttmrM7P/wrj9PxruaqALvqp1TgGl12hT2xbvAr83sTrxqroOBMxvyRudcgZnNB/5oZtvxkt3vgAIgeV8D24PPYRnQxczOxTtb3+acy8RrlH/fzGrwrkQqxGtjOB64zjm3Yg9DehMvib9mZtfjVVfdCdzunMvZh12VZqAkIE3OOfeOmZ0GXI93Np0N3I6XHGqX2WBmxwF3411O+Q3eQXdWnXU95x9Yr8W7GqYaWI13+WIFjcQ596aZXQNcDlyAV2I5Aa+xsyF+DjwAPI5XZ/4vvMtdL2uk+BryOTwPHI535VUa3qWo5zrnPjGzQ/EuK30Cr9SyFnibhrUB1I3FmdkpePv4PF4by714VU4S5jSymIhIBNMloiIiEUxJQEQkgikJiIhEMCUBEZEIpiQgIhLBlARERCKYkoCISARTEhARiWD/D0y+eu68o5ftAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "thetas, beta = np.linspace(0,10,100),  lambda x : 1/(1+np.exp(-xs+5 ))\n",
    "plt.plot(thetas,beta(thetas))\n",
    "plt.axvline(4, color = 'black')# boundary b/w Theta_0 and Theta_0^c. \n",
    "plt.axhline(.26, color = 'black') # Size of test, defined below. \n",
    "plt.hlines(y=[.3,.32,.34], xmin=0, xmax = 10, color = 'salmon') # Levels\n",
    "\n",
    "plt.xticks([])\n",
    "plt.yticks(ticks=[0,.26,.3,1], labels =['0','size', 'levels','1'] )\n",
    "my_colors = ['black', 'black', 'r','black']\n",
    "for ticklabel, tickcolor in zip(plt.gca().get_yticklabels(), my_colors):\n",
    "    ticklabel.set_color(tickcolor)\n",
    "plt.title('Example Power Function β(θ)')\n",
    "plt.xlabel(u'Model Parameter \\u03B8',{'size':15},labelpad=35)\n",
    "plt.text(x=1, y=.1, s='P(type I)', color='C0') # what color is the curve?\n",
    "plt.text(x=5, y=.9, s='1-P(type II)',color='C0')\n",
    "\n",
    "ax.annotate('\\u0398\\u2080', xy=(0.2, -0.03), xytext=(0.2, -0.15),\n",
    "            fontsize=14, ha='center', va='bottom', xycoords='axes fraction', \n",
    "            # bbox=dict(boxstyle='square', fc='0.8'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=4.9, lengthB=.4', lw=1.0))\n",
    "\n",
    "ax.annotate('\\u0398\\u2080ᶜ', xy=(0.7, -0.03), xytext=(0.7, -0.15),\n",
    "            fontsize=14, ha='center', va='bottom', xycoords='axes fraction', \n",
    "            # bbox=dict(boxstyle='square', fc='0.8'),\n",
    "            arrowprops=dict(arrowstyle='-[, widthB=7.0, lengthB=.6', lw=1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e95468e-5c20-4c17-9ee7-a465a8dce869",
   "metadata": {},
   "source": [
    "The greatest danger, in terms of type I errors, is comes when the probability of type I error is the highest. The value of the power there is noteworthy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fbb468-d2d9-49c1-9221-097d74902469",
   "metadata": {},
   "source": [
    "## Size and Level\n",
    "**Definition** The **size** of a test is defined to be\n",
    "$\\sup\\limits_{\\theta \\in \\Theta_0} \\beta(\\theta)$. \n",
    "\n",
    "- The max probability of type 1 error is the size. \n",
    "    - People like size $5\\%$. \n",
    "    - People can tollerate probabilities of type 1 error smaller than the size. \n",
    "- The minimum probability of the test correctly keeping $H_0$ is $1-\\text{Size}$. \n",
    "    - people like $95\\%$\n",
    "    - people can tollerate higher than $95\\%$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b71993-71dd-4b45-8417-0fa33b5bb0dd",
   "metadata": {},
   "source": [
    "**Definition** A test is said to have (significance) **level** $\\alpha$ if $\\alpha \\geq \\sup\\limits_{\\theta \\in \\Theta_0} \\beta(\\theta)$ (i.e. $\\alpha$ is greater than the size).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d45bb-bb93-403a-988d-660f42032fd2",
   "metadata": {},
   "source": [
    "Petz says that the standard way of doing things is to \n",
    "1. put a bound on error of the first kind (namely, level bounds size)\n",
    "2. crank up $n$ until error of the second kind is tolerably low. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009bbbf6-1c5e-43f3-8977-8b9bf96ad64f",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary>Drop down to see: This language does not match up with Kossis</summary>\n",
    "<li> \n",
    "Koosis says: (This seems inconsistant with Wasserman and Casella)\n",
    "\n",
    "The probability of a Type I error is typically known as $\\alpha$, \n",
    "\n",
    "while the probability of a Type II error is typically known as Beta, \n",
    "\n",
    "and power $1-\\beta$ is the probability of falsifying the null hypothesis when it is indeed false.\n",
    "\n",
    "Trying to bumper sticker it\n",
    "\n",
    "- Alpha is chance you look right when you are wrong. \n",
    "- Beta is chance you look wrong when you are right. \n",
    "- Power is chance you look right when you are right. \n",
    "-----\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1441d5e4-418e-4238-919c-7fa0d8b62c30",
   "metadata": {},
   "source": [
    "---\n",
    "Review before moving on: \n",
    "- Notation: $z_\\alpha = \\Phi^{−1}(1 − α)$ where $\\Phi$ is the CDF of $N(0,1)$.\n",
    "- the standard deviation with unknwm mean of $\\hat\\theta_n$ is called **standard error**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099a8cc5-fea8-4b1d-9388-014ad6253c5c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "e.g. Let $X_1,\\dots,X_n \\sim N(\\theta,1)$ and $H_0: \\theta = 0$ with \n",
    "$R = \\{x^n | \\bar{x}_n >c\\}$.\n",
    "</summary>\n",
    "<li> \n",
    "  Say you have a size $\\alpha=5\\%$, that you want or need to use. In designing the experiment, you need to make a decision about how large $n$ should be. \n",
    "\n",
    "To make the test have size \n",
    "$\\alpha:=\\sup\\limits_{\\theta \\in \\Theta_0}\\beta(\\theta)$, \n",
    "which in this $\\Theta_0 = \\{0\\} $ case is $\\alpha = \\beta(0) =\\mathbb{P}_{\\theta = 0}(\\bar{X}_n >c ) $, \n",
    "\n",
    "use $c$ such that \n",
    "$$\n",
    "\\alpha = \\mathbb{P}_{\\theta =0} (\\bar{X}_n>c) \\\\\n",
    "\\Leftrightarrow \n",
    "\\alpha = \\mathbb{P}_{\\theta =0} \\left(\\sqrt{n}\\frac{\\bar{X}_n-0}{1}>c \\sqrt{n}\\right) \\\\\n",
    "\\Leftrightarrow \\alpha = \\mathbb{P}_{\\theta =0} \\left(Z>c \\sqrt{n}\\right) $$\n",
    "$$\n",
    "\\Leftrightarrow \\alpha = 1-\\Phi\\left(c\\sqrt{n}\\right) \\\\\n",
    "\\Leftrightarrow \\Phi\\left( c\\sqrt{n} \\right) = 1-\\alpha  \\\\\n",
    "\\Leftrightarrow  c\\sqrt{n}  = z_\\alpha  \\\\\n",
    "\\Leftrightarrow  c  = \\frac{z_\\alpha }{\\sqrt{n}}.\n",
    "$$\n",
    "Thus, when you use a larger value of $n$ you can use a smaller value of $c$.  \n",
    "\n",
    "Interpretation: Since the variance of the sample distribution $\\bar{X}_n$ in terms of the population variance $\\sigma=1$ is $\\sigma/\\sqrt{n}=1/\\sqrt{n}$, the number $Z_\\alpha/\\sqrt{n}$ is the number of standard deviations out in the sampling distribution required to get to $F_{\\bar{X}_n}\\left(Z_\\alpha/\\sqrt{n}\\right) >1-\\alpha$.\n",
    "<\\details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c6f5fa-bc6d-45d8-9ff1-1fef5d754c27",
   "metadata": {},
   "source": [
    "This chapter considers 4 tests\n",
    "1. Wald\n",
    "2. $\\chi^2$\n",
    "3. permutation\n",
    "4. likelihood ratio "
   ]
  },
  {
   "cell_type": "raw",
   "id": "796268a3-09d0-4dda-8027-9bae11953d7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6fbae00-d492-44f4-90e1-2f01106b4d43",
   "metadata": {},
   "source": [
    "## Wald test\n",
    "\n",
    "In testing \n",
    "$$\n",
    "H_0 :\\theta=\\theta_0\\\\ \n",
    "\\text{ versus  }\\\\ \n",
    "H_1 :\\theta \\neq \\theta_0,\n",
    "$$\n",
    "let $\\hat \\theta_n$ be an estimate of $\\theta$ and let $\\text{se}_n$ be the standard error (with unknown mean) of $\\hat \\theta_n$. \n",
    "- assume $\\frac{\\hat \\theta - \\theta_0}{\\text{se}} \\stackrel{Dist}{\\to} N(0,1)$ (i.e. $\\hat \\theta$ is asymptotically normal) and \n",
    "    - of course, you do not have to know $\\theta^*$ to make this assumption.\n",
    "- rejejct $H_0$ if $\\lvert \\frac{\\hat \\theta - \\theta_0}{\\text{se}}\\rvert> z_{\\alpha/2}$ for your choice of $\\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9cccef-7f7c-42a5-b1fa-be4373f2e601",
   "metadata": {},
   "source": [
    "The following tells you how to use the test.\n",
    "\n",
    "**Theorem**. The size $\\alpha$ Wald test rejects $H_0$ if and only if $\\theta_0 \\notin C$ where\n",
    "$C=(\\hat  \\theta  −\\text {se}z_{α/2}, \\hat \\theta   + \\text{se}z_{α/2})$.\n",
    "\n",
    "Thus, testing the hypothesis is equivalent to checking whether the null value of the parameter is in the confidence interval.\n",
    "\n",
    "Additional theory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed29f722-2224-4442-b113-084937256198",
   "metadata": {},
   "source": [
    "**Theorem**. Asymptotically, the Wald test has size $α$, that is, \n",
    "$P_{ \\theta  _0} \\left( \\left|\\frac{\\hat{\\theta}_n - \\theta_0}{\\text{se}} \\right| >z_{α/2} \\right) \\to \\alpha$ as $n \\to\\infty$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5d8fcd-0d53-40be-950f-47992eab4ca0",
   "metadata": {},
   "source": [
    "**Interpretation** With large samples, one can be confident that the Wald test has a desired probability of false positives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699a462c-6c44-48c8-a2f7-9999988fe6d4",
   "metadata": {},
   "source": [
    "**Theorem** Suppose the true value of $\\theta$ is $\\theta_⋆  \\neq \\theta_0$.The probability of correctly rejecting the null hypothesis with the Wald test is given (approximately) by \n",
    "$$\n",
    "β( \\theta  _⋆) \\approx 1-\\Phi \\left( \\frac{\\hat \\theta - \\theta_0}{\\text{se}}+ z_{\\alpha/2}\\right)\n",
    "-\\Phi \\left(\\frac{\\hat \\theta - \\theta_0}{\\text{se}}- z_{\\alpha/2}  \\right)\n",
    "$$\n",
    "\n",
    "Again, that is theory and you do not need to know $\\theta^*$ in the use of the wald test; to use the wald test all you need is the first theorem above. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82cc4ec-0598-406d-b144-34477dc419e3",
   "metadata": {},
   "source": [
    "### Test of equal means\n",
    "\n",
    "Let \n",
    "- $X$ be a random variable with unknown mean $\\mu_X$ and unknown variance $\\sigma_X$\n",
    "- $Y$ be a random variable with unknown mean $\\mu_Y$ and unknown variance $\\sigma_Y$.\n",
    "\n",
    "(We need not assume either $X$ or $Y$ is normally distributed.)\n",
    "\n",
    "Consider the hypothesis\n",
    "$$\n",
    "H_0: \\mu_X=\\mu_Y\\\\\n",
    "H_1: \\mu_X\\neq \\mu_Y.\n",
    "$$\n",
    "\n",
    "This hypothesis can be tested with a \n",
    "- random sample $X^n$ of size $n$ of $X$\n",
    "- random sample $Y^m$ of size $m$ of $Y$\n",
    "\n",
    "by constructing \n",
    "- the estimator $\\bar{X}_n$ of $\\mu_X$\n",
    "- the estimator $\\bar{Y}_m$ of $\\mu_Y$\n",
    "\n",
    "and noting that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf5784ad-cbef-4bc2-b05f-3635f29a6e28",
   "metadata": {},
   "source": [
    "$$\n",
    "\\bar{X}_n\\stackrel{CLT}{\\approx} \n",
    "    {\\cal N}\\left(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\right)\\\\\n",
    "\\bar{Y}_m\\stackrel{CLT}{\\approx} \n",
    "    {\\cal N}\\left(\\mu_Y,\\frac{\\sigma_Y}{\\sqrt{m}}\\right)\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1eb4c7-53cd-4ca9-bd41-77352430ddd0",
   "metadata": {},
   "source": [
    "Further, since $\\bar{X}_n$ and $\\bar{Y}_m$ are independent, the estimator of $\\delta=\\mu_X-\\mu_Y$ has \n",
    "$$\n",
    "\\mathbb{V}(\\bar{X}_n - \\bar{Y}_m) \n",
    "= \n",
    "\\mathbb{V}(\\bar{X}_n) + \\mathbb{V}(\\bar{Y}_m) \n",
    "\\stackrel{CLT}{=} \\frac{\\sigma^2_X}{n} + \\frac{\\sigma^2_Y}{m}\n",
    "$$\n",
    "Thus, \n",
    "$$\n",
    "\\hat{\\delta} = \\bar{X}_n-\\bar{Y}_m \\sim {\\cal N}\\left( \\mu_X-\\mu_Y, \n",
    "\\sqrt{\n",
    "    \\frac{\\sigma_X^2}{n}  + \\frac{\\sigma_Y^2}{m}  \n",
    "    }\n",
    "\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb818ef-5f14-464a-903c-b96582d0dcd9",
   "metadata": {},
   "source": [
    "Therefore, under $H_0: \\delta = 0$ the statistic \n",
    "$$\n",
    "W = \\frac{\\hat{\\delta}}{\n",
    "    \\sqrt{\n",
    "        \\frac{s^2_{X,n}}{n} + \\frac{s^2_{Y,m}}{m}\n",
    "    }\n",
    "} \\sim {\\cal N}(0,1)\n",
    "$$\n",
    "where $s^2_{R,n}, ~R\\in\\{X,Y\\}$  can be either \n",
    "- the sample variance estimator of variance with unknown mean $s^2_{X,n} = \\frac{1}{n-1} \\sum_{i=1}^m\\left( X_i - \\bar{X}_n\\right)^2$\n",
    "- the plug in estimator of variance with unknown mean $s^2_{X,n} = \\frac{1}{n} \\sum_{i=1}^m\\left( X_i - \\bar{X}_n\\right)^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7184a1-7506-4550-bdbe-5ffad38ea687",
   "metadata": {},
   "source": [
    "Thus, a sample $Z=(X_1,...,X_n,Y_1,...,Y_m)$ gives a statistic $\\hat{\\delta}$, and an observation gives $w$ with rejection of $H_0$ if $w$ in not in the $1-\\alpha$ confidence interval of a standard unit normal distribution;\n",
    "$$\n",
    "w \\notin \\left(\n",
    "    F^{-1}\\left( \\frac{\\alpha}{2}\\right)\n",
    "    ~,~\n",
    "    F^{-1}\\left( 1-\\frac{\\alpha}{2}\\right)\n",
    "    \\right)\\\\\n",
    "\\implies \\sim H_0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe0ddd4-379b-4adb-be5b-e4481ac0e9a8",
   "metadata": {},
   "source": [
    "## p-values\n",
    "Recall\n",
    "\n",
    "**Definition** A test is said to have (significance) **level** $\\alpha$ if $\\alpha \\geq \\sup\\limits_{\\theta \\in \\Theta_0} \\beta(\\theta)$ (i.e. $\\alpha$ is greater than the size).\n",
    "\n",
    "\n",
    "As we reduce the level $\\alpha$ we change the region $R_\\alpha$ of rejection by making it smaller. Holding the observation $x^n$ constant and reducing $\\alpha$ we can imagine taking $\\alpha$ so low that our statistic $T(x^n)$ is no longer in  $R_\\alpha$. \n",
    "\n",
    "**Definition** The <u>p-value</u> of the test with the data $x^n$ is a smallest level $\\alpha$ at which the test rejects.\n",
    "\n",
    "But abstracting away from particular observations by using a random variable...\n",
    "\n",
    "**Definition** Suppose that for every $\\alpha \\in (0, 1)$ we have a size $\\alpha$ test with rejection region $R_\\alpha$. Then, the <u>$\\text{p-value}$</u> of $(X^n)$ is $\\inf \\{ \\alpha  \\,|\\, T(X^n) \\in R_\\alpha \\}$ ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2947ec9-396f-4092-bcc0-f5e1aaf15405",
   "metadata": {},
   "source": [
    "Addressing a common misconception:  \n",
    "- p-value is *not* the probability that the null hypothesis is true.\n",
    "\n",
    "Informally characterizing, \n",
    "- the p-value is a measure of the evidence against $H_0$; the smaller the p-value, the stronger the evidence against $H_0$. \n",
    "- The p-value is the probability (under $H_0$) of observing a value of the test statistic the same as or more extreme than what was actually observed.\n",
    "    - more like \"worst case probability\" instaead of \"probability\". \n",
    "\n",
    "The term \"more extreme than\" is vague there, but is less vague under particular circumstances, like the circumstance the the following."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0095e7-d3b0-4249-9b4b-f8ebc5e86c17",
   "metadata": {},
   "source": [
    "---\n",
    "**Theorem:** Suppose that the size $\\alpha$ test can be formulated in terms of a statistic $T$ as \n",
    "$$R_\\alpha = \\{x^n| T(x_n)\\geq C_\\alpha \\}$$\n",
    "Then,\n",
    "$$\\text{p-value}(x^n) = \\underset{\\theta\\in\\Theta_0}{ \\text{sup}} P_\\theta\\big(T(X^n)\\geq T(x^n)\\big).\n",
    "$$\n",
    "---\n",
    "\n",
    "That is, under the null hypothesis, what is the highest probability over $\\Theta_0$ that the statistic is at least this large. So think of a family of PDF curves for $T(X^n)$ indexed by $\\theta$ and the part of the tails beyond $T(x^n)$. Which member of the family of curves has the biggest area under the curve right of $T(x^n)$?  \n",
    "\n",
    "So, when people say \"probability that the null hypothesis is true\" they are simplifying to two cases\n",
    "1. test can be formulated in terms of a statistic $T$ \n",
    "2. the hypothesis set has a single element $\\Theta_0=\\{\\theta_0\\}$.\n",
    "\n",
    "Those conditions are met for the Wald test. But letting the first example you see be the extent of your understanding is dangerous. \n",
    "\n",
    "For the Wald test, the statistic is $W$, the observation $w$, and the rejection criterion $|w|> z_{\\alpha/2}$. The \n",
    "$$\n",
    "\\text{p-value}(w) = P_{\\theta_0}(|W|>|w|)\n",
    "$$\n",
    "and the naive interpretation holds up, as does the \"twice the area under the PDF for $W$ past $w$\" idea; no need to consider a family of PDFs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c8f2b7-3df5-43cc-8db8-df5c0b2f2a85",
   "metadata": {},
   "source": [
    "The following gives the central idea around p-values.\n",
    "\n",
    "**Theorem:** If the test statistic $T$ has a continuous distribution, then under \n",
    "$H_0 : \\Theta = \\{\\theta_0\\}$, the p-value has a Uniform(0,1) distribution. \n",
    "\n",
    "i.e. the probability of a type I error is $\\alpha$ when we use the rejection criteria formulated in terms of the p-value as a statistic $R_\\alpha = \\{x^n|p(x^n)<\\alpha\\}$. \n",
    "\n",
    "On the other hand, if $H_0$ is false then the distribution of the p-value will tend to concentrate closer to $0$, making it more likely that we reject $H_0$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a1a448-be4a-4f8f-9ff0-5dbf6d49b46c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "425d6bfa-80e7-445a-a947-a15843df53a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "987aeb52-b0ef-44d2-a671-2c1329d722d5",
   "metadata": {},
   "source": [
    "## 𝛘 squared test\n",
    "\n",
    "\n",
    "\n",
    "**Definition:** If $Z_1,...,Z_k\\sim {\\cal N}(0,1)$ be iid then the random vairable $V = \\sum\\limits_{i=1}^k Z_i^2$ is the <u>chi-squared</u> random variable with $k$ degrees of freedom.\n",
    "\n",
    "Notation: $V \\sim \\chi^2_k$ (that is $V$ is distributed as chi-squared.) \n",
    "\n",
    "The probability density of $\\chi^2_k$ is\n",
    "$$f_{\\chi^2_k}(v) \n",
    "= \\frac{v^{\\frac k2−1} e^{−\\frac v2} }{2^{\\frac k2} \\Gamma\\left(\\frac k2\\right)}\\\\\n",
    "=\\frac1{2\\Gamma\\left(\\frac k2\\right)} \\left( \\frac{v}{2} \\right)^{k/2 -1} e^{−\\frac v2}\n",
    "$$\n",
    "\n",
    "Note: The $\\chi^2$ distribution is a $\\Gamma(\\alpha,\\beta)$ distribution with $\\beta =2$ and $ \\alpha = k/2$ and so has mean $\\alpha\\beta = k$, variance $\\alpha\\beta^2 = 2k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683feda8-526d-4bb6-87ff-12727552bf0c",
   "metadata": {},
   "source": [
    "### Multinomial distributions\n",
    "\n",
    "**Definition:** A experiment with discrete sample space $\\Omega$ with $\\lvert\\Omega \\rvert=k$ and enumeration $\\omega_i, i=1,...,k$ is a <u>categorical experiment</u> with $k$ categories. \n",
    "\n",
    "The probability of outcome $\\omega_i$ is denoted $p_i$, and $p=(p_1,...,p_k)$.\n",
    "\n",
    "**Definition:** A sample of size $n$ from a categorical experiment is a <u>multinomial experiment</u>. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225426c3-2e10-42b7-9119-843847a4edcb",
   "metadata": {},
   "source": [
    "For multinomial distributions with $n$ draws from $k$ categories \n",
    "- we denote the number of draws from the $j$th category as $X_j$, \n",
    "- the outcome of the multinomial experiment is $(X_1,...,X_n)$\n",
    "- $X_j \\sim \\text{Binom}(n,p_{j})$\n",
    "    - $\\mathbb{E}(X_j) = np_{j}$\n",
    "    - $\\mathbb{V}(X_j) = np_{j}(1-p_{j})$\n",
    "- the MLE of $p_0$ is $\\left(\\frac{X_1}{n},...,\\frac{X_k}{n} \\right)$.\n",
    "\n",
    "\n",
    "### Pearson's 𝛘^2 test for multinomial data\n",
    "\n",
    "Let $p_0 = (p_{01}, . . . , p_{0k})$ be some fixed vector and suppose we want to test \n",
    "$$\n",
    "H_0 :p=p_0 \\\\\n",
    "H_1 :p \\neq p_0 .\n",
    "$$\n",
    "\n",
    "**Definition** Pearson’s $\\chi^2$ statistic is (as a funciton of the $X_i$ from a multinomial experiment as described above)\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "T   & = \\sum\\limits_{j=1}^k \\frac{(X_j −n p_{0j})^2}{np_{0j}} \\\\\n",
    "    & = \\sum\\limits_{j=1}^k \\frac\n",
    "        {\n",
    "            \\left(X_j −\\mathbb{E}(X_j)\\right)^2\n",
    "            }\n",
    "        {\\mathbb{E}(X_j)} \\, .\n",
    "\\end{array}\n",
    "$$ \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8fc1a3-7361-4808-8d04-49fd1eff1f88",
   "metadata": {},
   "source": [
    "---\n",
    "<details>\n",
    "<summary>\n",
    "Q: <a href src=\"https://ocw.mit.edu/courses/18-443-statistics-for-applications-fall-2006/resources/lecture11/\">Why</a> divide by expected value and not by variance? </summary>\n",
    "\n",
    "A: The $X_i$ are not independent, and this unexpected division you are asking about is just right to make up for lack of independence. The proof is not trivial, but note that \n",
    "1. $\\frac{X_j-n p_{0j}}{\\sqrt{np_{0j}(1-p_{0j})}} \\sim {\\cal N}(0,1)$\n",
    "2. $Z_j:=\\frac{X_j-n p_{0j}}{\\sqrt{np_{0j}}} \\sim {\\cal N}(0,1-p_{0j})$\n",
    "     - thus $\\sum_{j=1}^k \\mathbb{V}(X_j) = \\sum_{j=1}^k \\left(1-p_{0i}\\right) = k-1$\n",
    "     - this is the variance of $s_{k-1}=\\sum_{j=1}^{k-1} g_j \\text{ where } g_1,...,g_{n-1}\\sim {\\cal N}(0,1) \\text{ iid }.$\n",
    "3. $\\sum_{j=1}^n Z_j^2 \\sim \\sum_{j=1}^{n-1} g_i^2 \\text{ where } g_1,...,g_{n-1}\\sim {\\cal N}(0,1) \\text{ iid }.$\n",
    "\n",
    "That is, in the sum over squares of these dependent variables $Z_i$ one degree of freedom washes out, as does of the variance of the $Z_i$.  \n",
    "</details>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d39cf5b-1760-40e3-889b-1fb1d9ee1dff",
   "metadata": {},
   "source": [
    "**10.17 Theorem**. Under $H_0: p = p_0$ the statistic $T \\sim \\chi^2_{k-1}$ as $n\\to \\infty$. \n",
    "\n",
    "Hence the test: reject $H_0$ if $T > F^{-1}_{\\chi^2_{k-1}}(\\alpha)$. \n",
    "\n",
    "Wording I do not understand: \"has asymptoptic level $\\alpha$.\"\n",
    "\n",
    "The p-value is $\\mathbb{P}_{\\chi^2_{k-1}}(T>t)=1-F_{\\chi^2_{k-1}}(t)$ where $t$ is the observed value of the test statistic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4be0d8-012f-4e04-9f06-6acc7f52b992",
   "metadata": {},
   "source": [
    "e.g. Observation of Mendel's peas to test his theory of inheritance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b724a1-491c-4435-9e30-24e936abd2a7",
   "metadata": {},
   "source": [
    "## Permutation test\n",
    "that two samples are from the same distribution.\n",
    "\n",
    "Suppose that $X_1, . . ., X_m \\sim F_X$ and $Y_1, . . ., Y_n ∼ F_Y$ are two independent samples and \n",
    "$H_0 :F_X = F_Y \\text{ versus }  H_1 :F_X \\neq F_Y.$\n",
    "\n",
    "Let $Z = (x_1,...,x_m,y_1,...,y_n)$. Let $G$ be the group of perumtation on $n+m$ objects, and $T(Z)$ be some test statistic. (e.g. $|\\bar{X}_m − \\bar{Y}_n|$). \n",
    "\n",
    "Denote $T_g:=T(gZ) ~\\forall g \\in G$. \n",
    "\n",
    "**Definiton** The **permutation distribution** of $T$ is the discrete CDF $F(t) = \\frac{1}{ N!} \\sum\\limits_{g\\in G} I( T(gZ) > t)$ that puts mass $1/N!$ on each $T_g$.\n",
    "\n",
    "That is, the permutation distribution $F(t)$ is the fraction of permutatioins that give $T>t$. \n",
    "\n",
    "Calculating all permutations is computationally expensive, and we can get the same results with a convienient number of random;y chosen permutations. \n",
    "\n",
    "Assuming we reject when T is large, the p-value is\n",
    "$ \\frac{1}{ N!} \\sum\\limits_{g\\in G} I(T(gZ) > t_{obs})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0484060-0a04-4286-b6aa-3668aa3b4fce",
   "metadata": {},
   "source": [
    "**e.g.** The fraction of words that are 3 letter words from 8 essays from author A are in the list A, \n",
    "The fraction of words that are 3 letter words from 10 essays from author B are in the list B.  \n",
    "\n",
    "$$\n",
    "H_0: \\text{ Author A is author B.}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2f778238-dd40-4281-b896-5d261d543fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `np.random_sample` not found.\n"
     ]
    }
   ],
   "source": [
    "np.random.random_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "2e18050d-50bf-4d5f-b88a-c447e7d6becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import permutations \n",
    "\n",
    "\n",
    "A = [.225 ,.262 ,.217 ,.240 ,.230, .229, .235, .217]\n",
    "B = [.209, .205 ,.196 ,.210, .202 ,.207, .224 ,.223 ,.220, .201]\n",
    "\n",
    "def d_means(sample_A,sample_B):\n",
    "    a_bar = np.mean(sample_A)\n",
    "    b_bar = np.mean(sample_B)\n",
    "    return a_bar - b_bar\n",
    "\n",
    "Z = A+B \n",
    "diffs = []\n",
    "def get_random_permutation(L):\n",
    "    return list(np.random.choice(a=L,size=len(L),replace=False))\n",
    "    \n",
    "for _ in range(10_000):\n",
    "    Z_prime = get_random_permutation(Z)\n",
    "    diff = d_means(Z_prime[:len(A)],Z_prime[len(A):])\n",
    "    diffs.append(diff)\n",
    "\n",
    "xs = np.linspace(min(diffs) , max(diffs),100)\n",
    "F_perm = [sum(np.array(diffs) < x) for x in xs] #CDF\n",
    "f_perm = np.array(F_perm[1:]) - np.array(F_perm[:-1]) #PDF\n",
    "p = sum(diff>d_means(A,B) for diff in diffs)/len(diffs)\n",
    "print(f\"The p-value is {p}.\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(xs[:-1],f_perm)\n",
    "plt.axvline(x= d_means(A,B), color = 'red', label = 'Observed')\n",
    "plt.title('Permutation PDF');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c2b6b-a005-446c-8727-408e9e612d40",
   "metadata": {},
   "source": [
    "## Likelihood ratiotest\n",
    "\n",
    "For testing a vector-valued parameter $\\theta \\in \\Theta \\subseteq \\mathbb{R}$ with a sample $X_1,...,X_n$, let ${\\cal L}(\\theta) = \\prod_{i=1}^n f (X_i;\\theta)  $ be the likelihood of the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93e05c-c5c1-4b97-8d4b-6f55d8b3d164",
   "metadata": {},
   "source": [
    "**Definition**. Consider testing\n",
    "$H_0 : \\theta \\in\\Theta_0 \\text{versus} H_1 :\\theta \\notin \\Theta_0.$\n",
    "The **likelihood ratio statistic** is\n",
    "$$\n",
    "λ(X^n) = 2\\log \n",
    "\\left( \n",
    "\\frac{\\sup\\limits_{\\theta \\in \\Theta}   {\\cal L}(\\theta)  } \n",
    "            {\\sup\\limits_{\\theta \\in \\Theta_0 }{\\cal L}(\\theta)  }\n",
    "\\right)\n",
    "=2\\log \\left( \n",
    "\\frac{ {\\cal L}(\\hat \\theta)} \n",
    "             { {\\cal L}(\\hat \\theta_0)  }\n",
    "\\right)\n",
    "$$\n",
    "where $\\hat \\theta$ is the mle and $\\hat\\theta_0$\u0011 is the mle when $\\theta$ is restricted to lie in $\\Theta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d30b0e-925f-41cc-9512-7225aff55b4c",
   "metadata": {},
   "source": [
    "**Theorem** $\\lambda(x^n) \\stackrel{dist}{\\to}  \\chi^2_{r−q}$ with \n",
    "$\\text{p-value}(x^n) = P\\left(\\chi^2_{r−q} > \\lambda(x^n) \\right)$ where $r-q$ is the number of free parameters in (aka the dimension of) $\\theta_0$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bea206-33f6-480e-9e45-f3b61c12ac68",
   "metadata": {},
   "source": [
    "### e.g. Mendell's peas \n",
    "Consider a hypothesis that the data for Mendel's peas follows a multinomial distribution. \n",
    "\n",
    "The pdf of a multinomial distribution with $p = (p_1,...,p_k)$ is\n",
    "$f(x)=\n",
    "\\left( \\begin{array}{c}\n",
    "n\\\\\n",
    "x_1 . . . x_k \n",
    "\\end{array}\\right)\n",
    "p_1^{x_1} ···p_k^{x_k}$ \n",
    "\n",
    "Recall that if $X = (X_1 , . . . , X_k )$ has a multinomial $(n, p)$ distribution, then the mle of $p$ is \n",
    "$$\n",
    "\\hat p = (\\hat p_1, . . . , \\hat p_k) = \\left(\\frac{X_1}{n}, . . . , \\frac{X_k}{n}\\right).\n",
    "$$\n",
    "\n",
    "\n",
    "Thus, with \n",
    "$$\n",
    "H_0: \n",
    "% \\theta \\in \\Theta_0 = \\{ p_0\\} \\\\ \n",
    "p_0 = \\left(\\frac9{16},\\frac3{16},\\frac3{16},\\frac1{16} \\right)\n",
    "$$\n",
    "the likelihood ratio test statistic takes the form\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2d45e1-e273-4a4f-bdd7-eac64c6577c3",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{array}{ll}\n",
    "\\lambda \n",
    " &= 2\\log \\left(\n",
    " \\frac{ \n",
    "        {\\cal L}(\\hat p)\n",
    "      } \n",
    "      { \n",
    "        {\\cal L}(\\hat p_0)  \n",
    "       }\n",
    " \\right)\\\\\n",
    " &= 2\\log \\left( \\frac{\\prod\\limits_{i=1}^k (X_i/n)^{X_i} } { \\prod\\limits_{i=1}^k p_i^{X_i}  }\\right)\\\\\n",
    " &= \\sum\\limits_{i=1}^k 2{X_i}\\log \\left( \\frac{ (X_i/n) } { p_i  }\\right)\n",
    "\\end{array}\n",
    "$$\n",
    "and using the experimental data\n",
    "$p-value = \\mathbb{P}(χ^2_3 > .48) = .92.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b7d692-0d7b-4ed0-b2ee-979116cef0f1",
   "metadata": {},
   "source": [
    "## Multiple testing\n",
    "\n",
    "**Definition:** If a large number of hypotheses are true and they are simultaneously tested with a confidence level $\\alpha = 0.05$, then the probability of one of the hypotheses being rejected when it is in fact true is high. \n",
    "\n",
    "Austin called this statistics packing. In data mining, this comes up as one tests perhaps millions of hypotheses. We discuss two methods of dealing with the problem\n",
    "\n",
    "### Bonferroni method\n",
    "The Bonferroni method: If the p-values of the $m$ hypothesis tests are $P_1,...,P_m$, then reject hypothesis $H_i$ if $P_i<\\frac\\alpha m$\n",
    "\n",
    "**Theorem:** With the Bonferroni method, the probability of falsely rejeccting at least 1 hypothesis is $\\leq \\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89139c9-0b51-47c9-83b8-e470c0f53943",
   "metadata": {},
   "source": [
    "### BH Method\n",
    "The BH (Benjamini-Hochberg) Method: \n",
    "- Order the p-values you obtain into a monotonic increasing list $[p_1, ...,p_m]$ \n",
    "- Consider the ordered set of points $[(i,p_i)|i=1,...,m]$\n",
    "- Compare to the ordered set of points $L = [(i,i\\alpha/m) | i=1,...,m]$ (which are on a line), \n",
    "    - let $l_i$ be the $i$the element of $L$.\n",
    "- Let $T= \\max \\{p_i | p_i<l_i\\}$ \n",
    "- reject all hypotheses with $p_i< T$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15651964-978f-46ed-9f2b-ee9c075792b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No qualifying points; T is undefined\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wonderman/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAnF0lEQVR4nO3de3xU9bnv8c+TCyQSFOUmcjHURgQJJhhuYlGLiForSnXbWsFbVdyy1X1aWqv7bG2P+9R9am3VreANFKWiVbxUaaVakWq9EAIqiAGKoIEoAYRyCZCQ5/wxkzBJVrjOZE0y3/frNa/M/NZvrfXMJJlnfmut+T3m7oiIiDSUFnYAIiKSnJQgREQkkBKEiIgEUoIQEZFAShAiIhIoI+wA4qlTp06em5sbdhgiIi3GggUL1rt756BlrSpB5ObmUlxcHHYYIiIthpmtbmqZDjGJiEggJQgREQmkBCEiIoFa1TmIIFVVVZSVlbFjx46wQ5EklJWVRY8ePcjMzAw7FJGkk9AEYWZnA/cC6cCj7n5Xg+UWXX4usB24wt1Loss6AI8C/QEHrnL3dw80hrKyMtq3b09ubi6R3YlEuDsbNmygrKyM3r17hx2OSNJJWIIws3TgAWAUUAbMN7OX3f2TmG7nAHnR2xBgcvQnRBLHn939IjNrAxx2MHHs2LFDyUECmRkdO3akoqIi7FBEDsq6f+5gafk/qazaTV6X9hzXJSeu20/kCGIwsMLdVwKY2UxgDBCbIMYA0z0ypex7ZtbBzLoB24ARwBUA7r4L2HWwgSg5SFP0tyEHrXIT7NwCOV0go22z775s43YmPr2QRV9sAqBdm3Se+tEQCnsdGbd9JDJBdAe+iHlcxp7Rwd76dAeqgQpgmpmdBCwAbnL3bQ13YmbXAtcCDGjbFk4/vX6H22+HNJ2Ll7348ku4/vqwo5CWZMdm2LgSqrbDYZ2gQy/IzG7WELK27uSWdVvrtWU/24bdXXNIj9MHn0S+cwZF2LD4RFN9MoCBwGR3LyQyorglaCfu/rC7F7l7UbKeaMwZODDsEEQkXqq2w1dLYNc2cIdtFZFkUbO7WcPYWV3TqG3brmpqauJX4yeRI4gyoGfM4x7A2v3s40CZu78fbX+OJhJEPX36wNy59duWLo20h8ks/BikaTU1jf9uRJryyUvw7PgGjbvghkehc/P9n69cXsG4xz6o13bdad+gcPQJkHYAI4i9jDYSOYKYD+SZWe/oSebvAy836PMyMN4ihgKb3b3c3b8EvjCz2ld7JPXPXSRMjddQur6UuavmUrq+lBpvnKVFJIW1PbxxW1YHyDyo62gOWkGPDtz+3X4c1iYdM/hO/tFcOrgXaQeSHPYhYSMId682s4nAa0Quc53q7kvMbEJ0+RRgNpFLXFcQucz1yphN/BswI5pcVjZYlhA1XsOspbMY/8J4Kqsryc7IZvqF0xnbdyxppvMYIgIc3R++eRasmLOn7exfQYeeTa+TAO2zM7nilFzO7NuVXbtr6N4hi6zM+L6lJ/R7EO4+m0gSiG2bEnPfgRuaWHcRUJTI+BpavmF5XXIAqKyuZPwL48nvkk+fTjpEJCJAu85w/v3w5SLYWgGd8qDbSaGEYmb0PCpxI5dW/03qA1G+tbwuOdSqrK6kfGu5EoSI7HH40XD42WFHkXA6bhKjW043sjPqX6qWnZFNt5xuIUUkIhIeJYgYeR3zmH7h9LokUXsOIq9j3iFtd/v27fTo0aPuds8998QjXBGRhNIhphhplsbYvmPJ75JP+dZyuuV0I69j3iGfoK6p0ZVQItLyKEE0kGZp9OnUR+ccRCTl6RCTiIgEUoIQEZFAShAiIhJICUJERAIpQYiISCBdxdQM0tPTyc/Pp7q6mr59+/LEE09w2GHNO7GXSKuwrQLKFkDFp5EpLnoUQU7XsKNqtTSCaKi6CrZ8BVWV++67n7Kzs1m0aBGLFy+mTZs2TJkyZd8riUh9u7bDvLvh6Uvg9dth5qXw+i8jVd0kIZQgYlWUwqv/C6YMhz9cBWs/jPsuvvWtb7FixYq4b1ek1duwAj54qH7boqdg/fJw4kkBShC1KjfBi/8KC6dHhrHLZsOM78Gmz+O2i+rqav70pz+Rn58ft22KpIyqykgFt0bt25s/lhShBFHr689gTXH9tm0Vcfl0UllZSUFBAUVFRfTq1Yurr776kLcpknKO6g2djq/fdkQvOOq4cOJJATpJXSsjC9IyoKa6fnubdoe86dpzECJyCHK6wMVPwNu/hZV/hWNPhRGT4HDNtpwoShC1jvomnPrvMO/Xe9pOOK9Za8yKyD507QdjHoDKryG7A2S0DTuiVk0JolZGJgz9V+g5BL5aAh2Pg+5FkH1k2JGJSKyMNtBel7Y2ByWIWIcdBXmjIrc42rp1a1y3JyLSHHSSWkREAilBiIhIICUIEREJpAQhIiKBlCBERCSQEoSIiATSZa7NoHa671ovvvgiubm5gX1zcnJ0WayIJAUliGagqTZEpCVK6CEmMzvbzErNbIWZ3RKw3Mzsvujyj8xsYMyyVWb2sZktMrPihusmyosL1zD8rr/S+5ZXGX7XX3lx4Zq472Pr1q2MHDmSgQMHkp+fz0svvdSoT3l5OSNGjKCgoID+/fvzt7/9DYA5c+YwbNgwBg4cyMUXX6zRhkgKq/EaSteXMnfVXErXl1LjNXHdfsIShJmlAw8A5wD9gB+YWb8G3c4B8qK3a4HJDZaf4e4F7l6UqDhjvbhwDT+f9TFrNlXiwJpNlfx81seHnCRqZ3MtKCjgwgsvJCsrixdeeIGSkhLefPNNfvzjH+MNpjH+/e9/z+jRo1m0aBEffvghBQUFrF+/njvvvJPXX3+dkpISioqKuOeeew4pNhFpmWq8hllLZ1H4UCFnPHEGhQ8VMmvprLgmiUQeYhoMrHD3lQBmNhMYA3wS02cMMN0j747vmVkHM+vm7uUJjKtJv36tlMqq3fXaKqt28+vXSrmgsPtBb7fhIaaqqipuvfVW5s2bR1paGmvWrOGrr77i6KOPruszaNAgrrrqKqqqqrjgggsoKCjgrbfe4pNPPmH48OEA7Nq1i2HDhh10XCLSci3fsJzxL4ynsjpS/bKyupLxL4wnv0s+fTrFZ5LRRCaI7sAXMY/LgCH70ac7UA44MMfMHHjI3R8O2omZXUtk9EGvXr0OKeC1m4LLjDbVfrBmzJhBRUUFCxYsIDMzk9zcXHbs2FGvz4gRI5g3bx6vvvoq48aNY9KkSRx55JGMGjWKp59+Oq7xiEjLU761vC451KqsrqR8a3ncEkQiz0FYQFvDclB76zPc3QcSOQx1g5mNCNqJuz/s7kXuXtS5c+eDjxY4pkP2AbUfrM2bN9OlSxcyMzN58803Wb16daM+q1evpkuXLlxzzTVcffXVlJSUMHToUN555526kqXbt29n2bJlcY1NRFqGbjndyM6o/96UnZFNt5z41cdIZIIoA3rGPO4BrN3fPu5e+3Md8AKRQ1YJNWl0H7Iz0+u1ZWemM2l0fGtC/PCHP6S4uJiioiJmzJjBCSec0KjP3LlzKSgooLCwkOeff56bbrqJzp078/jjj/ODH/yAAQMGMHToUD799NO4xiYiLUNexzymXzi9LklkZ2Qz/cLp5HXMi9s+rOHJ0bht2CwDWAaMBNYA84FL3X1JTJ/vABOBc4kcfrrP3QebWTsgzd23RO//Bfilu/95b/ssKiry4uL6FzwtXbqUvn377nfcLy5cw69fK2XtpkqO6ZDNpNF9Dun8gyS/A/0bSVk1uyNleNu0g7btw45GiJyoXr5hOeVby+mW0428jnmk2YF97jezBU1dCJSwcxDuXm1mE4HXgHRgqrsvMbMJ0eVTgNlEksMKYDtwZXT1rsALZlYb4+/3lRzi5YLC7koIIg1t/AzenwIfPROpAT3ql3DsKWBBR4mluaRZGn069YnbOYeGEvpFOXefTSQJxLZNibnvwA0B660ETkpkbCKyn6p3wtxfRZIDwJpieOpCuOZN6HpiuLFJQmkuJhHZu81r4OM/1G+r3gnrdP6rtVOCEJG9y2gL2R0at7fNafZQpHkpQYjI3h3RHc76v/Xbup8MR+cH95dWQ5P1ici+9RsDHXrBV4shpyt0HwiHHxN2VJJgShAJtGHDBkaOHAnAl19+SXp6OrVf5vvggw9o06ZNmOGJ7L82h0Hu8MhNUoYSRAJ17Nixbg6mO+64g5ycHH7yk5/ULa+uriYjQ78CEUlOendq6KNn4Y1fwuYyOKIHjPxPGPAvcdv8FVdcwVFHHcXChQsZOHAg7du3r5c4+vfvzyuvvEJubi5PPfUU9913H7t27WLIkCE8+OCDpKen72MPIiLxoZPUsT56Fv54I2z+AvDIzz/eGGmPo2XLlvH666/zm9/8psk+S5cu5ZlnnuGdd95h0aJFpKenM2PGjLjGISKyNxpBxHrjl1DVYObWqspIexxHERdffPE+RwJvvPEGCxYsYNCgQUCkpkSXLl3iFoOIyL4oQcTaXHZg7QepXbt2dfczMjKoqdlT4KN22m935/LLL+dXv/pVXPctIocuHnMgtQSt7xkdiiN6HFh7HOTm5lJSUgJASUkJn332GQAjR47kueeeY926dQBs3LgxcFpwEWlezVHJLVkoQcQa+Z+Q2aD2Q2Z2pD1Bvve977Fx40YKCgqYPHkyxx9/PAD9+vXjzjvv5KyzzmLAgAGMGjWK8vJQCu2JSIymKrkt37A85MjiT4eYYtWeZ0jAVUx33HFHYHt2djZz5swJXHbJJZdwySWXHPK+pYXbuBLWlUJmW+hyIrTvGnZEKa05KrklCyWIhgb8S1xPSIsckvIP4ckLYPvGyONjBsLF0+DI3DCjSmm1ldxik0S8K7klCx1iEklW1VXwzn17kgPA2hJY9U54MUmzVHJLFhpBiCSrqm2RhNDQ+tLmj0XqpFkaY/uOJb9Lvq5iEpGQZB0B/b/XuL3XsOaPReqpreR2eu7p9OnUp1UmB1CCEEleZlBwGfS7IPI4oy2ccRv0HBJqWJI6dIhJJJkdlQsXTIHTfw7pGXBkb0jTfFzSPJQgEkjTfUtctMmGLieEHYWkICWIBNrXdN8iIslM5yBERCRQao0gbr4Zop/o46agAH73u/huU0QkCWgEISIigVJrBKFP+iIi+00jCBERCaQEISIigRJ6iMnMzgbuBdKBR939rgbLLbr8XGA7cIW7l8QsTweKgTXufl4iY020pqb7FpEDkyrV3JJBwl7V6Jv7A8A5QD/gB2bWr0G3c4C86O1aYHKD5TcBSxMVo4i0LKlUzS0ZJDLtDgZWuPtKd98FzATGNOgzBpjuEe8BHcysG4CZ9QC+AzyawBhF9m7zWtj0BdToDSgZpFI1t2SQyATRHfgi5nFZtG1/+/wO+Cmw1/9MM7vWzIrNrLiiouKQAhapU7kJPngEJg+DBwbBW3fBli/Djirl7a2am8RfIhOEBbT5/vQxs/OAde6+YF87cfeH3b3I3Ytq5zkSOWSfvwezfwI7NkFVJbz131A6O+yoUl5tNbdYrbWaWzJIZIIoA3rGPO4BrN3PPsOB881sFZFDU982s6cSF6pIA0HJoORJqNrR/LFInVSq5pYMEnkV03wgz8x6A2uA7wOXNujzMjDRzGYCQ4DN7l4O/Dx6w8xOB37i7pclMFaR+joe17itcx9Iz2z+WKROKlVzSwYJe1XdvRqYCLxG5EqkZ919iZlNMLMJ0W6zgZXACuAR4F8TFU9YVq1aRf/+/eOyrZ07d3LmmWdSUFDAM888E5dt7o+XX36Zu+66q1H73Llz+fvf/173+IorruC5556L+/5zcnIOqP8dd9zB3Xff3aj9gH4XeaOhfcxhi7btYfB1qsWQBFKlmlsySOj3INx9NpEkENs2Jea+AzfsYxtzgbkJCK/FWbhwIVVVVXVTiO+P6upqMjIymny8P84//3zOP//8Ru1z584lJyeHU045Zb+3tXv3btLTW8CbbJcT4IrZ8OVHULMbup6omgyScpR6m0F1dTWXX345AwYM4KKLLmL79u0AvPHGGxQWFpKfn89VV13Fzp07AcjNzeX2229n4MCB5Ofn8+mnn7Ju3Touu+wyFi1aREFBAf/4xz9YsGABp512GieffDKjR4+mvDxyJcfpp5/Orbfeymmnnca9997b6PGB7Bfg8ccfZ+LEifWe06pVq5gyZQq//e1vKSgo4G9/+xsA8+bN45RTTuEb3/hG3Whi7ty5nHHGGVx66aXk5+eze/duJk2axKBBgxgwYAAPPfQQAOXl5YwYMYKCggL69+9ft02A2267jZNOOomhQ4fy1VdfAbB69WpGjhzJgAEDGDlyJJ9//nmj137BggWcdNJJDBs2jAceeODAfnEdvwEnXgD531NykJSUUpP1/eKPS/hk7T/jus1+xxzO7d89ca99SktLeeyxxxg+fDhXXXUVDz74IBMnTuSKK67gjTfe4Pjjj2f8+PFMnjyZm2++GYBOnTpRUlLCgw8+yN13382jjz7Ko48+yt13380rr7xCVVUV48aN46WXXqJz584888wz3HbbbUydOhWATZs28dZbbwHwxz/+se7xjh07yMvLO6D9BsnNzWXChAn1iiA99thjlJeX8/bbb/Ppp59y/vnnc9FFFwGRCnqLFy+md+/ePPzwwxxxxBHMnz+fnTt3Mnz4cM466yxmzZrF6NGjue2229i9e3ddIt22bRtDhw7lv/7rv/jpT3/KI488wn/8x38wceJExo8fz+WXX87UqVO58cYbefHFF+vFeeWVV3L//fdz2mmnMWnSpAP+/YqkMo0gmkHPnj0ZPnw4AJdddhlvv/02paWl9O7dm+OPPx6Ayy+/nHnz5tWtM3bsWABOPvlkVq1a1WibpaWlLF68mFGjRlFQUMCdd95JWVlZ3fJLLrmkXv/ax4e633254IILSEtLo1+/fnWf9AEGDx5M7969AZgzZw7Tp0+noKCAIUOGsGHDBpYvX86gQYOYNm0ad9xxBx9//DHt27cHoE2bNpx33nmN4nr33Xe59NLIdQ/jxo3j7bffrhfL5s2b2bRpE6eddlpdHxHZfyk1gtjXJ/1EiUw5Vf9x5PRL09q2bQtAeno61dXVjZa7OyeeeCLvvvtu4Prt2rULfHyo+92X2vUb7is2Hnfn/vvvZ/To0Y3WnzdvHq+++irjxo1j0qRJjB8/nszMzLrXcG9xNXyd3b1Rm4jsP40gmsHnn39e90b+9NNPc+qpp3LCCSewatUqVqxYAcCTTz5Z90l3f/Tp04eKioq67VZVVbFkyZJ9rneo+43Vvn17tmzZcsDrjR49msmTJ1NVVQXAsmXL2LZtG6tXr6ZLly5cc801XH311ZSUlOx1O6eccgozZ84EYMaMGZx66qn1lnfo0IEjjjiibmQxY8aMA45VJJUpQTSDvn378sQTTzBgwAA2btzI9ddfT1ZWFtOmTePiiy8mPz+ftLQ0JkyYsO+NRbVp04bnnnuOn/3sZ5x00kkUFBTUu+S0KYe631jf/e53eeGFF+qdpN4fP/rRj+jXrx8DBw6kf//+XHfddVRXVzN37lwKCgooLCzk+eef56abbtrrdu677z6mTZvGgAEDePLJJ7n33nsb9Zk2bRo33HADw4YNIzs7O2ArItIU29chh5akqKjIi4uL67UtXbqUvn37hhSRtAT6G5FUZmYL3L0oaJlGECIiEkgJQkREAqXEVUy6mqWFqd4Ju7ZBTRVktoPMwyAtMZ9lWtMh1kRTJbfU0+oTRFZWFhs2bKBjx45KEi1B9U7Y+I/Iz1pH5kL2kXHflbuzYcMGsrKy4r7t1qa2klttsZ7aWVTH9h2rJNGKtfoE0aNHD8rKylAxoRaiajtsW1+/7YuNkNM1IRPlZWVl0aNHj7hvt7VpqpJbfpd8+nTqE3J0kiitPkFkZmbWfYNXWoAPZ8Jr19Vvy8iCiQugg97Iw7K3Sm5KEK2XxoaSXLr0bVxzYdCP4HBVDAuTKrmlJiUISS5d8+GyF6HnUGh/NJz2MxgyQXUYQqZKbqmp1X9RTlqonVsj5yPadQZdXJAUdBVT67S3L8q1+nMQ0kK1zYncJGnUVnLTOYfUofQvIiKBlCBERCSQEoSIiARSghARkUBKECIiEkgJQkREAilBiIhIoL1+D8LMtgBB36QzwN398IREJSIiodtrgnD39s0ViIiIJBcdYhIRkUAJTRBmdraZlZrZCjO7JWC5mdl90eUfmdnAaHuWmX1gZh+a2RIz+0Ui4xRJZjVeQ+n6Uuaumkvp+lJqvCbskCRFJGwuJjNLBx4ARgFlwHwze9ndP4npdg6QF70NASZHf+4Evu3uW80sE3jbzP7k7u8lKl6RZKRKbhKmRP6FDQZWuPtKd98FzATGNOgzBpjuEe8BHcysW/Tx1mifzOit9Uw7K7KfmqrktnzD8pAjk1SQyATRHfgi5nFZtG2/+phZupktAtYBf3H394N2YmbXmlmxmRWrrKi0Nnur5CaSaIlMEEGT+DccBTTZx913u3sB0AMYbGb9g3bi7g+7e5G7F3Xu3PlQ4hVJOqrkJmFKZIIoA3rGPO4BrD3QPu6+CZgLnB33CEWSnCq5SZgSWTBoPpBnZr2BNcD3gUsb9HkZmGhmM4mcnN7s7uVm1hmocvdNZpYNnAn8dwJjFUlKaZbG2L5jye+Sr0pu0uwSliDcvdrMJgKvAenAVHdfYmYTosunALOBc4EVwHbgyujq3YAnoldCpQHPuvsriYpVJJmpkpuERTWpRURS2N5qUmucKiIigZQgREQkkBKEiIgEUoIQEZFAShAiIhJICUJERAIpQYiISCAlCBERCaQEISIigZQgREQkUCIn6xNp0Wq8huUblmuSPElZShAiAVTqU0SHmEQCqdSniBKESCCV+hRRghAJpFKfIkoQIoFU6lNEJ6lFAqnUp4gShEiTVOpTUp0+DomISCCNIGSPyk3w5cew5Us48ljo2h/aHBZ2VCISEiUIidi5Beb9P3j3gT1t5/4Giq6CNA00RVKR/vMlomJZ/eQAMOc22LgynHhEJHRKEBJR+XXjtuodsGNz88ciIklBCUIijuoNbXIatH0DOvQMJx4RCZ0ShER0PA4ufQZqvwjWvQgufhxyuoQaloiERyepZY/cU+GqP0euZmrXGbKPCDsiEQmREoTU165T5CYiKS+hh5jM7GwzKzWzFWZ2S8ByM7P7oss/MrOB0faeZvammS01syVmdlMi4xQRkcYSNoIws3TgAWAUUAbMN7OX3f2TmG7nAHnR2xBgcvRnNfBjdy8xs/bAAjP7S4N1pZVSJTeR5JDI/7rBwAp3X+nuu4CZwJgGfcYA0z3iPaCDmXVz93J3LwFw9y3AUqB7AmOVJFFbya3woULOeOIMCh8qZNbSWdR4TdihiaScRCaI7sAXMY/LaPwmv88+ZpYLFALvxz9ESTaq5CaSPBKZICygzQ+kj5nlAM8DN7v7PwN3YnatmRWbWXFFRcVBByvJQZXcRJJHIhNEGRD7LasewNr97WNmmUSSwwx3n9XUTtz9YXcvcveizp07xyVwCY8quYkkj0QmiPlAnpn1NrM2wPeBlxv0eRkYH72aaSiw2d3LzcyAx4Cl7n5PAmOUJKNKbiLJI2FXMbl7tZlNBF4D0oGp7r7EzCZEl08BZgPnAiuA7cCV0dWHA+OAj81sUbTtVnefnah4Q7e1AraUQ/aRKT29hSq5iSQPc294WqDlKioq8uLi4rDDOHBrFsDzP4rMnJp9JJx/Pxx/DqTre4wiklhmtsDdi4KW6WNZ2Laug+eu3jOtduXX8IcrYH1pqGGJiChBhG3Ll/D1Z/Xbaqrh69XhxCMiEqUEEbasDpHDSg3l6IosEQmXEkTYjuwF370P0tL3tI2YBJ37hheTiAiazTU59DkXrvsbfL0qUn+h8wnQNmefq4mIJJISRDJIz4CuJ0ZuIiJJQoeYREQkkBKEiIgEUoIQEZFAShAiIhJIJ6mljiq5iUgsJQgB9lRyqy3WUzuL6ti+Y5UkRFKU/vMFUCU3EWlMCUIAVXITkcaUIARQJTcRaUwJQgBVchORxnSSWgBVchORxpQgpE6apdGnUx/6dOoTdigikgT08VBERAIpQYiISCAlCBERCaQEISIigZQgREQkkBKEiIgEUoIQEZFAShAiIhJICUJERAIpQYiISKCEJggzO9vMSs1shZndErDczOy+6PKPzGxgzLKpZrbOzBYnMsZkUeM1lK4vZe6quZSuL6XGa8IOSURSXMIShJmlAw8A5wD9gB+YWb8G3c4B8qK3a4HJMcseB85OVHzJpLaaW+FDhZzxxBkUPlTIrKWzlCREJFSJHEEMBla4+0p33wXMBMY06DMGmO4R7wEdzKwbgLvPAzYmML6koWpuIpKMEpkgugNfxDwui7YdaJ+9MrNrzazYzIorKioOKtCwqZqbiCSjRCYIC2jzg+izV+7+sLsXuXtR586dD2TVpKFqbiKSjBKZIMqAnjGPewBrD6JPq6dqbiKSjBJZMGg+kGdmvYE1wPeBSxv0eRmYaGYzgSHAZndPueMqquYmIskoYQnC3avNbCLwGpAOTHX3JWY2Ibp8CjAbOBdYAWwHrqxd38yeBk4HOplZGXC7uz+WqHjDpmpuIpJszP2ADvkntaKiIi8uLg47DBGRFsPMFrh7UdAy1aSu2gH/XAMZbeGIHmFHIyKSNFL7IPeGlfDi9fA/J8OUU2HR07Bre9hRiYgkhdRNELur4N3/gSWzwB0qv4YXJ0D5orAjExFJCqmbILZVwMd/aNy+7tPmj0VEJAmlboJokwMdj2vcntMyv2wnIhJvqZsgsg6Hs+6MnJyu1WsYHFMYXkwiIkkkta9iOnY4XPMmVJRC2/ZwdD60PzrsqEREkkJqJwgz6Hpi5CYiIvWk7iEmERHZq9QeQRAp1rN8w3LNgSQi0kBKJ4jaSm61xXpqZ1Ed23eskoSIpLxWNRfTUcf29VG3Tt3v/pVV2ykuX1CvtGeapVHU7WSyMw9LRIgiIknl2QmnNDkXU0p/TN65e1ejus81XsPO3btCikhEJHm0qhHEgc7mWrq+lMKHCuuV+8zOyGbhdQs17baIpIS9zeaa0iMIVXITEWlaSp+kViU3EZGmpXSCAFVyExFpij4qi4hIICUIEREJpAQhIiKBlCBERCSQEoSIiARqVV+UM7MKYHXYcRyiTsD6sINIEnot6tPrUZ9ejz0O5bU41t0DS2m2qgTRGphZcVPfakw1ei3q0+tRn16PPRL1WugQk4iIBFKCEBGRQEoQyefhsANIInot6tPrUZ9ejz0S8lroHISIiATSCEJERAIpQYiISCAliCRgZj3N7E0zW2pmS8zsprBjCpuZpZvZQjN7JexYwmZmHczsOTP7NPo3MizsmMJkZv8e/T9ZbGZPm1lW2DE1JzObambrzGxxTNtRZvYXM1se/XlkPPalBJEcqoEfu3tfYChwg5n1CzmmsN0ELA07iCRxL/Bndz8BOIkUfl3MrDtwI1Dk7v2BdOD74UbV7B4Hzm7QdgvwhrvnAW9EHx8yJYgk4O7l7l4Svb+FyBtA93CjCo+Z9QC+AzwadixhM7PDgRHAYwDuvsvdN4UaVPgygGwzywAOA9aGHE+zcvd5wMYGzWOAJ6L3nwAuiMe+lCCSjJnlAoXA+yGHEqbfAT8FakKOIxl8A6gApkUPuT1qZu3CDios7r4GuBv4HCgHNrv7nHCjSgpd3b0cIh84gS7x2KgSRBIxsxzgeeBmd/9n2PGEwczOA9a5+4KwY0kSGcBAYLK7FwLbiNPhg5Yoemx9DNAbOAZoZ2aXhRtV66UEkSTMLJNIcpjh7rPCjidEw4HzzWwVMBP4tpk9FW5IoSoDyty9dkT5HJGEkarOBD5z9wp3rwJmAaeEHFMy+MrMugFEf66Lx0aVIJKAmRmRY8xL3f2esOMJk7v/3N17uHsukZOPf3X3lP2E6O5fAl+YWW3R9JHAJyGGFLbPgaFmdlj0/2YkKXzSPsbLwOXR+5cDL8Vjoxnx2IgcsuHAOOBjM1sUbbvV3WeHF5IkkX8DZphZG2AlcGXI8YTG3d83s+eAEiJX/y0kxabcMLOngdOBTmZWBtwO3AU8a2ZXE0miF8dlX5pqQ0REgugQk4iIBFKCEBGRQEoQIiISSAlCREQCKUGIiEggJQgREQmkBCEtgpnlxk5vnIDtXxA7g66ZzTWzojhsd7aZdTjU7cSDmd1hZj8JOw5pOZQgRCIuAOI+xbq7n9saZl+1CL1fpBj9wqUlSTezR6LFYuaY2YlmVlK70MzyzGxB9P4qM/tvM/sgevtmtP1YM3vDzD6K/uxlZqcA5wO/NrNFZnZcdJMXR9ddZmbfiq6fbma/NrP50W1cF23vZmbzousvjum/ysw6mVk7M3vVzD6MLr+kqScZXecXZlZiZh+b2QnR9nojgOh2cqO3T6MzvS42sxlmdqaZvRMtIDM4ZvMnmdlfo+3XxGxrUsxz+kW0LdciBYoeJPLN5Z4H/6uTlkgJQlqSPOABdz8R2ERkWvTNZlYQXX4lkWIqtf7p7oOB/yEyhTjR+9PdfQAwA7jP3f9OZC6bSe5e4O7/iPbNiK5/M5HpDACuJjLF9CBgEHCNmfUGLgVec/cCIkV9FjWI/WxgrbufFC108+d9PNf17j4QmAzsz2GhbxIpLDQAOCEaz6nRdW+N6TeASK2NYcB/mtkxZnYWkdd2MFAAnGxmI6L9+xB5vQrdffV+xCGtiBKEtCSfufui6P0FQC6RokJXmlk6cAnw+5j+T8f8rC3TOSymz5NE3kSbUjurbu2+AM4CxkfnzHof6EjkzXV+NI47gPxo4adYHwNnRkc133L3zft4rkH73pvP3P1jd68BlhCpLubR/cau/5K7V7r7euBNIknhrOhtIZGRwgnR5wSw2t3f24/9SyukBCEtyc6Y+7uJTDb5PHAOcB6wwN03xPTxJu6zH+2x+6vdF4AB/xYdaRS4e293nxOt8jUCWAM8aWbj6+3EfRlwMpE37F+Z2X/uZb9N7bua+v+zWQH9IVJoaWfM/dhJORs+X48+p1/FPKdvuvtj0eXb9hGntGJKENKiufsO4DUih2KmNVh8SczPd6P3/86eGsY/BN6O3t8CtN+PXb4GXB+t34GZHR89v3AskUJHjxCZur1ezQYzOwbY7u5PEamIdjA1HVbVrmdmA4kUzTlQY8wsy8w6EpkRdH70OV1lkYJVmFl3M4tLRTJp2TTdt7QGM4CxQMPSk23N7H0iH4R+EG27EZhqZpOIlPKsnTp7JvCImd0IXLSXfT1K5JBNSbQeQQWRK6BOByaZWRWwFRjfYL18IifBa4Aq4PoDe4pAZLRUe3hrPrDsILbxAfAq0Av4P+6+FlhrZn2BdyNPia3AZURGL5LCNN23tHjRK3uOcPf/HdO2CiiKHmsXkYOgEYS0aGb2AnAc8O2wYxFpbTSCEAlJNLk1PI/wM3d/LYx4RBpSghARkUC6iklERAIpQYiISCAlCBERCaQEISIigf4/4vPDslcNRysAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "m = 10 # Number of hypotheses. \n",
    "alpha = 0.05 # Significance level for multiple hypothesis testing. \n",
    "# Create m p-values randomly from uniform distribution, sorted.\n",
    "df = pd.DataFrame( {\n",
    "    'l' : np.array([i *alpha/m for i in range(1,m+1)]),\n",
    "    'p' : np.sort(np.random.uniform(0, .06, size=m))\n",
    "})\n",
    "\n",
    "lt_filter = (df['p'] < df['l'])\n",
    "try:\n",
    "    T = df[lt_filter]['p'].iloc[-1]\n",
    "except:\n",
    "    T = df['p'].max()\n",
    "    print(\"No qualifying points; T is undefined\")\n",
    "\n",
    "bonferroni_threshold = alpha/m\n",
    "    \n",
    "df['reject'] = df['p'] < T\n",
    "df['hypothesis_number'] = df.index +1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "sns.scatterplot(data = df,x='hypothesis_number',y='l', color=\"green\", label = \"L\")\n",
    "sns.scatterplot(data = df,x='hypothesis_number',y='p', hue = \"reject\" , label = \"P\")\n",
    "plt.axhline(T, label='T', color = \"red\")\n",
    "plt.axhline(bonferroni_threshold, label = \"bonferroni threshold\")\n",
    "plt.legend();\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7638f3ac-1aae-4a95-8edd-dff91c8736d8",
   "metadata": {},
   "source": [
    "Here is why BH is cool; let $R$ be the number of hypotheses rejected, and $V$ be the number of hypotheses incorrectly reject. \n",
    "\n",
    "**Definition:** The <u>false discovery proportion</u> is \n",
    "$$\\text{FDP} = \n",
    "\\left\\{ \n",
    "\\begin{array}{ll} \n",
    "V/R & \\text{ if } R>0 \\\\ \n",
    "  0 & \\text{ if } R=0\n",
    "\\end{array}\n",
    "\\right. .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3783da-5efb-4f49-a5cd-dbdc26cc69de",
   "metadata": {},
   "source": [
    "**Definition:** The <u>false discovery rate</u> is $\\mathbb{E}(\\text{FDP})$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c35587-2e94-4767-9676-a98358c599d8",
   "metadata": {},
   "source": [
    "**Theorem:** With the BH procedure, regardless of the truth value of the hypotheses and regardless of the distribution of the $p$-values, $\\text{FDR} \\leq \\alpha$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd96e27d-2d57-4cb6-a137-a6f0b4423fce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d374fe0-0d41-44d6-88ed-15d45c1f28b3",
   "metadata": {},
   "source": [
    "## 10.8 Goodness-of-fit Tests\n",
    "When we want to check whether the data come from an assumed parametric model. There are many such tests; here is one for multinomial models. \n",
    "\n",
    "For a partition $I_1,...,I_k$ of $\\mathbb{R}$ into k disjoint intervals\n",
    "$p_j(\\theta) =\n",
    "\\int_{I_i}f(x;\\theta)dx$\n",
    "is the probability that an observation falls into interval $I_j$ under the assumed model. \n",
    "\n",
    "Let $N_j$ be the number of observations that fall into $I_j$. The likelihood for \n",
    "$\\theta = (\\theta_1,...,\\theta_s)$  based on the $N_i$ is the multinomial likelyhood \n",
    "$$Q(\\theta) = \\prod_i p_i(\\theta)^{N_j}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecaf3b87-642d-4b23-ab90-a6aebc5dc34b",
   "metadata": {},
   "source": [
    "Let \n",
    "$$\n",
    "\\tilde{\\theta} \n",
    "= \n",
    "\\underset{\\theta}{\\text{argmax}}\n",
    "\\,Q(\\theta)\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156b4c73-16f4-4b39-a906-73e81accbb92",
   "metadata": {},
   "source": [
    "Then the statistic $Q:=\\sum\\limits_{i=1}^k \\frac{(N_j −n p_j(\\tilde  \\theta  ))^2}{n p_j(\\tilde  \\theta  )} \\stackrel{dist}{\\to} \\chi^2_{k−1−s}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1efce5-4530-4466-8082-391b9948e3f0",
   "metadata": {},
   "source": [
    "**Theorem** p-value for the test is $\\mathbb{P}(\\chi^2_{k−1−s} > q)=1-F_{\\chi^2_{k-1-s}}(q)$ where $q$ denotes the observed value of $Q$ and $s$ is the number of components of the parameter $\\theta = (\\theta_1,...,\\theta_s)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1296deae-fb4f-4776-8d06-f25b2c81fa1a",
   "metadata": {},
   "source": [
    "## 10.10.2 The t-test\n",
    "\n",
    "Let $X_1,...,X_n ∼ N(μ,σ^2)$ where $ \\theta   = (μ,σ^2)$ are both unknown. Suppose we want to test $μ=μ_0$ versus $μ \\neq μ_0$. Let\n",
    "$$\n",
    "T= \\frac{(\\bar X_n − μ_0)}{  S_n/\\sqrt{n} }\n",
    "$$ \n",
    "Althoough $T\\sim N(0,1)$ for large $n$, the exact distribution of the statistic $T$ is called the t-distribution with n-1 degrees of freedom.\n",
    "\n",
    "**Definition** A random variable T has a **t-distribution with $k$ degrees** of freedom if it has density\n",
    "$$\n",
    "f(x) \n",
    "= \n",
    "\\frac{\n",
    "       \\Gamma\\left(\\frac{k+1}{2}\\right)\n",
    "       }\n",
    "      {\n",
    "      \\sqrt{k\\pi}\\Gamma\\left(\\frac{k}{2}\\right)\n",
    "      }\n",
    "\\frac{1}{   \\left(1+\\frac{x^2}{k}\\right)^{(k+1)/2}\n",
    "        }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17aeb4-52b8-4c9d-8cff-be90acd3d42d",
   "metadata": {},
   "source": [
    "To test $H_0 :μ =μ_0$ where $μ=E(X_i)$ is the mean, we can use the Wald test. But when \n",
    "- the data are assumed to be Normal and \n",
    "- the sample size is small (<30), \n",
    "it is common instead to use the $t-test. \n",
    "\n",
    "**Definition** In the t-test we reject the null hypothesis $\\mu = \\mu_0$ when $|T| > t_{n−1,α/2}$. Then we get a size $\\alpha$ test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e5f4b1-47d2-42d0-82f1-d82a1e5dc214",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1ff3c7b-4131-46f6-a218-af28c2eb1aea",
   "metadata": {},
   "source": [
    "# Ch 11  Bayesian Inference\n",
    "\n",
    "The frequentist point of view is based on the following postulates:\n",
    "- F1 Probability refers to limiting relative frequencies. Probabilities are objective properties of the real world.\n",
    "- F2 Parameters are fixed, unknown constants. Because they are not fluctuating, no useful probability statements can be made about parameters.\n",
    "- F3 Statistical procedures should be designed to have well-defined long run frequency properties. For example, a 95 percent confidence interval should trap the true value of the parameter with limiting frequency at least 95 percent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094ec8f8-b7af-412c-a973-ca9a3844b477",
   "metadata": {},
   "source": [
    "The Beysian point of view is \n",
    "- B1 Probability describes degree of belief, not limiting frequency. As such, we can make probability statements about lots of things, not just data which are subject to random variation. For example, I might say that “the probability that Albert Einstein drank a cup of tea on August 1, 1948” is 0.35. This does not refer to any limiting frequency. It reflects my strength of belief that the proposition is true.\n",
    "- B2 We can make probability statements about parameters, even though they are fixed constants.\n",
    "- B3 We make inferences about a parameter  $\\theta$   by producing a probability distribution for  $\\theta$. Inferences, such as point estimates and interval estimates, may then be extracted from this distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17211d4-71c3-4bc7-ad2c-ec06052b3121",
   "metadata": {},
   "source": [
    "## 11.2 The Bayesian Method\n",
    "1. We choose a probability density $f(\\theta)$ — called the **prior distribution** — that expresses our beliefs about a parameter $\\theta$ before we see any data.\n",
    "2. We choose a statistical model $f(x| \\theta  )$ that reflects our beliefs about x given $ \\theta  $. Notice that we now write this as $f(x| \\theta  )$ instead of $f(x; \\theta  )$ as we did for frequentist statistics.\n",
    "3. After observing data $X_1,...,X_n$, we update our beliefs and calculate the **posterior distribution** $f(\\theta|X_1,...,X_n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b05df9-2bfb-4b32-8c65-02ffee3a6214",
   "metadata": {},
   "source": [
    "The posterior distribution is calculated from the prior distribution and the data by Bayes's theorem\n",
    "$$f( \\theta  |x^n) = \\frac{ f(x^n| \\theta  )f( \\theta  ) } {\\int f (x^n| \\theta  )f ( \\theta  )d \\theta  }.$$\n",
    "Renaming the normalization constant $C$\n",
    "$$f( \\theta  |x^n) =  C f(x^n| \\theta  )f( \\theta  ) = C \\prod\\limits_i f(x_i| \\theta  )f(\\theta) = C {\\cal L}(\\theta) f(\\theta)$$\n",
    "\n",
    "That is \"Posterior is proportional to Likelihood times Prior\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1565232b-bfc5-4274-ad03-32d56801b33b",
   "metadata": {},
   "source": [
    "**Example** Let $X_1, . . . , X_n ∼ \\text{Bernoulli}(p)$. Take the uniform pdf $f:[0,1]\\to \\mathbb{R} \\text{ such that } f(p) = 1 ~\\forall ~ p \\in [0,1]$ as a prior. By Bayes’ theorem, the posterior has the form\n",
    "$f(p|x^n) ∝ f(p){\\cal L}_n(p) = p^{s}(1 − p)^{n−s} = p^{s+1−1}(1 − p)^{n−s+1−1}$\n",
    "where $s = \\sum_{i=1}^n x_i$ is the number of successes. Then \n",
    "$$\\text{prior } f(p) = \\beta(1,1)(p)\\\\\n",
    "\\text{posterior } f(p|x^n) = \\beta(s+1,n-s+1)(p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7194c4b3-0b42-4cb9-b601-4b1e6a6f4e97",
   "metadata": {},
   "source": [
    "**Definition** When the prior and the posterior are in the same (exponential) family (model), we say that the prior is **conjugate** with respect to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad9911b-bf2c-4790-9029-2b35dbd1aadc",
   "metadata": {},
   "source": [
    "## 11.6 Flat Priors, Improper Priors, and “Noninformative” Priors\n",
    "Where does one get the prior $f( \\theta  )$? \n",
    "\n",
    "School of thought, \n",
    "- **subjectivism** says that the prior should reflect our subjective opinion about $ \\theta  $ (before the data are collected). \n",
    "- use a “noninformative prior” like a flat prior $f( \\theta  ) ∝$ constant.\n",
    "\n",
    "Problem: \n",
    "Flat priors are not transformation invariant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e421165-ca6a-4823-b51a-4503fe7d160e",
   "metadata": {},
   "source": [
    "**Jeffreys’ Prior** Take\n",
    "$f(\\theta) ∝ I(\\theta)^{1/2}$\n",
    "where \n",
    "- the Fisher information function \n",
    "$I_n(\\theta) = \\sum\\limits_{i=1}^n \\mathbb{V}_ \\theta   (s(X_i;  \\theta  )) = nI(\\theta) = \\mathbb{V}_ \\theta   (s(X;  \\theta  ))$,\n",
    "and \n",
    "- the score function (statistic) \n",
    "$s(X; \\theta  )= \\frac{\\partial \\log f(X; \\theta  )}{\\partial \\theta}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d22c3d-02c0-468e-9f78-bef8fd84a2c8",
   "metadata": {},
   "source": [
    "**Definition:** An **improper prior** on $\\theta$ is a constant prior $f(\\theta) \\alpha c$ over $\\mathbb{R}$. \n",
    "\n",
    "Of course, sucha a thing is not normalizable, but formally it works as a prior since it drops out of Bayes's theorem\n",
    "$$f( \\theta  |x^n) = \\frac{ f(x^n| \\theta  )f( \\theta  ) } {\\int f (x^n| \\theta  )f ( \\theta  )d \\theta  }.$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f7c573-40d5-4e36-8f6f-95540c4aebac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## 11.8 Bayesian Testing\n",
    "Hypothesis testing from a Bayesian point of view is a complex topic; some choice of priors lead to intractable cancluations. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bbe538-2589-4890-bf73-0cca8f6af167",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ch 12 Statistical Decision Theory\n",
    "\n",
    "a formal theory for comparing statistical procedures.\n",
    "\n",
    "- loss\n",
    "- risk \n",
    "- minimax risk rule \n",
    "- admissable estimators\n",
    "- Stein’s Paradox and estimator\n",
    "\n",
    "all Opaque. :( \n",
    "\n",
    "--- \n",
    "\n",
    "Which estimator of $\\theta \\in \\Theta$ is best?  \n",
    "\n",
    "In the language of decision theory, \n",
    "- an estimator is sometimes called a **decision rule**\n",
    "- the possible values of the decision rule are called **actions**.\n",
    "\n",
    "**Definition:** A **loss function** maps $\\Theta \\times \\Theta$ into $\\mathbb{R}$ to measure discrepancy between $\\theta$ and $\\hat \\theta$. \n",
    "\n",
    "Here are some examples of loss functions:\n",
    "- squared error loss $L(\\theta , \\hat \\theta) = (\\theta - \\hat \\theta)^2$ \n",
    "- absolute error loss $L(\\theta , \\hat \\theta) = | \\theta - \\hat \\theta|$\n",
    "- zero-one loss: $L(\\theta ,\\hat \\theta) = 0$ if $\\theta = \\hat \\theta$ or 1 else. \n",
    "- Kullback-Leibler loss: $L(\\theta ,\\hat \\theta)= \\int \\log  \\frac{ f(x;\\theta) }{{ f(x;\\hat \\theta) }}f(x;\\theta) dx$ \n",
    "\n",
    "\n",
    "Remember here that the estimator is a function of the data; $\\hat \\theta(X^n)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d82ce41-d137-44f0-a04b-c089fa0a4c5f",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Definition:** The **risk** of the estimator $\\hat \\theta$ under the loss function $L$ is $$R(\\theta,\\hat \\theta) = \\mathbb{E}_{X^n;\\theta} L\\big(\\theta,\\hat \\theta(X^n)\\big) = \\int L\\big(\\theta,\\hat \\theta(x^n)\\big) f_{X^n;\\theta}(x^n)dx^n.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036cb66b-aff7-4eaa-97b4-400ff77a8ec0",
   "metadata": {
    "tags": []
   },
   "source": [
    "We would love it if the risk of one estimator was larger than the risk of another estimator for all values of $\\theta$. We are not so lucky. Thus, to compare the risk of estimators we introduce another conbstruct.\n",
    "\n",
    "**Definition:** The <u>max risk</u> of the estimator $\\hat \\theta$ under loss function $L$ is \n",
    "$$\n",
    "\\bar R (\\theta ,\\hat\\theta) = \\underset{\\theta}{\\text{sup}} R(\\theta,\\hat\\theta).\n",
    "$$\n",
    "\n",
    "**Definition** The <u>Bayes risk</u> of the estimator $\\hat \\theta$ under the prior $f(\\theta)$ is \n",
    "$$\n",
    "r(f,\\hat\\theta) = \\int R(\\theta ,\\hat\\theta) f(\\theta)d\\theta.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ddfc2a-7a9d-4976-9977-af5bc58e540d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Recall that estimators are called rules in this field. \n",
    "\n",
    "**Definition:** The estimator that mimimizes the maximum risk is the <u>minimax rule</u> of $\\theta$. \n",
    "\n",
    "\n",
    "$$\n",
    "\\underset{\\hat \\theta}{\\text{argmin}}  \n",
    "\\sup_{\\theta} R(\\theta,\\hat\\theta).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0b0e10-1221-4b7b-905f-fe5a6249bb3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Definition:** The estimator that minimizes the Bayes risk is the <u>Bayes Rule</u>\n",
    "$$\n",
    "\\underset{\\hat \\theta}{\\text{argmin}}\\, r(f,\\hat \\theta).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae55cf7-41c9-4b15-a223-bfc647927113",
   "metadata": {
    "tags": []
   },
   "source": [
    "--- \n",
    "Now to show tha the Bayes risk does not change with data, on average.\n",
    "\n",
    "**Defnition:** The <u>posterior risk</u> of the estimator $\\hat \\theta$ with prior  $f$ and data $x$ is $r\\left(f,\\hat \\theta|x\\right):= \\int L\\big(\\theta,\\hat\\theta(x)\\big) f(\\theta|x)d\\theta$. \n",
    "\n",
    "\n",
    "**Theorem:** $r(f,\\hat \\theta) = \\int r\\left(f,\\hat\\theta|x\\right) f(x) dx$ where the marginal $f(x) =\\int f(x,\\theta)d\\theta$. \n",
    "\n",
    "<details><summary>Proof</summary>\n",
    "**Proof** \n",
    "{}\n",
    "$$\n",
    "\\begin{array}{ll}\n",
    "r(f,\\hat \\theta)&: = \\int \\color{blue}{R(\\hat\\theta ,\\theta)} f(\\theta) d\\theta\\\\\n",
    "&= \\int \\color{blue}{ \n",
    "\\int L(\\theta,\\hat \\theta(x)) f(x| \\theta) dx \n",
    "} f(\\theta) d\\theta\\\\\n",
    "&= \\int  L(\\theta,\\hat \\theta(x)) f(x, \\theta) dx  d\\theta\\\\\n",
    "&= \\int  L(\\theta,\\hat \\theta(x)) f( \\theta|x) f(x) dx  d\\theta\\\\\n",
    "&= \\int \\color{green}{ \\int L(\\theta,\\hat \\theta(x)) f( \\theta|x)  d\\theta }\n",
    "f(x)dx  \\\\\n",
    "&= \\int \\color{green}{ r(f,\\hat \\theta | x)}\n",
    "f(x)dx  .\\\\\n",
    "\\square \n",
    "\\end{array}\n",
    "$$\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5334d7-9bae-40e2-9580-1d455c891f33",
   "metadata": {
    "tags": []
   },
   "source": [
    "The squared, absolute, and zero-one loss have Bayes rules that are the mean median and mode of the posterior distribution, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8284d41-7cd6-43af-aaeb-d4f6291b2af9",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Theorem:** The Bayes rule under loss $L(\\theta,\\hat \\theta) =\\left( \\theta - \\hat \\theta\\right)^2$, prior $f$, and evidence $x$ is $\\hat \\theta = \\mathbb{E}(\\theta|X=x)$.\n",
    "\n",
    "**Proof:** \n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\hat \\theta} r\\left(f,\\hat \\theta | x\\right)=0\\\\ \n",
    "\\Leftrightarrow \\frac{\\partial}{\\partial \\hat \\theta} \\int R\\left(\\theta,\\hat \\theta\\right) f\\left(\\theta|x^n\\right) d\\theta =0\\\\ \n",
    "\\Leftrightarrow \\frac{\\partial}{\\partial \\hat \\theta} \\int \\big(\\theta - \\hat \\theta(x^n)\\big)^2 f\\left(\\theta|x^n\\right) d\\theta =0 \\\\ \n",
    "\\Leftrightarrow 2\\int\\left(\\theta - \\hat\\theta \\right)f(\\theta|x) d\\theta=0\\\\\n",
    "\\Leftrightarrow \\hat\\theta  = \\mathbb{E}(\\theta| X=x)\\\\\n",
    "\\square.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d0716-9a7b-4251-8155-101084bf42fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "Theorems on minimax rules generally point this direction:\n",
    "> In most parametric models, with large samples, the MLE is approxi- mately minimax and Bayes, but maximum likelihood is not an optimal estimator when the number of parameters is approx the size of the sample. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8acc36b-61d9-48b2-a630-b2935b1f4915",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af5547b2-2e08-49a9-9641-92d19e4bde51",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41218525-8167-4e04-a923-1576a28c94e1",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a110edd-a767-4eab-a400-9521a6b4f6a0",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd7f58a-4240-4bd7-9063-913d62da98cd",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "398503b7-1366-4d0a-bdca-913db17bff56",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "348fb3e9-9927-4da3-b3d1-e5825b47dcbe",
   "metadata": {
    "tags": []
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
